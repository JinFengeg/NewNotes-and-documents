# ARM嵌入式系统开发-软件设计与优化

## 内容介绍

本书从软件设计的角度，全面、系统地介绍ARM处理器的基本体系结构和软件设计与优化方法。内容包括：

- ARM处理器基础；这是37个寄存器
- ARM/Thumb指令集；两种工作状态
- C语言与汇编语言程序的设计与优化；这里是如何在ARM体系结构下优化
- 基本运算、操作的优化；
- 基于ARM的DSP；这个好像是和算法有关
- 异常与中断处理；切换工作模式。
- 固件与嵌入式OS；烧录固件，震哥之前说过flash就是烧录了固件，所以我们只需要把指令写入寄存器中即可。操作系统与体系结构关系更加密切
- cache与存储器管理；内存管理
- ARMv6体系结构的特点等。

全书内容完整，针对各种不同的ARM内核系统结构都有详尽论述，并有大量的例子和源代码。

本书适合于从事ARM嵌入式系统教学和研发，想把其他嵌入式平台的软件移植到ARM平台上去的专业技术人员使用。

学习要求：

- 对ARM处理器有一定的了解
- C语言和汇编语言的基础
- 编译原理、操作系统、数字信号处理、计算机体系结构有一定基础。

## 致中国读者

本书的目的是展示如何设计和优化基于ARM处理器核的系统软件。目标是提供一个基础的工作参数，以便能利用它开发出许多成功的新产品。

2004年，ARM的合作伙伴生产制造了12亿片ARM处理器。ARM也推出了两个新的处理器：Cortex-M3和MPCore。Cortex-M3主要针对微控制器市场，而MPCore主要针对高端的消费类产品。

Cortex-M3改进了代码密度，减少了中断延迟，并有更低的功耗。Cortex-M3实现了本书第十五章所提到的Thumb-2指令集。MPCore是第一个ARM多处理器内核，执行基于均衡多处理器SMP的操作系统。MPCore提供了cache一致性，每个芯片支持1-4个ARM11核，这种设计为现代消费类产品对性能和功耗的需求作了很好的平衡。ARM还引入了L2cache控制器来改进系统的整体性能。

为了支持大量的密集数据处理，ARM引入了OptimoDE技术，作为一个可配置的、专用的超长指令字VLIW数据引擎，配合ARM处理器工作。这种数据引擎可帮助主处理器完成诸如MPEG4或H.264等复杂算法。

## 译者序

多年对ARM系统的研究与时间，一方面加深了我们对ARM处理器系统的理解，另一方面嵌入式由于其硬件资源、成本的限制以及一些实施需求，许多在PC等标准平台上的软件包括系统软件和应用软件都不能直接搬到一个特殊的嵌入式硬件平台上，必须经过适当的剪裁、优化；否则可能产生很差的效果，甚至导致系统瘫痪。通过对软件系统的合理设计与优化，可以降低对系统硬件资源（比如CPU性能、存储器、容量等）的需求，也可以降低系统功耗，从而使一个不可行的系统变为可行，也可以把一个毫无竞争力的产品变得极有竞争力。

这本书是从软件系统的角度对ARM系统开发的一个原则性指导，也是嵌入式软件开发者从入门变为高手的一个必备指南。

## 前言

本书的目标是，从一名产品开发者的角度来描述ARM内核的操作，重点放在软件设计上，不要求有以前的ARM开发经验。

## 本书的结构

1. 本书开头部分简要介绍了ARM处理器的设计原则，说明了他和传统RISC思想的区别及其原因。
2. 第一章介绍了基于ARM处理器的简单嵌入式系统。
3. 第二章进一步深入到硬件，介绍了ARM处理器核，综述了当前市场上的ARM内核。
4. 第三章和第四章分别介绍了ARM和Thumb指令集，为本书后面的内容打基础；有一些关键指令的解释，包括完整的例子。
5. 第五章和第六章讲述了如何编写高效的代码。第五章讲述了在ARM体系结构上编写可以被高效编译的C代码的技巧和规则。
6. 第六章详述了编写和优化ARM汇编代码的最佳方法，这对于通过降低系统功耗和时钟频率来改善系统性能是至关重要的。
7. 许多算法中都用到一些基本操作，如何优化他们是很值得研究的。第七章讨论了如何针对ARM处理器优化基本操作。该章不仅提供了实现一般基本操作的优化参考，而且为想得到一种快速参考方法的使用者提供了更加赋值的数学运算的优化参考。
8. 嵌入式音频和视频系统应用的需求正在日益增长。他们需要数字信号处理能力DSP。现在ARM体系结构提供了更高的存储器带宽和快速乘累加运算。使得仅用一个ARM内核的设计就能支持这些应用。第八章研究了如何尽可能改善ARM在数字处理应用方面的性能以及怎样实现DSP算法。
9. 异常处理是嵌入式系统的核心。高效的异常处理能够大大改善系统的性能。第九章以一系列范例介绍了异常处理和中断的理论与实践。
10. 固件是所有嵌入式系统的重要部分，第十章通过设计的称为Sandstone的一个简单固件包，介绍了固件的结构和设计。本章还介绍了一些可以运行在ARM上流行的工业固件包。
11. 第十一章设计的称为简单小操作系统SLOS的一个简单嵌入式操作系统为例，示范了嵌入式操作系统的实现方法。
12. 第十二、十三、十四章重点关注存储系统。第十二章讨论了围绕ARM内核的各种cache技术，演示了带cache的特定的ARM处理器的cache控制例程（缓存是由CP15协处理器控制的）。第十三章讨论了存储器保护单元MPU。第十四章讨论了存储器管理单元MMU。
13. 第十五章，展望了ARM体系结构的未来。

## 第一章、基于ARM的嵌入式系统

- RISC设计思想
- ARM设计思想
- 嵌入式系统的硬件
- 嵌入式系统的软件
- 总结

在许多成功的32位嵌入式系统中，ARM处理器都是其核心组成部分。也许大家还没有意识到，自己身边可能就有基于ARM处理器的产品。ARM内核已被广泛应用于移动电话、掌上设备以及种类繁多的便携式消费类产品中。

从1985年第一个ARM1原型诞生至今，ARM的设计者们经历了漫长的探索之路。到2001年底，已经有超过10亿个ARM处理器被销售到了世界各地。ARM公司的成功简历在一个简单而又强大的原始设计之上，事实上，ARM内核并不是单一的，而是一个遵循相同设计理念和使用相同指令集的内核系列。

例如，最成功的ARM内核之一是ARM7TDM1，具有最高120DhrystoneMIPS的性能。（这是一个小的基准测试程序）、高的代码密度和低功耗等特性个，使得他成为移动嵌入式设备的最佳选择。

第一章首先是介绍ARM是如何采用RISC(精简指令集计算机)的设计思想，创造出一个灵活的处理器结构；然后通过介绍一个嵌入式设备的实例，讨论围绕ARM处理器的典型的软硬件相关技术。

### 1.1RISC设计思想

**ARM内核采用RISC体系结构。**RISC是一种设计思想，其目标是**设计出一套能在高时钟频率下单周期执行、简单而有效的指令集**。RISC的设计重点在于**降低由硬件执行的指令的复杂度**，因为软件比硬件跟容易提供灵活性和更高的智能。因此，RISC设计对编译器有更高的要求；相反，传统的复杂指令集的计算机**CISC更侧重于硬件**执行指令的功能性，使得CISC指令更复杂。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1677566885737.png" alt="1677566885737" style="zoom:33%;" />

RISC设计思想主要由下面四个设计准则来实现。

-  指令集，RISC处理器减少了指令种类。RISC的指令种类只提供简单的操作，使得**一个周期就可以执行一条指令**。编译器或者程序员通过几条简单指令组合来实现一个赋值的操作。**每条指令长度固定，允许流水线在当前指令 译码阶段去取其下一条指令。**取指阶段的指令是正在执行指令的下一条指令。而在CISC处理器中，指令长度通常不固定，执行也需要多个周期。
- 流水线，**指令的处理过程被拆分成几个更小的、能够被流水线并行执行的单元**。在理想情况下，流水线每周期前进一步，可获得最高的吞吐率。而CISC指令的执行需要调用微代码的一个微程序。**RISC指令执行依靠组合逻辑电路。**
- 寄存器，**RISC处理器拥有更多的通用寄存器。每个寄存器都可存放数据或地址。**寄存器可为所有的数据操作提供快速的局部存储访问；**而CISC处理器都是用于特定目的的专用寄存器。**
- load-store结构，**处理器只处理寄存器中的数据**，独立的load和store指令用来完成数据在寄存器和外部存储器之间的传送。因为访问存储器很耗时，所以**把存储器访问和数据处理分开**。好处就是反复使用保存在寄存器中的数据，而避免多次访问存储器。相反在**CISC结构中，处理器能够直接处理存储器中的数据。**实际上就是移入移出两种指令而已。这里的分开指的是不直接对存储器里的数据进行处理。

这些设计准则，使得RISC结构的处理器更为简单，因此内核能够工作在更高时钟频率。相反，传统的CISC处理器因为结构更为复杂，只能工作在较低的时钟频率。（一个时钟周期执行一个指令）经过二十多年发展，CISC处理器也引入了许多RISC的设计思想，两者的界限越来越模糊了。

### 1.2ARM设计思想

有许多客观需求促进了ARM处理器的设计改进。首先便携式的嵌入式设备往往需要电池供电。为了**降低功耗**，ARM处理器已被特殊设计成较小的核，从而**延长了电池的使用时间**。特别是对于某些应用，比如手机很重要。

**高的代码密度**是嵌入式系统的又一个重要需求。由于成本问题和物理尺寸的限制，**嵌入式系统的存储器是很有限的**。所以高的代码密度对于那些仅限于在板存储器的应用很有帮助。（之前疑惑过，代码密度是什么意思，就是存储器中的代码量）

嵌入式系统通常都是**价格敏感**的，因此一般都使用**速度不高，成本较低**的存储器。（Nor和Nand两种存储器，前者地址总线，后者I/O接口通信）

**缩小嵌入式处理器内核管芯die的面积**。对于一个单片方案，**处理器内核所占用的面积越小，留给外设电路的空间越大**。减少最终产品的外围芯片数目，从而降低设计和制造成本。

ARM处理器中已经**集成了硬件调试技术**，因此软件工程师们能够观察到处理器在执行代码时的具体情况。这种更高的可视性，使得软件工程师们能够更快速地解决问题。**降低系统的整体开发成本**。

**ARM内核不是一个纯粹的RISC体系结构**，这是为了使它能够更好地适应其主要应用领域-嵌入式系统。某种角度说，正是因为他没有在RISC概念上沉入太深，才有了ARM内核的成功。现在系统的关键不在于单纯的处理器速度，而在于有效的系统性能和功耗。（之前就感觉内核分为Linux内核与ARM内核，一个软件一个硬件，处理器内核指的就是处理器本身）

#### 面向嵌入式系统的指令集

为了使ARM指令集能够更好地满足嵌入式应用的需要，ARM指令集和单纯的RISC指令集有以下几方面的不同。

- **一些特定指令的周期数可变**-并不是所有的ARM指令都是单周期的，比如多寄存器装载/存储的load/store指令的执行周期就是不确定调度，根据被传送的寄存器个数而定。如果是访问连续的存储器地址，就可以改善性能，因为连续的内存访问通常比随机访问要快。同时，代码密度也得到了提高，因为在函数的起始和结尾，多个寄存器的传输很常见。
- **内嵌桶型移位器产生了更为复杂的指令**-内嵌桶形移位器是一个硬件部件，在一个输入寄存器被一条指令使用之前，**内嵌桶形移位器可以处理该寄存器中的数据** 。扩展了许多指令的功能，以此改善了内核的性能，提高了代码密度。
- **Thumb16位指令集**-ARM内核增加了一套称为Thumb指令的16位指令集，使得**内核既能够执行16位指令，也可以执行32位指令**，从而增强了ARM内核的功能。16位指令与32位的定长指令相比较，代码密度可以提高约30%
- **条件执行**-**只有当某个特定条件满足时指令才会被执行。这个特性可以减少分支指令的数目**，从而改善性能，提高代码密度。
- **增强指令**-一些功能强大的数字信号处理器DSP指令被加入到标准的ARM指令之中，以**支持快速的16 * 16位乘法操作及饱和运算**。在某些应用中，传统的方法需要微处理器加上DSP才能实现。ARM的这些增强指令，使得ARM处理器也能够满足这些应用的需求。

这些增加的特性使得ARM处理器成为当今最通用的32位嵌入式处理器内核之一。

### 1.3嵌入式系统的硬件

嵌入式系统可控制各种不同的设备，从生产线上的小传感器，到NASA太空探测器中的实时控制新系统。所有的这些设备都是一些软件和硬件部件的组合。每一个部件的选择都要考虑到效率；而且如果可行，设计时还需要考虑将来的扩展性和延伸性。

图1.2所示为一个典型的使用ARM内核的嵌入式器件。每一个方框表示了一个功能或特性。方框之间的连线是传送数据的总线。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1677652137671.png" alt="1677652137671" style="zoom:50%;" />

可以吧这个器件分为以下四个主要的硬件部分。

- ARM处理器-控制整个器件。有多种版本的ARM处理器，以满足 不同的处理特性。一个ARM处理器包含了一个内核（执行引擎，用来执行指令和操纵数据）以及外围部件，他们之间由总线连接，这些部件可能包括存储器管理和cache。
- 控制器-协调系统的重要功能模块 。两个常见的控制器是中断控制器和存储器控制器。
- 外设-提供芯片与外部的所有输入 /输出功能，器件之间的一些独有特性就是靠不同的外设来体现的。
- 总线-用于在器件不同部件之间进行通信。

#### 1.3.1ARM总线技术

嵌入式系统使用和x86PC不同的总线技术。PCI(Peripheral Component Interconnect)总线技术是一种最常见的PC总线技术，用于把诸如图形显示适配器和硬盘控制器等连接到x86处理器总线。这是一种PC机主板上的**外部或片外总线**（这种总线也定义了外部设备与系统连接的机械和电气特性）。（这种外部总线指的是iic这样的吧）

相反，嵌入式设备使用芯片内的**片上总线**，允许不同的外围器件能够和ARM内核互联。

有两种不同类型的逻辑设备连接到总线 ：ARM处理器是总线主设备master，拥有对总线的仲裁权，通过同一总线，该逻辑设备可主动发起数据传输请求；外围器件是总线从设备slave，在总线上是被动的，逻辑设备只能对主设备发出的一个传输请求做出反应。

总线可分为两个结构层：**第一层是物理层，定义一些电气特征和总线宽度（16,32,64位）；第二层是协议层（protocol），定义了处理器和外围设备之间 进行数据通信的逻辑规则。**（比如rs485就是物理层，modbus就是协议层）（但是IIC这样的又怎么算呢）

ARM主要是一个芯片设计公司，他几乎不实现具体的总线电气特性，但他详细地定义了总线协议。

#### 1.3.2AMBA总线协议

高级微控制总线结构AMBA于1996年被提出，并被ARM处理器广泛用作片上总线结构。最初的AMBA总线包含**ARM系统总线ASB**和**ARM外设总线APB**。之后ARM公司提出了另一种总线设计，称为**ARM高性能总线AHB**。（在Cortex-M3上有APB和AHB两种总线）

使用AMB，外设设计者可在多个项目中重复使用同一设计。由于已有大量的基于AMBA接口设计的外设，因此硬件芯片设计者可从已做过测试和验证的外设中做广泛的选择。同样，一个外设也可以被简单地连接到片上总线，而不需要为不同的处理器结构重新设计接口。这种即插即用的接口提高了硬件开发者的设计效率，并缩短了产品上市时间。

AHB能够提供比ASB更更高的数据吞吐率，因为它不同于ASB的双向总线设计。AHB是**基于集中多总线机制**（centralized multiplexed bus scheme）的。这种改变使得AHB总线能够在更高的时钟速度下运行，并成为**第一个支持64位和128位宽度的ARM总线**。ARM的AHB总线结构还引入了两个变体：多层AHB和AHB-Lite。原来的**AHB在任何时候都只允许一个主设备活动在总线上**，多层AHB允许**多个活跃的总线主设备**。

**AHB-Lite是标准AHB总线的一个子集**，也只允许一个总线主设备。这种总线是**针对那些不需要标准AHB全部特性的情况而设计**的。

标准AHB和多层AHB的主从协议是相同的，但有不同的互联。多层AHB新的互联有利于多处理器系统，他允许并发操作和更高的吞吐率。

- 一条AHB总线连接高性能的片内外设
- 一条APB总线连接较慢的片内外设，这个通常是由AHB-APB桥接的
- 一条外部总线连接片外的外设，这条总线不一定都存在，外部总线需要一个特殊的桥，用于和AHB总线连续。在Cortex-M3上没有外部总线

在互联型产品中的驱动单元和被动单元就是通过一个多层的AHB总线架构相互连接的。一般是没有外部总线的，我们平时的IO口都是由APB总线连接的。

##### 总线矩阵

负责协调内核系统总线和DMA主控总线之间的访问仲裁，仲裁利用轮换算法。

##### AHB/APB桥

两个AHB/APB桥在AHB和两个APB总线间提供同步连接。

#### 1.3.3存储器

一个嵌入式系统必须有一定的存储器来存放和执行代码。在决定存储器的层次、宽度和类型等特性时，必须综合考虑价格、性能和功耗等因素。如果为了获得所需要的带宽、存储器的运行速度必须提高1倍，那么功耗也会提高。

##### 1.3.3.1存储层次

几乎所有的计算机系统的存储器结构都是分层的。处理器内部有一个可选的cache，他可以提高存储器性能。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1677736527998.png" alt="1677736527998" style="zoom:33%;" />

最快的存储器cache，其物理位置上最靠近ARM处理器核，最慢的辅助存储器则处于较远的位置。通常越靠近处理器核的存储器越昂贵，容量也越小。

cache位于注册和内核之间，**用于提高处理器核注册之间的数据传输速度。cache改善了系统的总体性能，但也使代码的执行时间变得不可预测**，对实时系统响应也没什么帮助。因此很多小型的嵌入式系统中，并**不需要**使用**cache**来优化性能。

主存的容量较大，256KB~256MB，根据具体的应用而定，通常是一些独立的洗牌。load/store指令存取数据时，如果数据在cache中，则快速访问cache，否则访问主存。这就是volatile关键字的用处了。在各级存储器中，辅助存储器容量最大，速度最慢，比如硬盘等存储设备。

##### 1.3.3.2存储器数据宽度

存储器的数据宽度是指每次访问所返回的数据位数，典型的有8/16/32/64位。存储器宽度对系统整体的性价比有直接影响。

如果一个没有cache的系统使用32位ARM指令和16位宽度的存储器芯片，则处理器每次取指就需要两个16位的存储器访问，显然会降低系统的性能，但16位宽度的存储器价格会相对便宜。

与之相比，如果处理器内核执行16位的Thumb指令，则对于16位宽度的存储器将获得更好的性能，因为处理器获取每条指令只需要一次存储器访问。因此对于16位宽度的存储器，使用Thumb指令可获得性能和成本两方面的优势。

下表总结了当使用不同宽度的存储器时，理论上获取一条指令所需要的周期数。

| 指令长度  | 8位存储器 | 16位存储器 | 32位存储器 |
| --------- | --------- | ---------- | ---------- |
| ARM32位   | 4周期     | 2周期      | 1周期      |
| Thumb16位 | 2周期     | 1周期      | 1周期      |

##### 1.3.3.3存储器类型

存储器的类型很多，本小节中，介绍一些基于ARM的嵌入式系统常用的存储器。

- 只读存储器ROM(Read-Only Memory)，在所有类型的存储器中，ROM是最不灵活的一种，因为它里面的内容是在生产时就固定的，不可再次变成来改变。ROM常用于不需要更新和修改内容的大宗产品，也有许多设备使用ROM来存放**启动代码**。
- FlashROM(闪存)即可以读也可以写，但是它写的速度比较慢，因此不适合存放动态数据，主要用于存放设备**固件**（firmware)和**断电后仍需长期保存的数据**。其实就是用来烧录代码的，对于FlashROM的擦除和改写是完全由软件实现的，不需要任何的硬件电路，这样降低了制造成本。Flash ROM已经成为当前最流行的只读存储器，可选择FlahsROM用于满足对存储器的大容量需求或用于构建辅助存储器。
- 动态随机访问存储器DRAM是设备中最为常用的RAM，和其他类型的RAM相比，它每兆字节的几个最低，**动态：需要定时的刷新存储单元**，因此在使用DRAM前，先要设置好DRAM控制器。常用来作为主存，存储单元是电容，保存的电量只能维持1-2ms，需要刷新。
- 静态随机访问存储器SRAM，比传统的DRAM要快，但他需要更大的硅片面积，SRAM是静态的-不需要刷新。SRAM的存取时间比DRAM要短得多，因为SRAM在数据访问之间不需要暂停。由于价格较高，常用于容量小，速度快的情况，比如高速存储器和cache。存储单元是触发器。六管静态mos管组成，保持状态直到下一次被赋予新状态。或者断电。
- 同步动态随机访问存储器SDRAM，是众多DRAM种类中的一种。能够工作在比普通存储器更高的时钟频率下。**因为SDRAM使用时钟，所以和处理器总线是同步的**，数据从存储元被流水化地取出，最后突发式burst地输出到总线。以前老的DRAM是异步的，不能像SRAM这样突发式高效传输。

#### 1.3.4外设

嵌入式系统和外界交互需要一定形式的外设。外设通过和片外其他设备或传感器的连接来实现芯片的输入/输出功能。每一个外设通常都只有单一的功能，也可以内置在芯片上。外设种类很多，可从一个简单的串行通信设备到非常复杂的802.11无线设备。

**所有的ARM外设都是存储器映射的**，编程接口是一组对应于某些存储器地址的寄存器。这些寄存器的地址是从某个外设的基地址开始的偏移量。（banked寄存器确实会因为工作模式的不同而映射到不同的寄存器上，寄存器也可以映射到主存上，但这是操作系统的部分，这里应该是把寄存器当成存储器的一种了）。

控制器是特殊的外设，可在一个嵌入式系统中实现更高层的功能。两个重要类型的控制器就是存储器控制器和中断控制器。

##### 1.3.4.1存储器控制器

各种不同类型的存储器通过存储器控制器连接到处理器总线上。上电时，**存储器控制器由硬件配置**，使得某些存储器处于工作状态。这些存储器允许执行 初始化代码。**有些存储器必须通过软件设置才能使用**，比如在使用DRAM之前，必须首先设置存储器定时和刷新率。

##### 1.3.4.2中断控制器
当一个外设或器件需要服务时，他就向处理器提出一个中断请求。**中断控制器提供一套可编程的管理机制**，使得软件通过设置中断控制寄存器中的相应位，来决定在任何特定时刻，哪一个外设或器件可以中断处理器。

ARM处理器有两种中断控制器：（之前从来没提到过这两种）标准的中断控制器和向量中断寄存器VIC。（之前Cortex-M3中使用了NVIC）

标准中断控制器在一个外部设备需要服务时，发送一个中断请求信号给处理器核。控制器可以通过编程设置来忽略或屏蔽某个或某些设备的中断请求。（这也是中断优先级的原理）。中断处理程序读取在中断控制器中与各设备对应的表示中断请求的寄存器内容，从而判断哪个设备需要服务。（内核中提到过，涉及到共享中断线的问题，所以dev必须具有唯一性）

VIC比标准中断控制器的功能**更为强大**，因为它**区分中断的优先级**，简化了判断中断源的过程。每个中断都有相应的优先级和处理程序地址，只有当一个新的中断优先级高于当前正在执行的中断处理优先级时，VIC才向内核提出中断请求。根据类型的不同，VIC可以调用**标准的中断异常处理程序**。该程序能够从VIC中**读取**设备的**处理程序的地址**。使得内核直接**跳转**到设备的**处理程序执行**。

### 1.4嵌入式系统的软件

一个嵌入式系统需要软件来实现具体的应用。下图中的四个软件部分是嵌入式设备软件的典型构造。从底层的硬件设备层往上，每个软件层次逐层封装代码，使得软件与硬件分离。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1677821255862.png" alt="1677821255862" style="zoom:50%;" />

这个图写的挺好，初始化程序比如uboot会直接初始化硬件，设备驱动也会直接接触硬件，操作系统仔细想想确实没有接触到硬件。但也接触到一部分的设备驱动。

初始化代码是在板上最先被执行的代码，是针对一个或一组特定的目标而定制的。他在把控制权交给操作系统之前，**初始化板上的最基本部分设备**。（启动时钟、串口、关闭MMU、Dcache、启动SDRAM，关闭看门狗，第二阶段是重定位，加载内核，禁止中断，在SVC模式下运行）

**操作系统提供了一个基础框架来控制应用程序和管理硬件系统资源**。许多嵌入式系统都不需要一个完整的操作系统，只需要一个由事件或轮询驱动的简单任务调度器。（之前我就好奇过裸机开发到底是怎么回事）

设备驱动是第三个组成部分，他们**给硬件设备上的外设提供了一致的软件接口。**

最后一个**应用程序完成一个设备所需的某个任务**。操作系统可以对同一个设备上运行的多个应用程序进行统一管理。

各个软件部分都可在ROM或RAM中运行。ROM代码是固定在设备上的，称之为固件（firmware）。往IC的寄存器中写入数据的都是烧录固件的了。之前提到过有两种运行方式，RAM运行的特点是需要重定位，ROM不需要。

#### 1.4.1初始化代码

初始化代码（启动代码）使处理器从复位状态进入到操作系统能够运行的状态。通常需要配置存储器控制器（DRAM操作需要先配置控制器）、处理器cache和初始化一些设备。在一个简单的系统中，操作系统可被一个简单的任务调度器或调试监控器所代替。

初始化代码在把控制权交给操作系统之前，须处理许多管理任务。我们可以把这些不同的任务划分为3个阶段：初始化硬件配置、诊断和引导。

- 初始化硬件配置包括设置目标平台，使之能够引导一个映像文件（image，后续执行的二进制代码）。尽管目标平台复位时自己有一个标准的配置，但是这个配置通常须修改，以便满足被引导的映像文件的需求。比如存储系统通常需要重新组织存储器映射（memory map）。这里指的是重定位不
- 诊断通常包含在初始化代码中，诊断代码用来检测系统，通过测试硬件目标来检测其工作是否正常。同时它也检测标准的系统相关的事件。测试发生在软件产品完成后，因此这种测试对于生产制造是非常重要的。诊断代码的主要目的是识别和隔离故障。
- 启动一个映像文件是最后一个阶段，首先必须装载这个映像文件。装载一个映像文件的过程可以是拷贝包括代码和数据的整个程序到RAM中，也可以只拷贝包含动态变量的数据区到RAM中。一旦启动，系统通过更改程序计数器PC指向映像文件的起始地址，然后交出控制权。

（四个_ main中调用的函数（两个初始化板级外设两个重定位）、八个阶段，若干其他函数）
有时，为了减少映像文件，映像文件会是压缩过的。这种情况下，当映像文件被装载，或当控制权递交给他的时候，映像文件要被解压。zImage就是压缩后的，和Image相比它有头部信息，是解压缩代码。
例1.1 初始化或组织存储器是初始化代码中的一个重要部分，因为许多操作系统在开始运行之前，希望了解存储器的组织情况。
下图中对比存储器在重新组织前/后的情况。对于基于ARM的嵌入式系统来说，通常都会提供存储器重映射，因为它允许系统上电后立刻从ROM中开始运行初始化代码。然后初始化代码HI重新定义或重构存储器映射，把RAM空间放在地址0x00000000。这一步很重要，因为这样异常向量表就在RAM中，并且可以被程序改写了。(要说的话，我就好奇为什么寄存器要映射到存储器上，寄存器并不都在CPU中，比如IO引脚等片上外设的寄存器实际上就是在主存上，所以寄存器可以进行重映射，但是每种ARM工作模式的banked寄存器是在主存上的么)

#### 1.4.2操作系统

初始化过程为操作系统进行控制准备好了硬件。操作系统 组织系统资源：外设、存储器和处理时间。有了操作系统的管理，不同的应用程序在操作系统环境下就可以高效的使用这些资源。

ARM处理器支持超过50种操作系统，可以把操作系统划分为两大类：实时操作系RTOS和平台操作系统。

RTOS保证对事件的响应时间。不同的操作系统对系统的响应时间有不同的控制。一个硬实时的应用需要一个完全被保证的响应时间；相反，一个软实时的应用只需要一个较好的响应时间，但是如果响应超时，则系统性能将会大大下降。运行RTOS的系统通常没有辅助存储器。

平台操作系统需要一个存储管理单元MMU，来管理庞大的非实时应用，而且通常都有辅助存储器。Linux操作系统就是平台操作系统的一个典型例子。

这两类操作系统并非相互排外的，有一些操作系统使用ARM内核，带有内存管理单元，同时也具有实时特性。ARM针对每一类操作系统都已经开发出一系列的处理器核。

#### 1.4.3应用程序

操作系统调度应用程序，为处理某个特定任务的代码。一个应用程序完成一个处理任务；操作系统控制整个运行环境。一个嵌入式系统可以只有一个也可以由多个应用同时运行。

ARM处理器被应用到众多的市场领域，包括网络。然而，在需要尖端高性能的应用中，并没有ARM处理器的身影。这是因为这些应用通常数量很少而成本很高，ARM公司并不以这种类型的应用为目标进行设计。

### 1.5总结

纯粹的RISC是以高性能为主要目标的，但ARM采用的是一种改进的RISC设计思想，目标是较高的代码密度和较低的功耗。。一个嵌入式系统通常包含了一个处理器核，周围有cache、存储器和外设。操作系统控制整个系统，管理应用程序任务。

RISC的设计思想关键是通过简化指令的复杂度来提高性能，使用流水线来加速指令的处理，提供大量的寄存器来存储数据，使用load-store结构。

ARM设计思想也包含了一些非RISC的观念或方法：

- 允许一些特定指令的执行周期数可变，以便降低功耗，减小面积和代码尺寸。
- 增加桶型移位器来扩展某些指令的功能。
- 使用16位的Thumb指令集来提高代码密度。（访问一次只需要16位数据）
- 使用条件执行指令来提高代码密度和性能。（减少分支）
- 使用增强指令来实现数据信号处理的功能。

一个基于ARM的嵌入式系统通常包含以下的硬件组成部分：

- 集成在芯片上的ARM**处理器**；
- 程序员通过存储器映射地址的寄存器访问的**外设**；
- 一种特殊类型的外设也就是**控制器**，使嵌入式系统可实现诸如存储器管理和中断控制等高层功能；
- 片内的AMBA**总线结构**吧处理器和外设连接起来。

一个嵌入式系统包含以下的软件组成部分：

- **初始化代码**配置硬件到一个确定的状态
- 初始化成功后，**操作系统**被装载和执行，操作系统提供了一个通用的编程环境，方便高效使用系统硬件资源
- **设备驱动**给外设提供一个标准的程序接口
- **应用程序**完成嵌入式系统的某个特定任务。

## 第二章、ARM处理器基础

- 寄存器，得弄明白寄存器映射到主存的原理、banked寄存器
- 当前程序状态寄存器、CPSR
- 异常、中断以及向量表。之前讲的标准中断控制器、和向量中断寄存器VIC
- 流水线，ARM的工作方式，并行执行指令的多个部分
- 内核扩展，这是个啥
- 体系结构的不同版本
- ARM处理器系列，之前一直弄混Cortex-M3这些是个啥系列，RISC这是指令集架构
- 总结

第一章介绍了基于ARM处理器的嵌入式系统。本章将重点介绍处理器本身。首先，概述处理器内核以及数据在内核各组成部分之间是如何移动的，从软件开发者角度描述ARM处理器的编程模型，这可以说明处理器内核的功能及其不同部分之间的相互作用；还将介绍基于ARM处理器的内核扩充，内核扩充不仅扩展了指令集，而且有效地组织和加速了主存；还将从ARM内核的命名规则简述ARM内核结构的不同版本re-vision，并将按照时间顺序介绍ARM指令集结构的变化；最后将按照ARM处理器内核系列的分类来介绍其结构实现。

程序员可把ARM内核看做是**由数据总线连接的各功能单元组成的集合**，其实就是CPU，箭头代表了数据的流向，直线代表了总线，方框表示了操作单元或存储区域。下图说明了数据流向，也说明了组成ARM内核的各个逻辑要素。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1677994402464.png" alt="1677994402464" style="zoom: 50%;" />

其中的ALU是算术逻辑单元，这个图没看懂，感觉和计组中提到的CPU组成部分不一样。

数据通过数据总线进入处理器核，这里所指的数据可能是一条要执行的指令或一个数据项。上图显示了一个冯诺依曼结构的ARM实现，数据和指令共享同一个总线；与此相反，哈佛结构的ARM实现两条不同的总线，地址的编写方式都不是一致的。

指令译码器在指令执行前先将他们翻译。每一条可执行指令都属于一个特定的指令集。(那需要多少个指令集啊)

与所有的RISC处理器一样，ARM处理器采用load-store体系结构。意味着只有两种类型的指令用于把数据移入/移出处理器：load指令从存储器复制数据到内核的寄存器；反过来，store指令从寄存器里复制数据到存储器。没有直接操作存储器数据的数据处理指令，因此，数据处理只能在寄存器里进行。

数据项存储在寄存器文件里，一组32位的寄存器存储体（storage bank）这里提到了bank，由于ARM内核是32位处理器，大部分指令认为寄存器中保存的是32位有符号或无符号数。当从存储器读取数据至一个寄存器时，**符号扩展硬件**会把8位和16位的有符号数转换成32位。

典型的ARM指令通常有2个源寄存器Rn和Rm、1个结果或目的寄存器Rd。源操作数分别通过内部总线A和B从寄存器文件中读出。

ALU算术逻辑单元或MAC乘累加单元（计组中没提到这个，提到了累加器ACC）通过总线A和B得到寄存器值Rn和Rm，并计算出一个结果。**数据处理指令直接把Rd中的计算结果写到寄存器文件**。**load-store指令使用ALU来产生一个地址，这个地址将被保存到地址寄存器并发送到地址总线上**。

ARM的一个重要特征是，**寄存器Rm可以选择在进入ALU前是否先经过桶型移位器**预处理，桶形移位器和ALU协作可以计算较大范围的表达式和地址。

在经过有关功能单元后，Rd寄存器里的结果值通过结果总线（result bus）写回寄存器文件。（头一次听过这个结果总线）。对于load-store指令，在内核从下一个连续的存储器单元装载数据到下一个寄存器，或写下一个寄存器的值到下一个连续的存储器单元之前，地址加法器会自动更新地址寄存器。处理器连续执行指令，直到发生异常或中断而改变了正常的执行流。（计组中是程序计数器通过自加获得下一个指令的地址，这里的地址寄存器MAR怎么也通过加法器自加来获得下一个操作的存储单元）

对处理器内核有了总体认识后，接下来将详细介绍处理器的各关键部件：寄存器、当前程序状态寄存器CPSR以及流水线。进程上下文中的寄存器上下文中就有CPSR、通用寄存器(31)、PC、栈指针ESP

### 2.1寄存器

这一小节很有帮助，之前没有深入了解过寄存器到底是个啥，只知道在CPU中，SRAM组成。

通用寄存器可保存数据和地址。他们用字母r为前缀加该寄存器的序号来标识。例如寄存器4可表示为r4。下图中列出了在用户模式下的有效活动寄存器（user mode，一种受限模式，通常用于执行应用程序）。处理器可以在7种不同的模式下运行，所有的寄存器都是32位的。

最多可有18个活动寄存器：16个数据寄存器和2个处理器状态寄存器。程序员可见的数据寄存器是r0~r15。

ARM处理器为特殊的任务或专门的功能指定了3个寄存器：r13、r14和r15。他们通常被赋予不同的标识，以区分其他寄存器。

- 寄存器r13通常用作堆栈指针sp，保存当前处理器模式的堆栈的栈顶，是esp栈顶指针的低16位。
- 寄存器r14又被称为链接寄存器lr，**保存调用子程序的返回地址**。其实就是作为PC寄存器的备份，当子程序执行完把lr的内容返回给PC。
- 寄存器r15是程序计数器pc，其内容是处理器要取的下一条指令的地址。

根据具体的应用场景，寄存器r13和r14也可以用作通用寄存器，有时这特别有用，因为在处理器模式改变时，这些寄存器是被**分组备份**的（r0-r7是未分组的所有模式下都指向同一个物理寄存器，r8-r14是分组的），把r13当做通用寄存器是很危险的，操作系统通常认为r13始终指向一个有效的栈结构。

在ARM状态下，寄存器r0~r13是正交的，也就是任何指令如果可使用r0，那么就可以使用其他寄存器。但是，有些指令是以特殊的方式来对待r14和r15的。

除了16个数据寄存器，还有两个程序状态寄存器：cpsr和spsr(分别是当前和备份的程序状态寄存器)。后者是异常模式下才有的。

寄存器文件包含所有程序员可利用的寄存器。哪些寄存器对程序员可见，取决于当前的处理器模式。

ARM内核使用cpsr来监视和控制内部的操作。cpsr是寄存器文件中一个专用的32位寄存器。下图说明了一般程序状态寄存器的基本格式。

cpsr分为四个八位区域：标志域、状态域、扩展域和控制域。在目前的设计中，扩展和状态域保留，以便将来使用。控制域包括处理器模式、状态和中断屏蔽位；标志域包含条件标志位。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678079779497.png" alt="1678079779497" style="zoom:33%;" />

之前的异常流程中就提到了修改cpsr中的处理器模式，指的就是mode位。一些ARM处理器内核有额外的位分配。例如，在标志域里的J位只存在于Jazelle使能的处理器中，该类处理器可执行8位的指令。在未来的设计中，极有可能为新功能的监测和控制分配额外的位。

#### 2.2.1处理器模式

处理器模式决定了哪些寄存器是活动的以及对cpsr的访问权。（系统和用户模式无法访问spsr）处理器模式要么是特权模式要么是非特权模式。特权模式允许对cpsr的**完全读/写访问**。非特权模式只允许对**cpsr的控制域进行读访问**，但允许对**条件标志的读写访问**。（非特权模式只有用户模式）

具体共有7种处理器模式。6种特权模式：终止abort模式（这是访问不可访问地址触发）、系统模式、管理模式SVC（上电、软中断）、一般中断IRQ、快速中断FIQ、未定义undefined模式（译码阶段就属于未定义）；一种非特权模式，用户模式

- 当处理器访问存储器失败时，进入数据访问终止模式
- 中断模式和快速中断模式分别对ARM处理器两种不同级别的中断作出响应；
- 处理器复位之后，进入管理模式，操作系统内核也通常处于这种模式
- 系统模式是一种特殊的用户模式，允许对CPSR的完全读写访问；
- 当处理器遇到没有定义的指令，或者不支持的指令时，进入未定义模式；
- 用户模式运行应用程序。

#### 2.2.2分组寄存器

下图列出了寄存器文件中所有37个寄存器。当然，在不同的时刻有20个寄存器对**程序是隐藏的。这些寄存器被称为分组寄存器**。只有当处理器处于某种特定模式时，才有效。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678081059205.png" alt="1678081059205" style="zoom:33%;" />

可以看到r0-r7是未分组寄存器，所有模式可见，r8-r14是分组寄存器，特定的模式可见。

除用户模式外，每一种处理器模式都可通过改写cpsr中的模式位来改变。

除系统模式外，所有处理器模式都有一组各自的分组寄存器，他们是16个主要寄存器的子集，每个分组寄存器与一个用户模式的寄存器对应。如果改变处理器的模式，新模式的一个分组寄存器将取代原来模式的分组寄存器。

这也是快速中断为什么比普通中断响应更快的理由，因为有更多自己专属的寄存器，不需要保存现场了。

比如当处理器处于中断模式时，执行的指令仍然可访问名字是r13和r14的寄存器，但实际上他们是分组寄存器r13_irq和r14_irq。**用户模式的r13_usr和r14_usr不会受到影响**。程序仍然可以正常访问寄存器r0~r12。

处理器模式既可以通过**程序直接改写cpsr**(处理器内核必须处于特权模式)来切换，也可以当内核的异常或中断响应时**由硬件切换**。下面的异常和中断会导致模式切换：复位、外设中断请求、快速中断请求、软件中断、数据访问中止、预取指中止和未定义指令。

异常和中断将挂起顺序指令的正常执行。并跳转到一个特定的地址。下图显示了当一个中断导致模式切换时所发生的情况。当一个外设向处理器核发出中断请求而产生中断时，内核从用户用户模式切换到中断模式。这个改变**使得用户寄存器r13和r14被保护**。用户寄存器r13和r14分别被寄存器r13_irq和r14_irq所代替。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678082397341.png" alt="1678082397341" style="zoom:33%;" />

异常导致的**将cpsr拷贝到spsr**。根据异常类型，**强制设置CPSR的处理器模式位**，强制PC从相关的异常向量地址取下一条指令执行，从而跳转到相应的异常处理程序。

r14_irq是保存了中断程序的返回地址，r13_irq保存的是中断模式的堆栈指针。

下图中也显示了在中断模式中的一个新寄存器：备份程序状态寄存器spsr，保存了先前处理器模式的cpsr。从图中可以看到，cpsr被复制到spsr_irq。为了回到用或是，需要使用一条特殊的返回指令，指示内核从spsr_irq恢复原来的cpsr，同时切换回先前受板胡的用户寄存器r13和r14。

只能在特权模式下修改和修改spsr，**用户模式下没有spsr**。

另一个值得注意的特点是，**当通过程序直接改写cpsr来切换模式时，cpsr不会被复制到spsr。只有当一个异常或中断发生时，才保存cpsr。**

当前活动的**处理器模式占据cpsr的低5位**。上电后从管理模式开始。从一个特权模式开始是很有用的，因为**初始化代码可以完全访问cpsr，以设置其他各模式的堆栈。**

下表列出了各种处理器模式，最后一列给出了cpsr中代表每一种处理器模式的二进制码。

| 模式     | 缩写 |      | 特权 | 模式位[4,0] |
| -------- | ---- | ---- | ---- | ----------- |
| 中止     | abt  | 是   | 是   | 101111      |
| 一般中断 | irq  | 是   | 是   | 10010       |
| 快速中断 | fiq  | 是   | 是   | 10001       |
| 未定义   | und  | 是   | 是   | 11011       |
| 管理     | svc  | 是   | 是   | 10011       |
| 系统     | sys  | 否   | 是   | 11111       |
| 用户     | usr  | 否   | 否   | 10000       |

#### 2.2.3状态和指令集

内核的状态决定了处理器将执行哪种指令集。（之前对于指令集接触太少了。）有三种指令集：ARM、Thumb和Jazelle。只有当处理器处于ARM状态时，ARM指令集才有效；同样，只有当处理器处于Thumb状态时，Thumb指令才有效。一旦处于Thumb状态，处理器就纯粹执行16位的Thumb指令。不能把ARM，Thumb和Jazelle指令混合使用。

在cpsr中的控制域中的J和T位反应了处理器的状态。当T位和J位为零时，处理器处于ARM状态，执行ARM指令，这是处理器**上电时的默认状态**。若T位置位，则处理器处于Thumb状态，为了改变状态，内核要执行专门的分支指令。（CPSR中的标志域中有用来表示处理器状态的标志位，而控制域中有中断屏蔽位、处理器模式）。

表2.2对ARM和Thumb指令集的特征做了比较。

| 项目           | ARM(cpsr T=0)       | Thumb(cpst T=1)              |
| -------------- | ------------------- | ---------------------------- |
| 指令长度       | 32位                | 16位                         |
| 内核指令       | 58条                | 30条                         |
| 条件执行       | 大多数指令          | 只有分支指令                 |
| 数据处理指令   | 访问桶型移位器和ALU | 独立的桶型移位器和ALU指令    |
| 程序状态寄存器 | 特权模式下可读/写   | 不能直接访问                 |
| 寄存器使用     | 15个通用寄存器+pc   | 8个通用寄存器+7个高寄存器+pc |

ARM设计者引进了第三种指令集，被称为Jazelle。Jazelle执行8位指令，他是一个软件和硬件的混合体，能够加速Java字节码(bytecodes)的执行。（这里提到了Java，原来高级语言和ARM也有直接的关系）。

为了执行Java字节码，需要Jazalle技术外加一个Java虚拟机的特殊修订版。特别要注意的是，**Jazelle的硬件部分只支持Java字节码的一个子集**，其余的由软件仿真。

Jazelle指令集是一个封闭的指令集，没有公开。下表给出了Jazelle指令集的一些特征。

| 项目     | Jazelle(cpsr T=0,J=1)                             |
| -------- | ------------------------------------------------- |
| 指令长度 | 8位                                               |
| 内核指令 | 硬件完成超过60%的Java字节代码，其余代码由软件完成 |

#### 2.2.4中断屏蔽

中断屏蔽位用来禁止某些中断请求来中断处理器。ARM处理器内核有2个级别的中断请求，中断请求IRQ和快速中断请求FIQ。（中断处理分为标准的中断控制器和VIC中断向量寄存器，这两个是硬件，用来接收外设发送的中断信号，而这里的cpsr中的中断屏蔽位是用来屏蔽处理器模式中的两种中断模式的）
cpsr的控制域有2个中断屏蔽位，位7和位6（I和F）他们分别控制IRQ和FIQ的中断屏蔽。I位设置为1时，屏蔽IRQ；同样，F为置位1，屏蔽FIQ。（EXTI控制器是ST自己加的，所以ARM架构中不曾体现，只有NVIC，对于ARMv7-A系列采用的是GIC）
#### 2.2.5条件标志
条件标志是由比较指令或带有后缀S的ALU操作结果来设置。比如，如果一条SUBS减法指令产生了一个结果为0的寄存器值，那么cspr中的Z标志就被置位。
在有DSP扩展的ARM内核中，Q位表示增强的DSP指令是否发生了溢出或饱和。该位由硬件自动设置，不能由硬件自动清除。要清除这一位，必须由软件直接写cpsr。
在有Jazelle扩展的处理器中，J位反映了内核的状态：若置位，则内核处于Jazelle状态。J位并不是都有用的，它只对于某些处理器内核有效。**为了使用Jazelle，需要从ARM公司和Sun Microsystem公司获得许可，以得到额外的软件。**
大多数ARM指令可根据条件标志位进行条件执行。下表列出了各条件标志位以及如何产生置位的简短说明。**这些标志位位于cpsr的高5位**，被用于条件执行。

| 标志位 | 标志名 | 置位条件                    |
| ------ | ------ | --------------------------- |
| Q      | 饱和   | 结果导致一个溢出和/或饱和   |
| V      | 溢出   | 结果导致一个有符号数溢出    |
| C      | 进位   | 结果导致一个无符号数进位    |
| Z      | 零     | 结果是0，常用在指示相等与否 |
| N      | 负数   | 结果的第31位为1             |

下图给出了对于具有DSP扩展和Jazelle的cpsr典型值。本书中将采用符号来表示cpsr的值，以便阅读。如果某一位置1，则用大写字母表示；若某一位为0，则用小写字母表示该中断被禁止。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678428433410.png" alt="1678428433410" style="zoom:50%;" />

无符号数进位，不采用Jazelle和Thumb状态，所以说ARM，屏蔽FIQ，处理器模式是管理模式。（这部分挺有用的，只是看cpsr就知道处理器当前的相关信息）

#### 2.2.6条件执行

条件执行控制内核是否将会执行一条指令。大多数指令都有一个**条件属性**，再**根据条件标志位的情况，决定内核是否执行该指令**。在执行前，处理器比较该**条件属性和CPSR的条件标志位**：如果匹配，指令就被执行，否则指令被忽略。

条件属性作为指令助记符的后缀被编码进指令。下表给出了条件执行代码助记符。若没有条件符号，则默认为无条件AL执行。

| 助记符 | 名称                        | 条件标志位 |
| ------ | --------------------------- | ---------- |
| EQ     | 相等                        | Z          |
| NE     | 不相等                      | z          |
| CS HS  | 进位置位/无符号数大于或等于 | C          |
| CC LO  | 进位清除/无符号数小于       | c          |
| MI     | 负数                        | N          |
| PL     | 非负数                      | n          |
| VS     | 溢出                        | V          |
| VC     | 无溢出                      | v          |
| HI     | 无符号大于                  | zC         |
| AL     | 无条件执行                  | 忽略       |
| LS     | 无符号数小于或者等于        | Z或c       |
| GE     | 有符号数大于或等于          | NV或nv     |
| LT     | 有符号数小于                | Nv或nV     |
| GT     | 有符号数大于                | NzV或nzv   |
| LE     | 有符号数小于或等于          | Z或Nv或nV  |



### 2.3流水线

流水线是RISC处理器执行指令时采用的机制。使用流水线，可在取下一条指令的同时译码和执行其他指令，从而加快执行速度。可以把流水线看做是汽车生产线，每个阶段只完成一项专门的生产任务。

下图显示了三级流水线：

- 取指(fetch)-从存储器装载一条指令；
- 译码(decode)-识别将被执行的指令；
- 执行(excute)-处理指令并把结果写回寄存器；

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678430901565.png" alt="1678430901565" style="zoom:50%;" />

下图通过一个简单的例子说明了流水线的机制。在第一个周期，内核从存储器取出指令ADD；在第二个周期，内核取出指令SUB，同时对ADD指令译码；在第三个周期，指令SUB和ADD都沿流水线移动，ADD指令被执行，而SUB指令被译码，同时又取出CMP指令。流水线使得每个时钟周期就可以执行一条指令。

随着流水线深度的增加，每一段的工作量被削减了，这使得处理器可以工作在更高的频率，同时也改善了性能。（减少时钟周期的长度，就是提高了时钟的频率）但系统延时latency同样也增加了，这是**因为在内核执行一条指令前，需要更多的周期来充填流水线**。流水线级数的增加也意味着在某些段之间会产生数据相关。可使用指令调整技术来编写代码，以减少数据相关。

这一段话没看懂。系统延时指的就是执行指令前填充流水线的时间。这里因为需要更多的指令周期，所以系统延时增加了。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678598283845.png" alt="1678598283845" style="zoom: 33%;" />

这个图感觉也有点问题，当前PC保存的是正在执行的指令的下一个指令。

每种ARM系列的流水线设计都有差异。例如，ARM9内核把流水线深度增加到5级。下图所示，ARM9增加了存储器访问段和回写段，这使得ARM9的处理能力可达到平均1.1Dhrystone MIPS/MHz，表示每秒可执行1.1百万条指令数。指令吞吐量增加了约13%，同时ARM9的内核能达到的最高频率也更高。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678598767066.png" alt="1678598767066" style="zoom:50%;" />

ARM10更是把流水线的深度增加到6级，下乳所示，ARM的平均处理能力可达到1.3Dhrystone MIPS/MHz，与ARM7相比，指令吞吐量提高了约34%；但同样有较大的系统延时。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678598955841.png" alt="1678598955841" style="zoom: 50%;" />

虽然ARM9和ARM10的流水线不同，但他们使用了与ARM7相同的流水线执行机制，**因此ARM7上的代码也可以在ARM9和ARM10上运行。**

##### 流水线执行的特点

ARM流水线的一条指令只有在完全通过执行阶段才被处理。比如一条ARM7流水线只有在取第四条指令的时候，第一条指令才完成执行。

下图反映了ARM7流水线上的指令顺序。MSR指令用来使能IRQ中断，只有在MSR指令完成流水线的执行阶段后才有效。它清除cpsr中的1位来使能IRQ中断，也就是说，一旦下一条指令ADD进入执行阶段，IRQ中断也就被使能了。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678599612943.png" alt="1678599612943" style="zoom:33%;" />

下图显示了流水线以及程序计数器pc的使用情况，在指令执行阶段，pc总是指向该指令地址加八字节的地址。一条指令是32位，需要占据4字节，所以8字节是pc总是指向当前正在执行的指令的地址下下条指令的地址。这是针对三级流水线的。当用pc来计算一个相对偏移量时，这一点很重要的，并且它也是所有流水线的结构特征。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678600325576.png" alt="1678600325576" style="zoom:33%;" />

当处理器处于Thumb模式时，pc的值为正在执行指令的地址加4。这是因为Thumb模式的指令是16位的，两个指令只需要4个字节。

另外，有说那个值得注意的流水线特征：

1. 执行一条分支指令或直接修改pc而发生跳转时，会使ARM内核**清空流水线**；
2. ARM10使用**分支预测技术**，通过预测可能的分支并在指令执行前装载新的分支地址，从而减小了清空流水线的影响；（这里没看懂，linux内核源码中也提到过分支预测的内容）
3. 即使产生了一个中断，一条**处于执行阶段的指令也将完成**。流水线里**其他指令将会被放弃**，而处理器将会从向量表的适当入口开始填充流水线。

### 2.4异常、中断及向量表

当一个异常或中断发生时，处理器会把PC设置为一个特定的存储器地址。这一地址放在一个被称为向量表vector table的特定的地址范围内。向量表的入口是一些跳转指令跳转到专门处理某个异常或中断的子程序。（这里的向量表是软件上的，是一系列指令，而VIC中断向量寄存器是硬件，和标准的中断控制器一样都是硬件电路）

存储器映射地址0x00000000是为向量表保留的。在某些处理器中，向量表可以选择定位在存储空间的更高地址。操作系统，比如Linux和Microsoft的嵌入式操作系统就可以利用这一特性。

当一个异常或中断发生时，处理器挂起正常的执行，转而从向量表装载指令。每一个向量表入口包含一条指向一个特定子程序的跳转指令。

| 异常/中断           | 缩写  | 地址       | 高位地址   |
| ------------------- | ----- | ---------- | ---------- |
| 复位（SVC模式）     | RESET | 0x00000000 | 0xffff0000 |
| 未定义指令(UND模式) | UNDEF | 0x00000004 | 0xffff0004 |
| 软件中断(SVC模式)   | SWI   | 0x00000008 | 0xffff0008 |
| 预取指中止(ABT模式) | PABT  | 0x0000000c | 0xffff000c |
| 数据终止(ABT模式)   | DABT  | 0x00000010 | 0xffff0010 |
| 保留                | --    | 0x00000014 | 0xffff0014 |
| 中断请求(IRQ模式)   | IRQ   | 0x00000018 | 0xffff0018 |
| 快速中断请求        | FIQ   | 0x0000001c | 0xffff001c |

所谓的向量表指的就是五种异常模式。

- 复位向量是处理器上电后执行的第一条指令的位置。这条指令**使处理器跳转到初始化代码处**。
- 未定义指令向量是在处理器**不能对一条指令译码**时使用的。
- 软件中断向量是执行SWI指令时被调用的，SWI经常被用作**调用一个系统调用的机制**。用来陷入内核态。
- 预取指中止向量发生在处理器试图从一个未获得正确访问权限的地址去取指时，**实际上中止发生在译码阶段**。（也就是说取指会成功，而译码会失败）
- 数据中止向量与预取指中止类似，发生在一条指令试图**访问未获得正确访问权限的数据存储器**时。
- 中断请求向量是用于外部硬件中断处理器的正常执行流。只有当cpsr中的**IRQ位未被屏蔽**时才能发生。
- 快速中断请求向量类似于中断请求，是为要求更短的中断响应时间的硬件保留的，只有当CPSR中的**FIQ位未被屏蔽**时才能发生。

###  2.5内核扩展

本节包含的硬件扩展是置于ARM内核外围的标准组件。他们可以改善性能，管理资源以及提供额外的功能，为处理特殊的应用提供了灵活性。每个ARM系列都有不同的扩展。

有三种硬件扩展位于内核周围；**cache**和**存储器**TCM(Tightly Coupled Memory)、**存储管理及协处理器接口**。

#### 2.5.1cache和紧耦合存储器

cache是位于主存储器和内核之间的快速存储器。它允许从某些存储器中更高效地取指。有了cache，处理器内核就能够在**大多数时间全速运行而无须等待低速的外部存储器访问**。大多数基于ARM的嵌入式系统使用处理器内部的一级cache，也有许多小的嵌入式不需要cache带来的性能上的改善。

ARM有两种形式的cache，第一种形式是针对冯诺依曼结构的内核。他把数据和指令放在一个统一的cache里，下图所示，为了简单起见，把存储器与AMBA总线架构连接部分统称为逻辑与控制。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678684863478.png" alt="1678684863478" style="zoom:33%;" />

第二种形式是针对哈佛结构的内核，有独立的指令cache和数据cache。

cache改善了系统的整体性能，但也使得程序的执行时间变得不可预测。对于实时系统来说，代码执行的确定性，装载和存储指令或数据的时间必须是可预测的，这一点至关重要。（学实时操作系统的实时性如何保证，借助实时调度器严格按照时间片运行，现在看来和硬件也有关系）

使用称为紧耦合存储器TCM的存储器就可以实现。TCM是一种快速SRAM，他紧挨着内核，并且**保证取指或数据操作的时钟周期数**。这对于一些要求确定行为的实时算法是很重要的。TCM位于**存储器地址映射中**，可作为快速存储器来访问，一个带TCM的处理器内核的例子如下图所示。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678685784175.png" alt="1678685784175" style="zoom:33%;" />

把上述两项技术结合，ARM处理器既能够改善性能，又能够获得可预测的实时响应。不过我很好奇，为什么两者结合就行了呢，TCM技术为什么可以保证可预测的取指和数据操作的时钟周期数。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678685924560.png" alt="1678685924560" style="zoom:33%;" />

#### 2.5.2存储管理

嵌入式系统通常使用多个存储设备，因此有必要实时某种策略来组织管理这些设备，并保护系统，避免一些应用非法访问硬件。可以使用存储器管理硬件来实现这些功能。

ARM内核的存储器管理硬件有3种不同类型：没有提供扩展，没有硬件保护（无保护）；提供有限保护的存储器保护单元MPU；提供全面保护的存储器管理单元MMU。（所以MMU本身就是用来管理存储器的，不仅仅是实现虚实结合从而提供逻辑地址）

- 无保护存储器是固定的，只能提供非常有限的灵活性。它通常用于小的、简单的嵌入式系统，这种系统由于其应用特点而不要求存储器保护。
- MPU使用一个只用到少量存储区域的简单系统。这些区域由一组特殊的协处理器寄存器控制，（cache也是通过一组协处理器管理的cp15，上电的时候还没有使用协处理器所以要关闭数据寄存器）**每一个区域定义了专门的访问权限**。这种类型的存储器管理，适用于要求**有存储器保护但没有复杂存储器映射**的系统。
- MMU是ARM上最广泛的存储器管理硬件。MMU使用一组转化表，以提供精细的存储器控制。这些表保存在主存里，并且提供虚拟地址与物理地址的映射和访问权限。MMU适用于支持多任务的复杂操作系统平台。

之前从来没有提到过TCM紧耦合存储器。

#### 2.5.3协处理器

协处理器可以附属于ARM处理器。一个协处理器通过扩展指令集（协处理器有着自己的指令添加到主存中，到时候识别出是协处理器的指令然后交给协处理器执行）或提供配置寄存器来扩展内核处理功能。一个或多个协处理器可以通过协处理器接口与ARM内核相连。

协处理器可以通过一组专门的、提供load-store类型接口的ARM指令来访问。例如协处理器15CP15，ARM处理器使用协处理器15的寄存器来控制cache、TCM和存储器管理。

协处理器也能通过提供一组专门的新指令来扩展指令集。比如有一组**专门的指令可以添加到标准ARM指令集**中为了**处理向量浮点VFP运算**。

**这些新指令是在ARM流水线的译码阶段被处理的，如果在译码阶段发现是一条协处理器指令，则把他送给相应的协处理器。如果该协处理器不存在，或不认识这条指令，则ARM认为发生了未定义指令异常。**这也使得编程者可以用软件来仿真协处理器的行为。（这就是为什么译码阶段会导致进入未定义工作模式的原因）。

### 2.6体系结构的不同版本

每个ARM处理器都有一个特定的指令集架构ISA，而一个ISA版本又可以有多种处理器实现。ISA随着嵌入式市场的需求而发展。ARM公司精心规划该发展过程，使得在较早的架构版本上编写的代码也可以在后继版本上执行。

在解释ISA的发展过程前，我们先来介绍ARM处理器的命名规则。命名规则确定了处理器具有的相关功能特性。

#### 2.6.1命名规则

ARM使用如图的命名规则来描述一个处理器，在ARM后的字母和数字表明了一个处理器的功能特性。随着更多特性的增加，将来字母和数字的组合可能会改变。注意：命名规则不包含体系结构的版本信息。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1678688512607.png" alt="1678688512607" style="zoom:33%;" />

关于ARM命名规则，还有一些附加的要点：

- ARM7TDMI之后的所有ARM内核，即使ARM标志后没有包含那些字符，也都包括了TDMI的功能特性。
- 处理器系列是共享相同硬件特性的一组处理器的具体实现。例如，ARM7TDMI，ARM740T和ARM720T都共享相同的系列特性，都属于ARM7系列。
- JTAG是由IEEE1149.1标准测试访问端口(standard test access port)和边界扫描结构来描述的。他是ARM用来**发送和接收处理器内核与测试仪器之间调试信息的一系列协议**。
- 嵌入式ICE宏单元(EmbeddedICE macrocell)是**建立在处理器内部、用来设置断点和观察点的调试硬件**。（STlink的调试原理是建立在处理器上的）
- 可综合的，意味着处理器内核是以源代码形式提供的。这种源代码形式又可以被编译成一种易于EDA（电路板开发平台）工具使用的形式。

#### 2.6.2体系结构的发展

自从第一个ARM处理器于1985年问世以来，ARM体系结构一直在发展。下表给出了从最初的体系结构版本1到现在的版本6的那些显著的增强。ISA最明显变化之一是在ARMv4T(ARM7TDMI处理器)中引入了Thumb指令集。

| 版本     | 内核实现范例     | ISA增强                                  |
| -------- | ---------------- | ---------------------------------------- |
| ARMv1    | ARM1             | 第一个ARM处理器                          |
|          |                  | 26位寻址                                 |
| ARMv2    | ARM2             | 32位乘法器                               |
|          |                  | 32位协处理器支持                         |
| ARMv2a   | ARM3             | 片上cache                                |
|          |                  | 原子交换指令                             |
|          |                  | 协处理器15用于cache管理                  |
| ARMv3    | ARM6和ARM7DI     | 32位寻址                                 |
|          |                  | 独立的cpsr和spsr                         |
|          |                  | 新增模式，未定义指令和中止模式           |
|          |                  | MMU支持-虚拟存储                         |
| ARMv3M   | ARM7M            | 有符号和无符号长乘法指令                 |
| ARMv4    | StrongARM        | 有符号和无符号半字和字节的load-store指令 |
|          |                  | 新增模式-系统模式                        |
|          |                  | 为体系结构上定义的操作而保留SWI空间      |
|          |                  | 不再支持26位寻址模式                     |
| ARMv4T   | ARM7TDMI和ARM9T  | Thumb                                    |
| ARMv5TE  | ARM9E和ARM10E    | ARMv4T的超集                             |
|          |                  | 增加ARM和Thumb状态之间切换的额外指令个   |
|          |                  | 增强乘法指令                             |
|          |                  | 额外的DSP类型指令                        |
|          |                  | 快速乘累加                               |
| ARMv5TEJ | ARM7EJ和ARM926EJ | Java加速                                 |
| ARMv6    | ARM11            | 改进的多处理器指令                       |
|          |                  | 边界不对称和混合大小端数据的处理         |
|          |                  | 新的多媒体指令                           |

ARMv表示的是ARM版本，而ARM表示的是具体的内核实现范例。

下表总结了程序状态寄存器的各个部分及其在特定指令架构上对应功能的有效性。全部指的是ARMv4及其以上的体系结构。

| 部分   | 位   | 架构     | 描述        |
| ------ | ---- | -------- | ----------- |
| 模式位 | 4:0  | 全部     | 处理器模式  |
| T      | 5    | ARMv4T   | Thumb状态   |
| I&F    | 7:6  | 全部     | 中断屏蔽位  |
| J      | 24   | ARMv5TEJ | Jazelle状态 |
| Q      | 27   | ARMv5TE  | 条件标志位  |
| V      | 28   | 全部     | 条件标志位  |
| C      | 29   | 全部     | 条件标志位  |
| Z      | 30   | 全部     | 条件标志位  |
| N      | 31   | 全部     | 条件标志位  |

### 2.7ARM处理器系列

ARM公司设计了许多处理器，它们可以根据使用内核的不同划分到各个系列中。系列划分是基于ARM7,ARM9,ARM10,ARM11内核。后缀数字791011表示不同的内核设计。数字的升序说明性能和复杂度的提高。ARM8开发出来以后很快就被取代了。

下表显示了ARM7/ARM9/ARM10及ARM11内核之间一个粗略的属性比较。其所列的一些数据可能会有较大变化，这依赖于生产过程的类型和工艺，他们对工作频率MHz和功耗W也会产生直接影响。

| 项目         | ARM7       | ARM9       | ARM10     | ARM11     |
| ------------ | ---------- | ---------- | --------- | --------- |
| 流水线深度   | 3级        | 5级        | 6级       | 8级       |
| 典型频率/MHz | 80         | 150        | 250       | 335       |
| mW/MHz       | 0.06mW/MHz | 0.19mW/MHz | 0.5mW/MHz | 0.4mW/MHz |
|              |            | +cache     | +cache    | +cache    |
| MIPS         | 0.97       | 1.1        | 1.3       | 1.2       |
| 架构         | 冯诺依曼   | 哈佛       | 哈佛      | 哈佛      |
| 乘法器       | 8*32       | 8*32       | 16*32     | 16*32     |

在每个系列中，存储器管理、cache和TCM等处理器扩展也有多种变化，ARM继续在可用的产品系列和每个系列内部的不同变种两方面做进一步开发。

还有一些执行ARM ISA的（特定的指令集架构）处理器，比如StrongARM和XScale，这些处理器是由特定的半导体公司独家生产的。

下表总结了各种处理器的不同功能特性。下面将从ARM7系列开始，依次就ARM系列做进一步的说明。

| CPU核(ARM的) | MMU/MPU | cache                  | Jazelle | Thumb | ISA(指令级架构，也就是ARM版本) | E(增强的乘法指令和饱和运算指令) |
| ------------ | ------- | ---------------------- | ------- | ----- | ------------------------------ | ------------------------------- |
| ARM7TDMI     | 无      | 无                     | 否      | 是    | v4T                            | 否                              |
| ARM7EJ-S     | 无      | 无                     | 是      | 是    | v5TEJ                          | 是                              |
| ARM720T      | MMU     | 统一的8Kcache          | 否      | 是    | v4T                            | 否                              |
| ARM920T      | MMU     | 独立的16K/16K D+Icache | 否      | 是    | v4T                            | 否                              |
| ARM922T      | MMU     | 独立的8K/8K D+Icache   | 否      | 是    | v4T                            | 否                              |
| ARM926EJ-S   | MMU     | 独立的cache与TCM可配置 | 是      | 是    | v5TEJ                          | 是                              |
| ARM940T      | MPU     | 独立的4K/4K D+Icache   | 否      | 是    | v4T                            | 否                              |
| ARM946E-S    | MPU     | 独立的cache和TCM可配置 | 否      | 是    | v5TE                           | 是                              |
| ARM966E-S    | 无      | 独立的cache和TCM可配置 | 否      | 是    | v5TE                           | 是                              |
| ARM1020E     | MMU     | 独立的32K/32KD+Icache  | 否      | 是    | v5TE                           | 是                              |
| ARM1022E     | MMU     | 独立的16K/16KD+Icache  | 否      | 是    | v5TE                           | 是                              |
| ARM1026EJ-S  | MMU     | 独立的cache与TCM可配置 | 是      | 是    | v5TE                           | 是                              |
| ARM1036J-S   | MMU     | 独立的cache与TCM可配置 | 是      | 是    | v6                             | 是                              |
| ARM1136JF-S  | MMU     | 独立的cache与TCM可配置 | 是      | 是    | v6                             | 是                              |

#### 2.7.1ARM7系列

ARM7内核是冯诺依曼体系结构，数据和指令使用同一条总线。内核有一条3级流水线，执行ARMv4指令集。

ARM7TDMI是ARM公司于1995年退出的新系列中的第一个处理器内核。是目前一个非常流行的内核，已被用在许多32位嵌入式处理器上。它提供了非常好的性能：功耗比，ARM7TDMI处理器内核已经许可给许多世界顶级半导体公司，他是第一个包括Thumb指令集、快速乘法指令和嵌入式ICE调试技术的内核。

ARM7系列中一个重要的变化是ARM7TDMI-S与标准ARM7TDMI有相同的操作特性，但他是可综合的。之前提到过。

ARM720T是ARM7系列中最具灵活性的成员，因为它包含了一个MMU。MMU的存在意味着ARM720T能够处理Linux和Microsoft嵌入式操作系统，这一处理还包括了8KB的统一cache。向量表通过设置一个协处理器15寄存器来重定位到更高的地址。

另一个成员是**ARM7EJ-S**处理器，也是可综合的。与其他ARM7处理器有很大不同，因为他有一条**5级流水线**，并且执行ARMv5TEJ指令（v5表示版本号，这是指令集架构）。这个版本是ARM7中**唯一一个提供Java加速和增强指令，而没有任何存储器保护**的处理器。

#### 2.7.2ARM9系列

ARM9系列于1997年问世，由于**采用了5级指令流水线**，ARM9处理器能够运行在比ARM7更高的时钟频率上，改善了处理器的整体性能；存储器系统根据哈佛体系结构重新设计，**区分了数据D和指令I总线**。

ARM9系列的第一个处理器是ARM920T，包含独立的D+Icache和一个MMU。这个处理器能够被用在要求有虚拟存储器支持的操作系统上。ARM922T是ARM920T的变种，只有**一半大小的D+Icache**。

ARm940T包括一个更小的D+Icache和一个MPU。他是针对不要求运行平台操作系统的应用而设计的。ARM920T和ARM940T都执行v4T架构指令。

ARM9系列的下一个处理器是基于ARM9E-S内核的。这个内核是ARM9内核带有E扩展的一个可综合版本。它有2个变种；ARM946E-S和ARM966E-S。两者都执行v5TE架构指令。他们也支持可选的嵌入式跟踪宏单元ETM，允许开发者实时跟踪处理器上指令和数据的执行。当调试对时间敏感(time-critical)的程序段时，这种方法非常重要。

ARM946E-S包括TCM/cache和一个MPU。TCM和cache的大小可配置。该处理器是针对要求有确定的实时响应的嵌入式控制应用而设计的。而ARM966E有可配置的TCM，但没有MPU和cache扩展。

ARM9产品线的最新内核是ARM926EJ-S可综合的处理器内核，发布于2000年。它是针对小型便携式Java设备，诸如3G手机和个人数字助理PDA应用而设计的。ARM926EJ-S是第一个包含Jazelle技术（可加速Java字节码的执行）的ARM处理器内核。他还有一个MMU、可配置的TCM以及具有零或非零等待存储器的D+Icache。

#### 2.7.3ARM10系列

ARM10发布于1999年，主要是针对高性能的设计。它把ARM9的流水线扩展到6级，也支持可选的向量浮点单元VFP（避免在内核中进行浮点数运算，应该就是该Soc没有硬件支持，所以只能在用户层进行浮点数运算），对ARM10的流水线加入了第7段。VFP明显增强了浮点运算的性能，并与IEEE754.1985浮点标准兼容。

ARM1020E是第一个使用ARM10E内核的处理器。像ARM9E一样，它包括了增强的E指令。它有独立的32KB D+I cache、可选向量浮点单元VFP以及MMU。ARM1020E还有一个双64位总线接口，以改善性能。

ARM1026EJ-S非常类似于ARM926EJ-S，但同时具有MPU和MMU。这一处理器具有ARM10的性能和ARM926EJ-S的灵活性。

#### 2.7.4ARM11系列

ARM1136J-S发布于2003年，是针对高性能和高能效应用而设计的。ARM1136J-S是第一个执行ARMv6架构指令的处理器。它集成了一条具有独立的load-store和算术流水线的8级流水线。ARMv6指令包含了针对媒体处理的单指令流多数据流SIMD扩展，采用特殊的设计，以改善视频处理性能。

ARM1136JF-S就是为了进行快速浮点运算，而在ARM1136J-S增加了向量浮点单位。

#### 2.7.5专用处理器

StrongARM最初是ARM公司于Digital Semiconductor公司合作开发的，现在由Intel公司单独许可。在要求低功耗、高性能和PDA(个人数字助理)上的应用很广泛。他是哈佛结构，具有独立的D+Icahce。StrongARM是第一个包含5级流水线的高性能ARM处理器，但它不支持Thumb指令集。

Intel的XScale是StrongARM的后续产品，在性能上有显著改善。在本书写作之际，据报道XScale可运行在高达1GHz的频率上。XScale执行v5TE架构指令，他是哈佛结构的，类似于StrongARM，也包含一个MMU。

SC100致力于性能指标的另一方面。他是特别针对低功耗的安全应用而设计的。SC100是第一个基于ARM7TDMI内核、带有 MPU的安全内核。它不仅内核小，而且有较低的电压和电流需求，对于智能卡应用颇具吸引力。

### 2.8总结

在本章中，我们把注意力集中在实际ARM处理器的硬件基础上。ARM处理器可抽象成8个部件：ALU(算术逻辑单元)、桶形移位器、MAC(乘累加单元)、寄存器文本、指令译码器、地址寄存器、增量加法器和符号扩展。

ARM有3个指令集：ARM、Thumb和Jazelle。寄存器文件包括37个寄存器，但是在任意时刻只有17或18个寄存器可以被访问；其余的根据处理器模式被保护。当前的处理器模式保存在cpsr中，同时还保存了处理器内核的当前状态、中断屏蔽位、条件标志和状态，该状态决定了哪个指令集正在被执行。

一个ARM处理器由一个内核及周围的组件并通过总线连接起来。内核扩展包括：

- cache可**改善系统的总体性能**；
- TCM可改进具有**确定性的实时响应**；
- 存储管理用于组织存储器和保护系统资源；MMU存储管理单元、MPU存储保护单元。
- 协处理器用于扩展指令集和功能，协处理器15控制cache、TCM和存储器管理。

一个ARM处理器是**一个特定指令集架构ISA的具体实现**。自从第一个ARM处理器问世以来，ISA就一直在不断的完善。各种处理器根据相似的特性，可以被划分在各个系列(ARM7/ARM9/ARM10/ARM11)中。ISA特定指令集架构指的就是ARM版本，具体实现就是ARM核。

## 第三章、ARM指令集

- 数据处理指令
- 分支指令
- load-store指令
- 软件中断指令
- 程序状态寄存器指令
- 常量的装载
- ARMv5E扩展
- 条件执行
- 总结

本章介绍的指令集是基础知识，因为这些内容在本书的其他部分都会用到。所以，在深入讨论优化和高效算法之前，首先需要学习指令集。本章将介绍最普通和最常用的ARM指令 ，这些内容是建立在前一章所涉及的ARM处理器基础知识上的。第四章将会介绍Thumb指令集，附录A给出了所有的ARM指令的完整描述。

不同的ARM体系结构版本支持的指令是不同的，但是新的版本一般是增加指令并且保持指令的向后兼容。也就是说，在ARMv4T上写的代码在ARMv5TE处理器上也是可以运行的。下表列出了所有ARMv5E指令集架构ISA下支持的指令。这个ISA包括了所有ARM指令，以及在ARM指令集中一些新的功能特征。ARM ISA一列，列出了该指令是在哪个修订版本引入的。一些指令在后续的架构中已扩展了功能，例如CDP指令在ARMv5中有一个变体叫CDP2。同样，有些指令，项LDR，也有ARMv5的扩展，但不需要新的或扩展的助记符。治理的ARM指令集指的就是ARM汇编吧。每个ARM版本不同相应的指令集不同，对应的汇编也不同。这就是汇编为什么与硬件的体系架构相关原因了。

| 助记符        | ARM ISA   | 说明                           |
| ------------- | --------- | ------------------------------ |
| ADC           | v1        | 带进位的32位数加法             |
| ADD           | v1        | 32位数相加                     |
| AND           | v1        | 32位数的逻辑与                 |
| B             | v1        | 在32M的空间内的相对跳转指令    |
| BIC           | v1        | 32位数的逻辑位清零             |
| BKPT          | v5        | 断点指令                       |
| BL            | v1        | 带链接的相对跳转指令           |
| BLX           | v5        | 带链接的切换跳转               |
| BX            | v4T       | 切换跳转                       |
| CDP CDP2      | v2 v5     | 协处理器数据处理操作           |
| CL2           | v5        | 零计数                         |
| CMN           | v1        | 比较两个数的相反数             |
| CMP           | v1        | 32位数比较                     |
| EOR           | v1        | 32位逻辑异或                   |
| LDC LDC2      | v2 v5     | 从协处理器取一个或多个32位值   |
| LDM           | v1        | 从内存送多个32位字到ARM寄存器  |
| LDR           | v1 v4 v5E | 聪哥虚拟地址取一个单个的32位值 |
| MCR MCR2 MCRR | v2 v5 v5E | 从寄存器送数据到协处理器       |
| MLA           | v2        | 32位乘累加                     |
| MOV           | v1        | 传送一个32位数到寄存器         |
| MRC MRC2 MRRC | v2 v5 v5E | 从协处理器传送数据到寄存器     |
| MRS           | v3        | 把状态寄存器的值送到通用寄存器 |
| MSR           | v3        | 把通用寄存器的值送到状态寄存器 |
| MUL           | v2        | 32位乘                         |
| MVN           | v1        | 把一个32位数的逻辑非送到寄存器 |
| ORR           | v1        | 32位逻辑或                     |
| PLD           | v5E       | 预装载提示指令                 |
| QADD          | v5E       | 有符号32位饱和加               |
| ...           | ...       | ...                            |

太多了就不展示了。后边举例介绍指令操作时，使用PRE和POST条件，分别表示指令执行前和执行后的内存、寄存器情况。对于十六进制数字，使用0x前缀表示；二进制使用0b前缀。示例格式如下：

PRE (执行前条件)

​		(指令)

POST（执行后情况）

在执行前、后的条件说明中，如果需要对内存进行说明，则使用的格式为：

```assembly
mem(data_size)[address]
```

其含义是从address开始的data_size存储器位，例如mem32[1024]表示从地址1KB开始的32位数据值。

ARM指令**只对存放在寄存器的数据进行处理**，**对于存储器数据，只能使用load和store指令进行存取**。ARM指令通常带有2个或者3个操作数。例如下面的加法指令ADD，把存放在寄存器r1和r2中的值相加，然后把结果存放在寄存器r3

| 指令语法     | 目标寄存器Rd | 源寄存器1(Rn) | 源寄存器2(Rm) |
| ------------ | ------------ | ------------- | ------------- |
| ADD r3,r1,r2 | r3           | r1            | r2            |

ARM指令可以划分为以下几类：数据处理指令、分支指令、load-store指令、软件中断指令和程序状态寄存器指令。后续章节将分类介绍ARM指令的语法和功能。（其中的软件中断指令应用在内核提供给用户层的系统调用中，本质是触发软件中断以及传递参数到内核态中）

### 3.1数据处理指令

数据处理指令对于存放在寄存器中的数据进行操作，包括MOVE传送指令、算术指令、逻辑指令、比较指令和乘法指令。大多数数据处理指令可以**使用桶型移位器对其中的一个操作数进行预处理。**

如果在数据处理指令前使用S前缀，指令的执行将会更新cpsr中的标志。MOVE指令和逻辑指令会对进位标志C、负数标志N以及零标志Z产生影响。在最后一位移出时，桶型移位的结果将更新进位标志C；N标志根据操作结果的第31位进行设置；如果结果为零，那么Z标志就会被设置。

#### 3.1.1MOVE指令

MOVE指令是最简单的ARM指令，执行的结果就是把一个数N送到目标寄存器Rd。其中N可以是寄存器，也可以是立即数。**MOVE指令多用于设置初始值或者在寄存器间传送数据。**

MOVE指令语法：

<指令>{(cond)}{S} Rd,N

| MOV  | 把一个32位数送到一个寄存器     | Rd = N  |
| ---- | ------------------------------ | ------- |
| MVN  | 把一个32位数的非送到一个寄存器 | Rd = ~N |

通常N是一个寄存器Rm或者是一个使用#前缀的常量。以后会对操作数N的取值做完整的描述。

例3.1MOVE指令

例子中MOV指令把寄存器r5的内容复制到r7中去。执行后寄存器r7中的8被5覆盖。

```assembly
PRE
	r5 = 5
	r7 = 8
	MOV r7,r5;r7 = r5
POST
	r5 = 5
	r7 = 5
```

#### 3.1.2桶形移位器

在例子3.1中，N是一个寄存器。其实N不仅可以表示寄存器或者立即数，也可以是一个在数据处理指令使用前就被桶型移位器预处理过的寄存器Rm。

数据处理指令是在算术逻辑单元ALU中完成的。**ARM处理器一个显著的特征就是可以在操作数进入ALU之前，对操作数进行指定位数的左移或者右移。**这种功能明显增强了许多数据处理操作的灵活性。

有些数据处理指令并没有用到桶形移位器，例如MUL/CLZ和QADD指令等。

预处理或移位发生在该指令周期内。这对于把一个常量送入寄存器，被2的幂乘或除等操作是特别有用 。

为了对桶型移位器进行说明，以下图为例，在MOVE指令中增加移位操作。寄存器Rn在进入ALU前没有进行移位预处理操作，Rm使用桶型移位器移位后产生结果N进入ALU。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1679205305235.png" alt="1679205305235" style="zoom:33%;" />

这张图把桶形移位器的作用彻底说明白了。

例3.2在寄存器Rm送入目标寄存器之前，首先对它执行逻辑左移LSL。这就像在标准C中对寄存器使用移位操作<<。MOV指令把桶形移位器操作的结果N放入寄存器Rd，N是LSL操作的结果。由桶形移位器实现的逻辑左移。

```assembly
PRE
	r5 = 5
	r7 = 8
	MOV r7 r5,LSL #2;let r7 = r5 * 4 = (r5 << 2)，一下子说明白了，就是汇编指令往往是先对数进行操作然后再把数据存入寄存器中，正常来讲是先把数据存入ALU进行运算，然后拿出来再把数据存入寄存器中，这里移位的操作由桶型移位器负责了。
POST
	r5 = 5
	r7 = 20
```

这个例子中，寄存器r5乘4后把结果放在寄存器r7.

使用桶形移位器可执行5种不同的移位操作，比如表3.2所列。

| 助记符 | 说明           | 移位操作 | 结果                               | Y值         |
| ------ | -------------- | -------- | ---------------------------------- | ----------- |
| LSL    | 逻辑左移       | x LSL y  | x << y                             | #0-31 or Rs |
| LSR    | 逻辑右移       | x LSR y  | (unsigned)x>>y                     | #1-32 or Rs |
| ASR    | 算术右移       | x ASR y  | (signed)x>>y                       | #1-32 or Rs |
| ROR    | 循环右移       | x ROR y  | ((unsigned)x >> y)\|(x<<(32-y))    | #1-32 or Rs |
| RRX    | 扩展的循环右移 | x RRX    | (c flag << 31)\|((unsigned)x >> 1) | none        |

注：x表示要移位操作的寄存器，y表示要移位的位数。其实我没太搞清楚ALU是干啥的，可以用来生成寄存器地址给地址总线。

图3.2是一个逻辑左移一位的操作，如位0移入位1，位0清除，**C标志位被替换为移出寄存器的那一位。**当y表示移位位数时，原来数的位32-y将被移入C标志位，即对C标志进行替换。如果移位位数y>1，那么执行移位量为y的移位和执行y次移位量为1的移位效果相同。

例3.3一条MOVS指令，把寄存器r1左移一位送到寄存器r0。

这相当于把r1乘以2^1.因为指令助记符中有S出现，故cpsr的C标志位会被更新。

```assembly
PRE
	cpsr = nzcvqiFt_USER;这里是什么cpsr寄存器是32位，为什么变成了字符串，本书使用字符串表示了，表示前五个字符是标志位为0并没有被触发，i表示一般中断没有被屏蔽，F表示快速中断被屏蔽了，t表示不采用Thumb处理器状态，USER表示处理器处于用户模式
	r0 = 0x0000 0000
	r1 = 0x8000 0004
	MOVS r0,r1,LSL,#1;这里使用了前缀S，将r1逻辑左移1位，存入r0中，这里是MOVE指令+移位指令
POST
	cpsr = nzCvqiFt_USER
	r0 = 0x0000 0008
	r1 = 0x8000 0004;1000 0000 0000 0000 0000 0000 0000 0100左移一位，变成0000 0000 0000 0000 0000 0000 0000 1000
```

下表是数据处理指令的桶形移位操作语法。

| N                  | 语法              |
| ------------------ | ----------------- |
| 立即数             | # immediate       |
| 寄存器             | Rm                |
| 立即数逻辑左移     | Rm,LSL,#shift_imm |
| 寄存器逻辑左移     | Rm,LSL,Rs         |
| 立即数逻辑右移     | Rm,LSR,#shift_imm |
| 寄存器逻辑右移     | Rm,LSR,Rs         |
| 立即数算术逻辑右移 | Rm,ASR,#shift_imm |
| 寄存器算术逻辑右移 | Rm,ASR,Rs         |
| 立即数循环右移     | Rm,ROR,#shift_imm |
| 寄存器循环右移     | Rm,ROR,Rs         |
| 扩展循环右移       | Rm,RRX            |

#### 3.1.3算术指令

算术指令用于实现32位有符号数或者无符号数的加法和减法操作。

语法：<指令>{<cond>}{S}Rd,Rn,N

| ADC  | 32位带进位加法       | Rd=Rn+N+carry          |
| ---- | -------------------- | ---------------------- |
| ADD  | 32位加法             | Rd=Rn+N                |
| RSB  | 32位逆向减法         | Rd=N-Rn                |
| RSC  | 带进位的32位逆向减法 | Rd=N-Rn-!(carry flag)  |
| SBC  | 带进位的32位减法     | Rd=Rn-N-!(carray flag) |
| SUB  | 32位减法             | Rd=Rn-N                |

N是桶形移位器操作的结果，可以说对立即数或者寄存器进行操作。Rd是目标寄存器，Rn和Rm是源寄存器。

例3.4使用减法指令把存储在r1中的值减去r2中的值，然后把结果存放在r0中。

```assembly
PRE
	r0=0x00000000
	r1=0x00000002
	r2=0x00000001
	SUB r0,r1,r2
POST
	r0=0x00000001
```

例3.5使用逆向减法指令RSB从常数0减去r1，然后把结果存放在r0中。可使用这种方法对一个数进行取反操作。

```assembly
PRE
	r0=0x00000000
	r1=0x00000077
	RSB  r0,r1,#0;Rd=0x0-r1所谓的逆向减法就是可以让立即数减去寄存器值存入寄存器
POST
	r0=-r1=0xffffff89
```

例3.6SUBS指令可以很方便地实现循环计数器的递减操作

本例使用SUBS指令从寄存器r1中减去常量1，然后把结果写回到r1。

注意，cpsr的Z和C位将会受到影响。

```assembly
PRE
	cpsr = nzcvqiFt_USER
	r1=0x00000001
	SUBS r1,r1,#1;指令助记符会导致cpsr的条件标志位更新，这里Z表示0，C表示进位都被影响
POST
	cpsr= nZCvqiFt_USER
	r1=0x00000000
```

算术指令表示加减，桶形移位器的操作表示移位

#### 3.1.4算术指令使用桶形移位器

在算术指令和逻辑指令中广泛使用的第2操作数的移位功能，是ARM指令集的一个非常显著的特征。例3.7是一个算术指令使用过内嵌桶形移位器的示例，指令把存储在r1中的值乘以3。

例3.7寄存器r1首先左移一位，其结果等于r1值的2倍；然后加法操作把r1和桶形移位器的结果相加；最终的结果放在寄存器r0中，r0等于3×r1。

```assembly
PRE
	r0=0x00000000
	r1=0x00000005
	ADD r0,r1,r1,LSL #1;这个是算术指令加移位指令。r1实际上是和r1,LSL #1的结果相加存入r0中
POST
	r0=0x0000000f
	r1=0x00000005
```

#### 3.1.5逻辑指令

逻辑指令可对2个源操作数的对应位进行逻辑操作。

语法为：<指令>{<cond>}{S}Rd,Rn,N

| AND  | 32位逻辑与                   | Rd=Rn&N  |
| ---- | ---------------------------- | -------- |
| ORR  | 32位逻辑或                   | Rd=Rn\|N |
| EOR  | 32位逻辑异或（不进位的加法） | Rd=Rn`N  |
| BIC  | 逻辑位清除(AND NOT)          | Rd=Rn&~N |

这个BIC好眼熟

例3.8逻辑或操作。

把寄存器r1和r2进行或操作，然后把结果放到r0。

```assembly
PRE
	r0=0x00000000
	r1=0x02040608
	r2=0x10305070
	ORR r0,r1,r2;r1和r2进行逻辑或存入r0中
POST
	r0=0x12345678
```
例3.9本例使用一个更复杂的逻辑指令，BIC指令，它可以把一个逻辑位清零。
```assembly
PRE
	r1=0b1111
	r2=0b0101
	BIC r0,r1,r2;这里就是二进制的1111和1010进行逻辑与
POST
	r0=0b1010
```

上面代码的执行等价于：Rd=Rn AND NOT(N)

在这个例子中，寄存器r2中**置1的位将清除r1中对应位置的位**。这么理解确实速记了。BIC指令在清除状态位时是非常有用的，也经常用于改变cpsr中的中断屏蔽位。

只有当逻辑指令有S后缀时，指令才会更新cpsr，这些指令可以想算术指令一样使用桶形移位器来移位第2操作数。

#### 3.1.6比较指令

比较指令通常用于把一个寄存器与一个32位的值进行比较或测试。比较指令根据结果更新cpsr的标志位，但不影响其他的寄存器。在设置标志位后，其他指令可通过条件执行来改变程序的执行流程。关于条件执行的更多信息，请参考3.8节。对于比较指令，**不需要使用S后缀就可以改变标志位**。

指令语法：<指令>{<cond>}Rn,N，这里并没有{S}

| CMN  | 取负比较 | 标记根据Rn+N的值设置           |
| ---- | -------- | ------------------------------ |
| CMP  | 比较     | 标记根据Rn-N的值设置           |
| TEQ  | 等值测试 | 标记根据Rn`N也就是异或的值设置 |
| TST  | 位测试   | 标记根据Rn&N的值设置           |

注：N是桶形移位器的操作结果。其实就是说N可以是寄存器、立即数也可以是移位后的第二操作数。

例3.10CMP指令

指令执行前，r0与r9相等，z标志是0，用小写字母表示。执行后z标志变成1，用大写字母表示。指示出比较结果相等。cpsr的最高五位nzcvq表示的是对应指令的执行结果。而不是只对应一个指令。

```assembly
PRE
	cpsr = nzcvqiFt_USER
	r0 = 4
	r9 = 4
	CMP r0,r9
POST
	cpsr = nZcvqiFt_USER;比较完发现r0和r9相等，差为0，z变成Z
```

比较指令CMP**本质是一个不返回运算结果的减法指令**（看出来了，根据运算结果判断比较结果）；同样，TST指令是一个没有保存结果的逻辑与操作；TEQ则是一个逻辑异或操作。对于每个操作，不需要保存运算结果，只根据结果影响cpsr。

必须记住：**比较指令只改变cpsr中的条件标志，不影响参与比较的寄存器内容。**

#### 3.1.7乘法指令

乘法指令把一对寄存器的内容相乘，然后根据指令类型把结果累加到其他的寄存器。长整型的乘累加要使用代表64位的一对寄存器，最终的结果放在一个目标寄存器或者一对寄存器中。

乘法指令的语法：MLA{<cond>}{S}Rd,Rm,Rs,Rn

MUL{<cond>}{S}Rd,Rm,Rs

| MLA  | 乘累加 | Rd=(Rm*Rs)+Rn |
| ---- | ------ | ------------- |
| MUL  | 乘法   | Rd=Rm*Rs      |

<指令>{<cond>}{S}RdLo,RdHi,Rm,Rs

| SMLAL | 长整型有符号乘累加 | [RdHi,RdLo]=[RdHi,RdLo]+(Rm*Rn) |
| ----- | ------------------ | ------------------------------- |
| SMULL | 长整型有符号乘法   | [RdHi,RdLo] = Rm*Rs             |
| UMLAL | 长整型无符号乘累加 | [RdHi,RdLo]=[RdHi,RdLo]+(Rm*Rs) |
| UMULL | 长整型无符号乘法   | [RdHi,RdLo]=Rm*Rs               |

执行一个乘法指令需要的周期数取决于处理器的具体实现。对于某些处理器实现，需要的周期数还依赖于Rs的值（Rs是参与乘法的，Rn是乘累加中的加法）。关于周期定时的更多细节参考附录。

例3.11一个简单的乘法指令：把寄存器r1和寄存器r2相乘，然后把结果放在寄存器r0，本例中r1=2,r2=2，运算结果为4，放在寄存器r0

```assembly
PRE
	r0 = 0x00000000
	r1 = 0x00000002
	r2 = 0x00000002
	MUL r0,r1,r2;//r0 = r1*r2
POST
	r0 = 0x00000004
	r1 = 0x00000002
	r2 = 0x00000002
```

长整型乘法指令(SMLAL,SMULL,UMLAL和UMULL)产生64位的结果。由于结果太大，不能存放在一个32位的寄存器，所以把结果存放在2个32位的寄存器RdLo和RdHi中。（这里的[RdLo,RdHi]指的就是两个32位的寄存器存放64位数据的）

RdLo存放低32位，RdHi存放高32位。例3.12是一个长整型乘法的例子。

例3.12把寄存器r2和r3的结果相乘，然后把结果放在r0和r1中。r0存放低32位，r1存放高32位。

```assembly
PRE
	r0 = 0x00000000
	r1 = 0x00000000
	r2 = 0xf0000002
	r3 = 0x00000002
	UMULL r0,r1,r2,r3;[r1,r0] = r2*r3这里和大小端没关系，人家是以字节为单位，这里的以32位寄存器为单位。结果是1 e0000004
POST
	r0 = 0xe0000004;RdLo
	r1 = 0x00000001;RdHi
```

### 3.2分支指令

分支指令可改变程序的执行过流程或者调用子程序。这种指令使得一个程序可以使用子程序、if-then-else结构以及循环。执行流程的改变迫使程序计数器pc指向一个新的地址，ARMv5E架构指令集包括以下4种不同的分支指令。

语法：

B{<cond>}label

BL{<cond>}label

BX{<cond>}Rm

BLX{<cond>}label |Rm

| B    | 跳转                   | pc = label                                                   |
| ---- | ---------------------- | ------------------------------------------------------------ |
| BL   | 带返回的跳转           | pc = label,lr=BL后面的第一个指令地址。这里的lr指的是链接寄存器，保存PC寄存器的内容，也就是保存调用子程序的地址 |
| BX   | 跳转并切换状态         | pc=Rm&oxfffffffe,T=Rm&1                                      |
| BLX  | 带返回的跳转并切换状态 | pc=label,T=1,pc=Rm&0xfffffffe,T=Rm&1,lr=BLX后面的第一条指令地址 |

地址label以一个有符号的相对于pc的偏移量保存在指令中，必须被限制在分支指令的约32MB范围内。T对应于cpsr中的Thumb位，如果指令设置了T，那么ARM切换到Thumb状态。

例3.13显示一个前向跳转和一个后向跳转。

由于跳转是由地址确定的，这里不再给出执行前后的状态。这里前向跳转跳过了3条指令；后向跳转建立了一个无限循环。

```assembly
	B forward
	ADD r1,r2,#4
	ADD r0,r6,#2
	ADD r3,r7,#4
forward
	SUB r1,r2,#4
---------------------------------
backward
	ADD r1,r2,#4
	SUB r1,r2,#4
	ADD r4,r6,r7
	B backward
```

分支指令用于改变程序的执行流程，大多数汇编语言通过使用地址标号来隐藏分支指令编码的细节。在例3.13中，forward和backward就是地址标号。地址标号放在一行的开始处，汇编器会记录该行指令的地址，用于计算跳转的偏移量。

例3.14带链接的跳转

带链接的跳转指令和B指令类似，不过BL指令还要把一个返回地址写到链接寄存器lr。（所谓的链接指的就是带链接的跳转中链接地址。所以lr保存的是PC的备份，理解为是调用子程序的返回地址）。BL可用于子程序调用。下面的例子是一个代码片段，使用BL指令跳转到一个子程序再通过拷贝链接寄存器lr到pc来返回。

```assembly
BL subrouine ;跳转到子程序，
CMP r1,#5;将立即数5与r1进行比较，其实就是不返回值的减法
MOVEQ r1,#0;if(r1 == 5)then r1 = 0，这个指令第一次见
...
subroutine
<子程序代码>
MOV pc,lr;返回，所谓的带链接的功能就是把lr送入pc中

```

分支切换指令BX和带链接的分支切换指令BLX是第三种类型的分支指令。BX指令使用一个存储在寄存器Rm中的绝对地址，主要用于**跳转到Thumb**代码或从Thumb状态返回。

cpsr中的T位由分支寄存器的最低位来更新。同样，BLX指令也是**用分支寄存器的最低位来更新cpsr中的T位**，并要把返回地址写入链接寄存器lr。

load-store指令用于在存储器和处理器寄存器之间传输数据。共有3种类型的load-store指令：单寄存器传输指令、多寄存器传输指令和交换指令。

### 3.3load-store指令

#### 3.3.1单寄存器传送指令

这种指令用于把单一的数据传入或者传出一个寄存器。支持的数据类型有字(32位)、半字(16位)和字节。下面是不同的单寄存器传送指令的格式。

语法：

```
<LDR|STR>{<cond>}{B}Rd,addressing1
LDR{<cond>}SB|H SH Rd,addressing2
STR{<cond>}H Rd,addressing2
```

| LDR   | 把一个字装入一个寄存器       | Rd<-mem32[address]             |
| ----- | ---------------------------- | ------------------------------ |
| STR   | 从一个寄存器保存一个字32位   | Rd->mem32[address]             |
| LDRB  | 把一字节装入一个寄存器       | Rd<-mem8[address]              |
| STRB  | 从一个寄存器保存一个字节     | Rd->mem8[address]              |
| LDRH  | 把一个半字装入寄存器         | Rd<-mem16[address]             |
| STRH  | 从一个寄存器保存一个半字     | Rd->mem16[address]             |
| LDRSB | 把一个有符号字节装入寄存器   | Rd<-signExtend(mem8[address])  |
| LDRSH | 把一个有符号的半字装入寄存器 | Rd<-signExtend(mem16[address]) |

例3.15LDR和STR指令可以装载和存放边界对齐的数据。

所谓边界对齐，就是数据便捷地址与该数据类型的大小是一致的。例如，LDR只能从地址为4字节整数倍的存储器地址装载32位的字048等地址。此例子中从一个以寄存器r1内容为地址的存储器中装载数据，然后再写回到原来的地址。

```assembly
读取数据到r0
LDR r0,[r1];=LDR r0,[r1 #0]
存储数据
STR r0,[r1];=STR r0,[r1,#0]
```

#### 3.3.2单寄存器load-store指令的寻址方式

ARM指令集提供了几种存储器寻址的不同方式，这些方式是以下几种变址模式的组合：回写前变址(preindex with writeback)、前变址(preindex)及后变址(postindex)。

表3.4列出了几种变址模式。

| 变址模式   | 数据             | 基址寄存器         | 示例           |
| ---------- | ---------------- | ------------------ | -------------- |
| 回写前变址 | mem[base+offset] | 基址寄存器加上偏移 | LDR r0,[r1,#4] |
| 前变址     | mem[base+offset] | 不变               | LDR r0,[r1,#4] |
| 后变址     | mem[base]        | 基址寄存器加上偏移 | LDR r0,[r1],#4 |

例3.16回写型前变址和前变址的区别是：

- 回写型前变址在计算出新的地址后要用新的地址**更新**基址寄存器的内容，然后再**利用新的基址寄存器进行寻址**；
- 而前变址方式虽然也利用对基址寄存器的**改变值进行寻址**，但基址寄存器在操作之后仍然**保持原值**。
- 后变址和回写型前变址类似，也要更新基址寄存器的内容，但后变址仿古式先利用基址寄存器的**原值进行寻址**操作，然后再**更新**基址寄存器。

```assembly
PRE
	r0 = 0x00000000
	r1 = 0x00090000
	mem32[0x00009000] = 0x01010101
	mem32[0x00009004] = 0x02020202;表示该地址中存储的内容
	LDR r0,[r1,#4]!;这里表示r1先变址+4=0x00009004,然后[0x00009004]读取数据送入r0中，此时r0 = 0x02020202，最后进行回写r1寄存器，r1 = 0x00009004
回写型前变址寻址
POST(1)
	r0 = 0x02020202
	r1 = 0x00009004
	--------
	LDR r0,[r1,#4];这里同样是先变址r1+4 = 0x00009004,然后取址[0x00009004]，存入r0中，r0 = 0x02020202，但是这里并不回写r1 = 0x00009000
前变址寻址：
POST(2)
	r0 = 0x02020202
	r1 = 0x00009000
	
-----------
	LDR r0,[r1],#4
后变址寻址：
POST(3)
	r0 = [r1] = 0x01010101;先取址然后再变址回写
	r1 = r1+4 = 0x00009004
```

例3.16说明了在相同的前置条件下，不同的变址方式是如何影响寄存器r1中的地址和装载到寄存器r0的数据结果的。

对于一条特定的load-store指令，其寻址模式依赖于其所属的指令类。表3.5中列出了32位字word和无符号字节unsigned byte的load-store指令所支持的寻址模式。

| 寻址方式1(Addressing1)       | Addressing1语法                 |
| ---------------------------- | ------------------------------- |
| 立即数偏移前变址寻址         | [Rn,# + / - offset_12]          |
| 寄存器偏移前变址寻址         | [Rn,+ / - Rm]                   |
| 比例寄存器偏移前变址寻址     | [Rn,+ / - Rm,shift_imm]         |
| 立即数偏移回写前变址寻址     | [Rn,# + / - offset_12]!         |
| 寄存器偏移回写前变址寻址     | [Rn,+ / - Rm]!                  |
| 比例寄存器偏移回写前变址寻址 | [Rn,+ / - Rm,shift #shift_imm]! |
| 立即数后变址寻址             | [Rn],+ / - offset_12            |
| 寄存器后变址寻址             | [Rn], + /- Rm                   |
| 比例寄存器后变址寻址         | [Rn],+ / - Rm,shift #shift_imm  |

有符号的偏移量或寄存器用+/-表示，表示相对一个基址寄存器Rn的正偏移量或负偏移量。基址寄存器是一个指向字节的指针，偏移量表示偏移的字节数。

- 寻址方式中 的**立即数**说明地址是通过基址寄存器和一个编码在指令 中 的12位偏移量计算而得；
- **寄存器** 说明地址是通过基址寄存器和另一个特定的寄存器中的内容计算得出；
- 比例寄存器(scaled register)是指说明基址寄存器和一个桶形移位器来计算地址。

下表提供了LDR指令的不同变体的操作示例。

| 寻址模式       | 指令                      | r0=                     | r1+=          |
| -------------- | ------------------------- | ----------------------- | ------------- |
| 回写前变址寻址 | LDR r0,[r1,#0x04]!        | mem32[r1+0x04]          | 0x04          |
|                | LDR r0,[r1,r2]!           | mem32[r1+r2]            | r2            |
|                | LDR r0,[r1,r2,LSR #0x04]! | mem32[r1+(r2 LSR 0x04)] | (r2 LSR 0x04) |

最后一种就是比例寄存器，这里是直接把本质拿出来了，就是桶形移位器，移位指令LSR，将r2中的数据向右移位4

| 寻址模式   | 指令                    | r0=                       | r1+= |
| ---------- | ----------------------- | ------------------------- | ---- |
|            | LDR r0,[r1,#0x4]        | mem32[r1+0x4]             | 不变 |
| 前变址寻址 | LDR r0[r1,r2]           | mem32[r1+r2]              | 不变 |
|            | LDR r0[r1,-r2,LSR #0x4] | mem32[r1-(r2 LSR #0x04 )] | 不变 |

| 寻址模式   | 指令                    | r0=       | r1+=          |
| ---------- | ----------------------- | --------- | ------------- |
|            | LDR r0,[r1],#0x4        | mem32[r1] | 0x04          |
|            | LDR r0,[r1],r2          | mem32[r1] | r2            |
| 后变址寻址 | LDR r0,[r1],r2,LSR #0x4 | mem32[r1] | (r2,LSR #0x4) |

接下来列出16位半字或有符号字节的load和store指令。

| Addressing2方式和变址方法 | Addressing2语法        |
| ------------------------- | ---------------------- |
| 立即数偏移前变址寻址      | [Rn,# + / -offset_8]   |
| 寄存器偏移前变址寻址      | [Rn,+ / - Rm]          |
| 立即数偏移回写前变址寻址  | [Rn,# + / - offset_8]! |
| 寄存器偏移回写前变址寻址  | [Rn, + / - Rm]!        |
| 立即数后变址寻址          | [Rn],# + / - offset_8  |
| 寄存器后变址寻址          | [Rn], + / - Rm         |

这里对于有符号的半字、字节、双字数据的操作并没有比例寄存器也就是移位操作，这些操作(这个操作是从寄存器读取数据到主存)不能使用桶形移位器，并没有STRSB或者STRSH指令(从寄存器把数据存入主存，针对有符号的字节和半字)，因为STRH可以存储一个有符号或者无符号的半字；STRB可以存储有符号或者无符号的字节。**其实说的是对于STRB而言从寄存器发送到主存是不可以使用桶形移位器，而从主存到寄存器可以使用。**

下表列出STRH指令的各种变体

| 寻址模式       | 指令               | 结果             | R1+= |
| -------------- | ------------------ | ---------------- | ---- |
| 回写前变址寻址 | STRH r0,[r1,#0x4]! | mem16[r1+0x4]=r0 | 0x4  |
|                | STRH r0,[r1,r2]!   | mem16[r1+r2]=r0  | r2   |
| 前变址寻址     | STRH r0,[r1,0x4]   | mem16[r1+0x4]=r0 | 不变 |
|                | STRH r0,[r1,r2]    | mem16[r1+r2]=r0  | 不变 |
| 后变址寻址     | STRH r0,[r1],#0x4  | mem16[r1]=r0     | 0x4  |
|                | STRH r0,[r1],r2    | mem16[r1]=r0     | r2   |

#### 3.3.3多寄存器传送指令

多次装载-存储的load-store指令可以用一条指令传送多个寄存器的值到内存，或者从内存取数据到多个寄存器。传输是从一个指向寄存器的基地址寄存器Rn开始的。多寄存器传送指令在数据块操作、上下文切换、堆栈操作等方面，比单寄存器传送指令会有更高的执行效率。

多寄存器的load-store指令会增加中断的延迟，因为ARM通常 **不会打断正在执行的指令去响应中断**，必须等指令执行完。例如在ARM7中，一个多寄存器的load指令如果装载N个寄存器，那么志林执行需要2+Nt个周期，其中t是依次顺序访问寄存器所需的周期数。如果一个中断在多寄存器load-store指令执行期间产生，那么处理器在多寄存器load-store指令执行完后才对中断响应。

编译器，比如armcc，提供了一个开关来控制依据load-store指令可以传送的最大寄存器数目，以限制最大的中断延迟。（这里的中断延迟最大值是由编译器决定的）

语法：<LDM|STM>{<cond>}<寻址模式>Rn{!},{Registers}{r^}

| LDM  | 装载多个寄存器 | {Rd}*N<-mem32[start address + 4 *N] optional Rn updated    |
| ---- | -------------- | ---------------------------------------------------------- |
| STM  | 保存多个寄存器 | {Rd} * N->mem32[start address + 4 * N] optional Rn updated |

下表列出了多寄存器load-store指令的不同寻址模式，其中N是操作寄存器的个数。

| 寻址模式 | 描述       | 起始地址  | 结束地址  | Rn!      |
| -------- | ---------- | --------- | --------- | -------- |
| IA       | 执行后增加 | Rn        | Rn+4 *N-4 | Rn+4 * N |
| IB       | 执行前增加 | Rn+4      | Rn4*N     | Rn+4*N   |
| DA       | 执行后减少 | Rn-4*Rn+4 | Rn        | Rn-4*N   |
| DB       | 执行前减少 | Rn-4*N    | Rn-4      | Rn-4*N   |

任何当前寄存器组的子集都可以使用多寄存器load-store指令与存储器进行数据交换。基址寄存器Rn决定目标或者原地址，可以通过选择使用Rn后缀字符！来确定Rn的值是否随着传送而改变，**就像使用回写前变址寻址的单寄存器传送指令一样**

例3.17寄存器r0作为基地址寄存器Rn，并且使用了！后缀，表示在指令个执行后寄存器将被更新。

注意：在多寄存器传送指令中，这些寄存器并没有被单独列出来，而是使用“-”来表示一个寄存器范围。本例中，这个范围是r1~r3，如果列出每一个寄存器，则要用逗号分割，并使用{}括起来。

```assembly
PRE
	mem32[0x80018] = 0x03
	mem32[0x80014] = 0x02
	mem32[0x80010] = 0x01
	r0 = 0x00080010
	r1 = 0x00000000
	r2 = 0x00000000
	r3 = 0x00000000
	LDMIA = r0!,{r1-r3};这里LDM表示装载多个寄存器，IA表示执行后增加，将r0作为基址寄存器开始地址+4，然后装载r1,r2,r3寄存器。这里没有[r0]!
POST
	r0 = 0x0008001c
    r1 = 0x00000001
    r2 = 0x00000002
    r3 = 0x00000003
```

下图是一个图形化表示，在执行前基址寄存器r0指向存储器地址0x80010寄存器地址0x80010,0x80014及0x80018保存的内容分别为1,2,3。load指令之心后，r1，r2，r3的值发生改变；最后，基址寄存器r0指向了存储器地址0x8001c。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1680501860534.png" alt="1680501860534" style="zoom: 33%;" />

因为是LDMIA，这里LD表示load，M表示多个，IA表示执行前增加，i表示increase，A表示after。

如果例子中的LDMIA指令被LDMIB指令取代，并且是执行前的状态，那么执行后的状态如下图所示

在相同的前置条件下，如果把上述LDMIA指令换成前增量的LDMIB指令，那么寄存器r0所指向的第一个字将被忽略，寄存器r1将从下一个地址装载数据，执行后，寄存器r0指向最后一个被装载的字。递减类的多寄存器传送指令DA和DB是从起始地址这对于寄存器地址与寄存器编号移动方向相反的传送是很有效的。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1680502721617.png" alt="1680502721617" style="zoom:33%;" />

这里可以看出来无论是LDMIA还是LDMIB，最后r0的值都是0x8001c，而r123寄存器的值则不同，IA是从起点开始出发包含四个寄存器的前三个，而IB是从起点的下一个寄存器开始出发。包含四个寄存器的后三个。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1680502861084.png" alt="1680502861084" style="zoom:33%;" />

可以使用递增和递减的多寄存器传送来正向或反向访问数组，或用于堆栈的压入和退出操作。这里的地址+4是因为32位地址，地址偏移量是一个字节。

下表列出了更新基地址的load-store指令对。如果使用了表中的一条store指令，那么与之配对的load指令（相同寄存器数目）将冲更新装载数据并恢复基地址指针。如果是三个寄存器，地址则是基地址+4*3。这对于需要临时保存一组寄存器，然后再恢复他们的场合，是很有用的。这里指的是保存上下文吧。或者是切换ARM工作模式的时候每种模式有专属的寄存器，这么保存到主存中。

| 多寄存器store指令 | 多寄存器load指令 |
| ----------------- | ---------------- |
| STMIA             | LDMDB            |
| STMIB             | LDMDA            |
| STMDA             | LDMIB            |
| STMDB             | LDMIA            |

例3.18显示STMIB和LDMDA的组合使用

STMIB指令把值7,8,9存入存储器，然后r1~e3被改写，最后使用LDMDA恢复了r1,r2,r3的原始值，并恢复了基地址指针r0。

```assembly
PRE
	r0 = 0x00009000
	r1 = 0x00000009
	r2 = 0x00000008
	r3 = 0x00000007
	STMIB r0!,{r1-r3};这里的保存寄存器是把寄存器r1r2r3中的789存入[r0+4*3]中。这里保存了现场
	下面是破坏现场
	MOV r1,#1
	MOV r2,#2
	MOV r3,#3
PRE(2)
	r0 = 0x0000900c
	r1 = 0x00000001
	r2 = 0x00000002
	r3 = 0x00000003
	LDMDA r0!,{r1-r3};之前讲r1-r3寄存器数据存入了[r0中]准确说是r0的9004 9008 900c中。现在需要取出了，就是从900c 9008 9004中取出
POST
	r0 = 0x00009000
	r1 = 0x00000009
	r2 = 0x00000008
	r3 = 0x00000007
```

这个例子很好，说明了 如何实现对寄存器上下文保存的，将寄存器数据存入主存中，再取出。

例3.19使用多寄存器传送指令来完成一个存储器数据块拷贝

下面的代码从原地址拷贝32字节到目标地址

```assembly
;r9 存放源数据起始地址
;r10 存放目标起始地址
;r11 存放源的结束地址
loop
	LDMIA r9!,{r0-r7};装载32字节并更新r9指针装载[r9]!中的信息到r0-r7寄存器中
	STMIA r10!,{r0-r7};存储32字节并更新r10指针，读取r0-r7寄存器中的数据到[r10]!主存中
	CMP r9,r11;到达结束地址
	BNE loop;不相等则跳转，其实就是循环直到
```

这个程序假设代码执行前已设置好了寄存器r9,r10和r11.寄存器r9和r11决定了拷贝数据的范围，r10为数据存储的目标地址。LDMIA指令装载由r9指向的数据到寄存器r0-r7，同时更新r9指向下一个要拷贝的数据块。CMP和BNE指令比较指针r9和r11，检查是否已到达结束地址，如果块拷贝已完成，则程序结束；否则循环将以更新过的r9和r10继续。BNE是附条件标志NE(不相等)的分支指令。（之前没查到BNE，NE是不相等语句会导致cspr中的n标志位，nzcvq）

下图是对上述存储器块拷贝的示意图。理论上讲，这个循环使用2条指令就可以传送32字节，所以在33MHz的时钟下，可以获得64MB/s的吞吐量。以上 数据是在使用快速内存的理想存储系统中得到的。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1680588475571.png" alt="1680588475571" style="zoom:33%;" />

寄存器保存方式是一个指令就可以，因为只需要访问一次主存，而对主存的拷贝需要访问两次，所以需要两个指令。所以上下文中的用户上下文就是采用这种拷贝的。

##### 堆栈操作

ARM体系结构使用多寄存器的load-store指令来完成堆栈操作。pop操作（出栈）使用一条多处理器的load指令加载到寄存器中，push操作(入栈)使用一条多寄存器的store指令。

在使用一个堆栈的时候，需要确定堆栈在存储器空间中是向上生长还是向下生长的。这涉及到使用I还是D，栈是向下增长的，堆是向上增长的。

满堆栈(full stack,"F")是指堆栈指针**sp指向堆栈的最后一个已使用的地址**或满位置也就是栈中地址最低位。（也就是sp指向堆栈的最后一个数据项位置）；相反，空堆栈（empty stack,"E"）是指**sp指向堆栈的第一个没有使用的地址**或空位置（sp是esp的低十六位）

有一些多寄存器load-store指令的别名支持堆栈操作。在pop的右边下一列，是与之实际等价的load指令。例如，一个递增式满堆栈将由符号FA附加在load指令-LDMFA，这可以转换成一个LDMDA指令。

下表是堆栈操作寻址方式

| 寻址方式 | 说明   | pop   | =LDM  | push  | =STM  |
| -------- | ------ | ----- | ----- | ----- | ----- |
| FA       | 递增满 | LDMFA | LDMDA | STMFA | STMIB |
| FD       | 递减满 | LDMFD | LDMIA | STMFD | STMDB |
| EA       | 递增空 | LDMEA | LDMDB | STMEA | STMIA |
| ED       | 递减空 | LDMED | LDMIB | STMED | STMDA |

这里解释下满堆栈与空堆栈的具体区别：

满堆栈并不是说当前堆栈已经满了，而是说sp堆栈指针会指向最后一个已使用的地址也就是满位置。

对于装载寄存器LD而言，需要将有效数据存入寄存器中，所以应该是在当前的满位置读取，执行后改变所以是A，此时如果向上生长的地址，满位置在低地址，需要将当前sp指向的地址存入寄存器后下降，sp上升反而没有数据了，所以A对应D，LDMFA == LDMDA

对于保存寄存器ST到栈而言，sp指针指向的如果是满位置，那么应该执行前改变，也就是B，如果是向下生长的地址，满位置在高地址，需要把数据从寄存器保存到sp指向的下一个低地址。所以是DB，STMFD == STMDB

例3.20STMFD指令把寄存器内容放入堆栈，并更新sp的值。

下图显示了在一个递减式满堆栈上的push入栈操作，可以看到堆栈指针的变化并指向堆栈的满位置。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1680760551522.png" alt="1680760551522" style="zoom:33%;" />

```assembly
PRE
	r1 = 0x00000002
	r4 = 0x00000003
	sp = 0x00080014
	STMFD sp!,{r0,r4};这里sp指针后边的！表示回写指针数值发生变化，F表示满堆栈，D表示向下生长，等于STMDB。这里的数据是从右往左依次存入sp中，如果是LDM装载寄存器，就是从左往右遍历寄存器。
POST
	r1 = 0x00000002
	r4 = 0x00000003
	sp = 0x0008000c
```

例3.21显示在一个递减式空堆栈上，使用STMED指令完成的一个push操作STMED指令把寄存器内容压栈，但sp指向了下一个空位置。

这里的STMED表示空堆栈，sp指向的是一个空的存储单元，向下增长的地址，所以等价于STMDA。我们存储到栈中也是向下增长的。

```assembly
PRE
	r1 = 0x00000002
	r4 = 0x00000003
	sp = 0x00080010
	STMED sp!,{r1,r4};将r4/r1数据依次存入sp指向的地址中
POST
	r1 = 0x00000002
	r4 = 0x00000003
	sp = 0x00080008
```

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1680762350164.png" alt="1680762350164" style="zoom:33%;" />

若要检查一个堆栈，需关注堆栈的3个属性：堆栈基址、堆栈指针以及；堆栈基址是堆栈在存储器中的起始地址；堆栈指针初始时指向堆栈基址单元，随着数据压栈，堆栈指针连续移动并始终指向栈顶；（因为栈底是在最高地址固定了，向下增长，也就是说栈顶是时刻在变化的）如果堆栈指针超出了堆栈限制，就会发生堆栈溢出错误。因为栈很小的，内核栈对于32位机而言只有4KB，堆很大而且是不连续地址。下面的一小段代码用于检测递减式堆栈的溢出错误。

```assembly
SUB sp,sp,#size;将sp-size的值存入sp寄存器中
CMP sp,r10;将sp值与r10做对比，比较指令无须S后缀就可以修改cpsr中的条件标志位。
BLL0 _stack _overflow;
```

ATPCS把寄存器r10定义成堆栈限制或者sl(stack limit)。这是一个可选的操作，因为堆栈检查只有在堆栈检查使能的时候才可使用。(ATPCS是ARM处理器中对寄存器的使用规则r10是sl、r13是sp、r14是lr、r15是pc，一般函数调用如果r0-r3寄存器就可以使用的话不需要压栈了)，BLL0指令是一个加了条件助记符L0的带链接的分支指令。就是跳转完会返回。

如果在执行一个push入栈操作时，sp小于r10，就发生了堆栈溢出错误。如果堆栈指针sp在执行pop出栈操作时，超出了堆栈基址，就产生了堆栈下溢(stack under-flow)错误。这里sp小于r10说明此时堆栈指针向下增长超过了极限值，此时栈过大导致溢出了。如果出栈的时候地址大于堆栈基址，说明此时堆栈指针超过了栈底，堆栈下溢了。

目前是学完了保存寄存器上下文的指令，以及入栈出栈的指令。两者其实等价，后者是前者的取别名。

#### 3.3.4交换指令

交换指令是load-store指令的一种特例，把一个存储器单元的内容与寄存器内容相交换。交换指令是一个原子操作（atomic operation）-这话说得，原子操作本质就是汇编指令，因为指令不可被打断（缺页中断会打断指令，中断不会），**在连续的总线操作中读/写一个存储单元，在操作期间阻止其他任何指令对该存储单元的读写**。软件中断是通过指令触发的，外部中断并不是。

语法：SWP{B}{<cond>}Rd,Rm,[Rn]。

这个SWP是将寄存器和存储单元中的内容**交换**。

|      |          | tmp=mem32[Rn];这里为什么要找一个临时变量 |
| ---- | -------- | ---------------------------------------- |
| SWP  | 字交换   | mem32[Rn] = Rm;Rm是用来赋值给存储单元的  |
|      |          | Rd = tmp;Rd是用来存放存储单元中的数据的  |
|      |          | tmp=mem8[Rn]                             |
| SWPB | 字节交换 | mem8[Rn] = Rm                            |
|      |          | Rd = tmp                                 |

就是Rd是目标寄存器用来存放[Rn]的，Rm是写入[Rn]的

交换指令在执行期间不能 被其他任何指令或其他任何总线访问打断，在此期间系统占据总线，直到交换完成。这里的总线比如AHP，外部中断也是通过APB外设总线把中断信号传到cpu的中断控制器的，所以此时交换指令是不会被外部中断打断的。而内部中断又是指令引发的，所以也不会被打断，但是缺页中断可以打断。我感觉是因为缺页中断由MMU发出的电信号，而MMU在cpu内部所以和总线无关。

例3.22使用交换指令把一个存储器单元的内容放到寄存器r0，然后把r1的内容存储到该内存单元中。

```assembly
PRE
	mem32[0x9000] = 0x12345678
	r0 = 0x00000000
	r1 = 0x11112222
	r2 = 0x00009000
	SWP r0,r1,[r2];r0 = [r2],[r2] = r1
POST
	mem32[0x9000] = 0x11112222
	r0 = 0x12345678
	r1 = 0x11112222
	r2 = 0x00009000
```

交换指令多用于实现操作系统中的**信号量和互斥操作**。（原子操作、信号量、互斥锁都是由交换指令实现的，对堆栈的操作、保存上下文是由多寄存器装载和保存指令实现的，这个指令不可以被中断）从指令的语法可以看到，这条指令可以有一字节修饰符B，所以交换指令可以有字交换和字节交换两种形式。

例3.23显示使用SWP指令来保证数据交换期间不被其他任务改写，是一个信号量操作的简单实现。SWP指令占据总线直至交换完成。

```assembly
spin
	MOV r1, = semaphore
	MOV r2,#1
	SWP r3,r2,[r1];//将信号量存入r3中，将信号量置1bold the bus until complete
	CMP r3,#1;判断当前信号量是否为1
	BEQ spin;如果相等跳转到spin
```

这里将[r1]存入r3是为了比较当前信号量是否被另一个进程使用，如果为1表示确实被使用了，那么程序循环。如果为0则说明此时信号量没有被获取，跳出循环。无论信号量是否被获取，都将[r1] = 1，这是因为如果为0那么现在被当前进程获取了也是1了。

### 3.4软件中断指令

软件中断指令SWI可以产生一个软件中断异常，这为应用程序调用程序例程提供了一种机制，（说的是系统调用中触发软中断从而执行内核中的系统调用）

语法：SWI{<cond>}SWI_number

|      |          | lr_svc=SWI指令后面的指令地址，这是将下一个指令地址存入svc模式下的lr寄存器中，程序返回地址。 |
| ---- | -------- | ------------------------------------------------------------ |
|      |          | spsr_svc=cpsr，将cpsr当前程序状态寄存器内容存入svc模式下的spsr备份程序状态寄存器中进行备份 |
| SWI  | 软件中断 | pc=vectors+0x8，将向量表的0x8偏移地址送入pc程序寄存器中。    |
|      |          | cpsr模式=SVC，修改cpsr的[4:0]变成管理模式，这里就能看出来软中断的ARM工作模式是管理模式 |
|      |          | cpsr I=1(屏蔽IRQ中断)，nvczq_ift_USER，这里是将IRQ位置一表示屏蔽IRQ |

以便操作系统例程（系统调用）可以在特权模式下被调用。每个SWI指令有一个关联的SWI号(number)用于表示一个特定的功能调用或特性。

例3.24一个ARM工具箱中用于调试SWI的例子，是一个SWI号为0x123456的SWI调用。通常SWI指令是在用户模式下执行的。

```assembly
PRE
	cpsr = nzcVqift_USER;用户模式，条件V被触发，一般中断和快速中断不屏蔽，不使用Thumb指令集，如果也不使用Jazelle指令，那就是ARM指令了。
	pc = 0x00008000;这里的pc值对应的就是SWI指令的地址
	lr = 0x003fffff;lr= r4
	r0 = 0x12
	0x00008000 SWI 0x123456;因为SWI触发软中断会把向量表地址偏移0x8存入pc中，所以这里提到了pc
POST
	cpsr = nzcVqift_SVC;此时ARM工作模式切换成了SVC，但是这里没有禁止中断
	spsr = nzcVqift_USER;保存之前的cpsr寄存器内容
	pc = 0x00000008;向量表+0x8
	lr = 0x00008004;第一个就是保存程序返回地址，pc是0x00008000，那么下一个指令是32位之后，也就是+4
	r0 = 0x12;用于传递参数到内核态
```

SWI用于调用操作系统的例程，通常需要传递一些参数（比如系统调用号），可以通过使用寄存器来完成（eax寄存器，这个寄存器还有累加的功能）。上面的例子中，r0用于传递参数0x12，返回值也通过寄存器来传递。处理软件中断调用的代码段称为中断处理程序(SWI Handler)实际上是系统调用服务函数。

中断处理程序通过执行指令的地址获取**软件中断号**（对于中断下半部的软中断有索引号，这个索引号指的是软中断的优先级，其实也就是数组中的索引号，一共只用了9个，所以这里的软中断指的是软件模拟硬件中断），## 指令地址是从lr计算出来的 ##。（lr存入的是pc+4的地址是SWI指令的下一个指令地址，这里的指令地址指的是获取SWI指令地址）

---

SWI**指令引发的软中断和中断下半部的实现方式之一的软中断区别**

指令引发的软中断实际上是软件模拟硬件中断，通过指令引发保存上下文，包括中断服务程序也是指令把地址送入pc中。并且软中断期间会屏蔽一般中断。SWI指令后边的数字就是软件中断号

中断下半部的软中断是软中断是存放在结构体数组中，当中断上半部标记软中断或者内核线程ksoftirq唤醒软中断的时候才会执行。至于软中断的准备操作是由c语言设计的，并不是指令直接实现。软中断具有索引号，但是没有软件中断号。

----

SWI号由下式决定：

```assembly
SWI_NUMBER = (SWI instruction)AND NOT(0xff000000);这里其实就是清除了高八位
```

这里的SWI instruction就是实际处理器执行的32位SWI指令。这里指的是汇编指令被编译成32位的机械码么。SWI指令有很多种，就是根据SWI号进行区分的。

例3.25SWI处理程序开始部分的实现。

这个片段代码计算了正被调用的SWI号，并把它放进r10(这个寄存器是之前提到的堆栈限制，堆栈指针需要确保大于这个堆栈限制r10才可以使用，否则就是堆栈溢出了)。

从下面的例子可以看到，load指令先拷贝整个SWI指令到寄存器r10，然后使用BIC屏蔽了指令的高八位，获取SWI号。这里假定SWI是在ARM状态下被调用的。（肯定的，SWI号只能在32位汇编指令上使用这种方式获取。）

```assembly
SWI_handler
	;保存寄存器r0~r12和lr，这里就是保存寄存器上下文，esp并不是r13
	STMFD sp!,{r0-r12,lr};满堆栈，向下扩展地址，sp回写，从lr开始存入等价于STMDB对应的操作是LDMIA等价于LDMFD，D是不变的都是向下增长。堆栈指针如果是向下增长就说明STMxD只能是向下走，LDMxD是向上移动因为只有下面是空的，只有上面是有数据的。
	;read the SWI instruction
	LDR r10,[lr,#-4];装载寄存器，将lr-4作为地址的内容存入r10中，之前lr是执行SWI指令前的pc值+4，现在是将当初的pc值对应的指令存入r10中,当初的pc值其实就是存放SWI指令的地址。这里因为一条指令是4B，所以这里并不是指针加法，而是单纯的地址相加减，指针加法本身应该是汇编实现的，因为指针是汇编实现的，所以ARM指令中的pc/lr+-都是单纯的地址加减。
	;此时r10存放的是32位的SWI指令地址，通过屏蔽指令的高8位获得SWI号。
	BIC r10,r10,#0xff000000
	;既然r10已经获得了SWI号，接下来可以执行SWI触发的中断处理程序了
	BL service_routine
	;执行完中断服务程序之后恢复上下文
	LDMFD sp! {r0-r12,pc}^;堆栈操作不需要[]来读取寄存器值作为主存地址，因为sp指针就是指向主存的。这里的^是什么意思，强迫cpsr从spsr寄存器中恢复。
```

在寄存器r10中的值就是SWI号将被SWI处理程序用于调用相关的SWI服务子程序。有SWI号来确定对应的SWI处理程序。所以这就导致执行处理程序之前需要先计算出SWI号并存入r10中。

### 3.5程序状态寄存器指令

ARM指令集提供了2条指令，可直接控制程序状态寄存器psr。

MRS指令用于把cpsr或者spsr的值传送到一个寄存器；

MSR指令用于把寄存器的内容传送到cpsr或者spsr。这两条指令结合，可用于对cpsr和spsr进行读写操作。

指令语法:

```assembly
MRS {<cond>} Rd,<cpsr|spsr>
MSR {<cond>} <cpsr|spsr>_<fields>,Rm
MSR {<cond>} <cpsr|spsr>_<fields>,#immediate
```

| MRS  | 把程序状态寄存器的值送到一个寄存器中 | Rd=psr               |
| ---- | ------------------------------------ | -------------------- |
| MSR  | 把通用寄存器的值送到程序状态寄存器中 | psr[field]=Rm        |
| MSR  | 把一个立即数送到程序状态寄存器       | psr[field]=immediate |

在指令语法中可看到一个称为fields(域)的项，他可以是控制(c)、扩展(x)、状态(s)以及标志(f)的任意组合。这些域及其在程序状态寄存器中的特定字节区域，如图3.9所示。

图3.9中，控制域控制终端屏蔽、Thumb状态和处理器模式。例3.26将说明如何通过清除I屏蔽位来使能IRQ中断，这个例子使用了MRS和MSR指令来读写cpsr。

例3.26MRS指令先把cpsr的值复制到r1，然后使用BIC清除r1的位7；再使用MSR把r1的值复制到cpsr，使能IRQ中断。从这个例子可以看到代码如何保护cpsr中的其他设置为，而只修改控制域的I位。

```assembly
PRE
	cpsr = nzcvqIFt_SVC;屏蔽一般中断、快速中断、模式是管理模式
	MRS r1,cpsr;
	BIC r1,r1,#0x80;将0b10000000也就是第七位清空，写回r1
	MSR cpsr,r1
POST
	cpsr = nzcvqiFt_SVC
```

只有软中断或者中断才会把cpsr存入spsr，并且在用户模式下只能更改条件标志位f，nzcvqxxJ是标志域，ift[4:0]是控制域，扩展域和状态域没学过。

#### 3.5.1协处理器指令

协处理器指令用于扩展指令集。协处理器指令既可用于提供附加的计算能力，又可用于控制包括cache和内存管理的存储子系统。分为三种指令（数据处理和初始化cpu、寄存器和cp寄存器传送，cp寄存器和主存传送）

协处理器指令包括数据处理、寄存器传输以及内存传输指令。这里只对协处理器指令进行简要说明，因为协处理器指令和具体的协处理器相关。未定义模式其实就是遇到无法识别的指令导致的，比如译码阶段，cpu读取了协处理器指令自然就会无法识别了。

注意：协处理器指令只用于带有协处理器的ARM核。

语法：

```assembly
CDP {<cond>} cp,opcode1,Cd,Cn {,opcode2};cp表示协处理器编号，具体是哪个协处理器，Cd/Cn/Cm描述协处理器中的寄存器，opcode描述在协处理器中执行的操作。
<MRC|MCR> {<cond>} cp,opcode1,Rd,Cn,Cm{,opcode2}
<LDC|STC> {<cond>} cp,Cd,addressing
```

| CDP     | 协处理器数据处理-在协处理器内部执行一个数据处理操作 |
| ------- | --------------------------------------------------- |
| MRC MCR | 协处理器寄存器传输-把数据送入或取出协处理器寄存器   |
| LDC STC | 协处理器内存传输-从协处理器装载/存储一个内存数据块  |

在协处理器指令语法中，协处理器15也就是CP15是为系统控制预留的，比如内存管理、写缓冲控制、cache控制及寄存器识别等。之前也是只提到了CP15，uboot启动时不可以启动数据cache就是因为此时cpu还无法通过cp15控制cache，会导致读取错误。

例3.27把一个cp15寄存器拷贝到一个通用寄存器。

```assembly
;把协处理器CP15寄存器C0的内容拷贝到r10
MRC p15,0,r10,c0,c0,0;协处理器是cp15，拷贝到r10中，操作是0，操作的协处理器寄存器是c0，为啥有两个c0
```

#### 3.5.2协处理器15(cp15)指令语法

Cp15可以配置处理器核，并有一组专门的寄存器用于存储配置信息，比如例3.27所述。通过写一个值到一个寄存器来设置一种配置属性，比如打开cache。这就是所谓的初始化cpu了。

CP15被称为系统控制协处理器。MRC/MCR指令用于读/写CP15，在语法中Rd是内核目标寄存器，Cn是主寄存器，**Cm是辅寄存器**，**opcode2是辅寄存器修饰符**。辅寄存器通常也被称为扩展寄存器。

下面这个例子，把CP15的控制寄存器c1写到内核寄存器r1中

```assembly
MRC p15,0,r1,c1,c0,0;这里的c0就是辅寄存器
```

为了便于对CP15的配置寄存器进行说明，使用下面的缩写格式：

CP15:cX:cY:Z

第一部分，CP15定义他是协处理器15；冒号后的第二部分是主寄存器，X是0~15的值；第三部分是辅寄存器或扩展寄存器，Y同样是0~15的值；最后一项是opcode2，opcode2可以是一个0~7的值。

有些操作可能用到一个非零值(W)的opcode1，这种格式表示为：

CP15:w:cX:cY:Z，并没有提到这两个opcode的数字对应什么操作。

### 3.6常量的装载

读者可能已经注意到，ARM指令不用于把一个32位常量装入寄存器。都是把立即数装入寄存器。这里涉及到了SWI指令，ARM状态下的指令是32位的，所以指令中不可能再定义一个普通的32位的常量。MOV就是用来把32位数送入寄存器的？？？

为了便于变成，ARM增加了两条位指令，用于把一个32位的常量送入寄存器。

语法：LDR Rd,=constant

ADR Rd,label

| LDR  | 常量装载伪指令，这不是装载寄存器指令，(LDR r1,[r2]) | Rd=32位常量 |
| ---- | --------------------------------------------------- | ----------- |
| ADR  | 地址装载伪指令，这个没遇到过                        |             |

第一条伪指令用于把一个32位常量送入寄存器，（如果是把主存中的内容送入寄存器就是单寄存器装载指令了也是LDR），他的具体执行可以是任何可实现该指令的指令。如果要执行的操作不能用其他指令来编码，其实就是执行LDR指令了，执行存储器读。第二条伪指令把一个相对地址写入寄存器中，它将会使用一个包含pc相对地址的表达式进行编码。

例3.28显示使用LDR指令把一个32位常量0xff00ffff装入寄存器r0。

```assembly
LDR r0,[pc,#constant_number - 8 - {PC}];这句话没看懂。
constant_number
	DCD oxff00ffff
```

这个是使用了存储器访问来装载常量，对于时间要求苛刻的程序代价是较高的。

例3.29使用另一种方法来实现同样的功能-使用MVN指令。

例3.29使用MVN指令装载常量0xff00ffff到寄存器r0

```assembly
PRE
	MVN r0,#0x00ff0000
POST
	r0 = 0xff00ffff
```

这是把32位的逻辑非送入寄存器中。这里介绍的存储器读取和逻辑非都不属于把32位**常量**送入寄存器中，所以搞了两个伪指令。

下表列出两条伪指令在执行不同常量装载时的不同转换。第一条伪指令使用了一条简单的MOV指令（这里就是我想法）；第二条伪指令使用了一个pc相对地址的load，推荐使用第一条伪指令来装载常量，让编译器或者汇编器来选择实际的转换指令。使用反汇编的方法可以看到编译器或汇编器在常量装载时具体选择的指令。

| 伪指令             | 实际执行的指令         |
| ------------------ | ---------------------- |
| LDR r0,=0xff       | MOV r0,#0xff           |
| LDR r0,=0x55555555 | LDR r0,[pc,#offset_12] |

原来=0xff表示的是常量，#0xff表示的是立即数。所以确实没有32位常量送入寄存器的指令。其实=0xff是一个32位的地址，这个地址是常量，可以把其他寄存器地址送入r0中，然后[r0]这样操作其他寄存器。

从上表可以看出，可以避免存储器访问而使用其他指令来实现常量的存储，**这依赖于所要装载的常量的内容**（具体的实现方式由编译器或者汇编器根据常量内容决定），好的编译器和汇编器会使用灵活的方法来避免从存储器装载常量，这些工具有一些算法来寻找指令所需要产生的最理想的数，并最大限度地使用桶形移位器，用最佳的指令完成操作。如果通过这些方法不能产生所需的常量，那么就使用访问寄存器的方法解决。

LDR伪指令的执行

- 或者是用一条MOV指令，
- 或者用一条MVN指令产生一个值，
- 或者是用一条LDR指令从一个pc相对的存储器地址中读取数据。

另外一条比较有用的伪指令是ADR，或者称为一个相对地址指令。他可以把一个**指定标号**的地址，使用一个pc相对地址的加减放入寄存器Rd。

### 3.7ARMv5E扩展

ARMv5E扩展提供了许多新的指令。其中最重要的指令是16位数据的有符号乘累加指令。这些指令在许多ARMv5E的实现上都可以在一个周期内完成。

ARMv5E在操作16位数据时提供了更好的性能和更大的灵活性，这对于诸如16位数字音频处理等许多应用是很重要的。

| 指令                  | 说明                 |
| --------------------- | -------------------- |
| CL2{<cond>}Rd,Rm      | 零计数               |
| QADD{<cond>}Rd,Rm,Rn  | 有符号32位饱和加法   |
| QDADD{<cond>}Rd,Rm,Rn | 有符号双32位饱和加法 |
| 剩下的不介绍了。。    |                      |

#### 3.7.1零计数指令

零计数指令用于计算最高符号位与第一个1之间的零的个数。

例3.30一个CLZ的例子。

这个例子中，r1中的第一个1的位前面有27个0，执行CLZ后r0的值为27。CLZ指令在规格化数据时非常有用。

```assembly
PRE
	r1 = 0b0000000000000000000000000000010000
	CLZ r0,r1;计算r1中符号到1之间的零的个数
POST
	r0 = 27
```

#### 3.7.2饱和算术指令

通常的ARM算法指令在整数溢出时自动回卷，例如0x7fffffff+1=-0x80000000.因此，在设计算法时，必须注意不能超出一个32位整数的最大表示范围。

例3.31显示最大值超出范围的情况。

```assembly
PRE
	cpsr = nzcvqiFt_SVC
	r0 = 0x00000000
	r1 = 0x70000000(正数)
	r2 = 0x7fffffff
ADDS r0,r1,r2;S表示后缀+S，结果会反馈到cpsr的标志位
POST
	cpsr = NzcVqiFt_SVC;两个正数相加导致溢出并且结果为负导致N负，V溢出
	r0 = 0xefffffff(负数)
```

32位数中最高位是符号位，所以实际可用的位是31位，32位的最大正整数是0x7fffffff，此时相加超过了最大正整数，导致溢出，若使用ARMv5E指令，就可以得到一个饱和结果：

发生正溢时，结果将保持为最大的正数0x7fffffff。这就可以避免使用额外的代码来检查可能的溢出。

n是负数，c是进位，v是溢出，z是结果为0，q是饱和。

| 指令  | 饱和计算         |
| ----- | ---------------- |
| QADD  | Rd = Rn + Rm     |
| QDADD | Rd = Rn + (Rm*2) |
| QSUB  | Rd = Rn-Rm       |
| QDSUB | Rd = Rn -(Rm*2)  |

其实这里的饱和算术指令识别方式就是前缀为Q。

例3.32使用QADD指令完成例3.31同样的加法。

```assembly
PRE
	cpsr = nzcvqiFt_SVC
	r0 = 0x00000000
	r1 = 0x70000000(正数)
	r2 = 0x7fffffff(正数)
	QADD r0,r1,r2
POST
	cpsr = nzcvQiFt_SVC;这里因为饱和算术，不会变成负数，默认具有S的功能，会显示到cpsr中。
```

原本是比较指令可以不加后缀S就可以更改cpsr，饱和算术指令也可以。

可以看到，在寄存器r0中保存了饱和数，同时Q为被设置。Q标志说明饱和发生，他将一直保持，直到程序显式地清除。

#### 3.7.3ARMv5E乘法指令

下表列出了所有ARMv5E的乘法指令。其中，x和y分别用于选择一个32位寄存器中的2个16位哪个作为第一操作数，哪个作为第二操作数。这个域设置为T，表示使用高16位；设置为B，表示使用低16位。对于32位结果的乘累加操作，Q标志位指示累加是否溢出了有符号32位值。（这里的溢出属于饱和溢出，所以和V符号无关）

| 指令    | 有符号乘法[累加]               | 有符号结果 | Q标志位 | 计算操作                  |
| ------- | ------------------------------ | ---------- | ------- | ------------------------- |
| SMLAxy  | (16-bit * 16-bit)+32-bit       | 32位       | 更新    | Rd = (Rm.x * Rs.y) + Rn   |
| SMLALxy | (16-bit * 16-bit) + 64-bit     | 64位       | 无影响  | [RdHi,RdLo]+=Rm.x * Rs.y  |
| SMLAWy  | ((32-bit * 16-bit)>>16)+32-bit | 32位       | 更新    | Rd=((Rm * Rs.y)>>16 + Rn) |
| SMULxy  | (16-bit * 16-bit)              | 32位       | 无影响  | Rd = Rm.x * Rs.y          |
| SMULWy  | ((32-bit * 16-bit)>>16)        | 32位       | 无影响  | Rd = (Rm*Rs.y)>>16        |

原型是MLA这是32位乘累加，前缀+S表示有符号的32位，xy分别表示哪两个16位相乘。Wy表示32位与16位相乘并右移16位。后缀+L表示相加的是64位long类型。如果x=T表示前16位，y=B表示后16位。

另一个原型是MUL这是32位乘，同样前缀+S表示有符号。

例3.33显示乘法指令的使用方法。

这里使用有符号乘累加指令SMLATB。也就是使用前16位 * 后16位

```assembly
PRE
	r1 = 0x20000001
	r2 = 0x20000001
	r3 = 0x00000004
	SMLATB r4,r1,r2,r3;r4 = r1前16 * r2后16 + r3
POST
	r4 = 0x00002004;0x2000*0x1 + 0x4
```

指令把寄存器r1的高16位乘以寄存器r2的低16位，结果累加到寄存器r3，并把它写到目标寄存器r4中。

### 3.8条件执行

大多数ARM指令是可条件执行的，可指定指令只有当条件代码标志与给定的条件匹配时才执行。通过条件执行，可以改善性能和提高代码密度。

条件码是跟在指令助记符后面的2个字母，缺省条件是AL(always execute)，即无条件执行。

条件执行减少了分支 指令的数目，相应地减少了指令流水线的排空次数，从而改善了执行代码的性能。条件指令是ARM指令集与RISC指令集的区别之一。

条件执行主要依赖于两部分：条件码和条件标志。条件码位于指令中，条件标志位于cpsr中。

例3.34使用一个带有EQ条件码的ADD指令，指令只有在cpsr的zero位为1时才被执行。

```assembly
;r0 = r1 + r2 if zero flag is set
ADDEQ r0,r1,r2
```

不带S后缀的比较指令和数据处理指令也会更新cpsr中的条件标志，比如CMP和QADD。

例3.35为了说明条件执行的优点，通过这个例子中的一个简单的C代码片段，比较使用条件执行指令与不使用条件执行指令时的汇编代码情况。

```c
while(a!b)
{
    if(a>b)a-=b;else b-=a;
}
```

这里使用寄存器r1代表a，寄存器r2代表b，下面的代码是在ARM汇编器编写的同样算法(求最大公约数)的汇编代码，其中只使用了可条件执行的分支指令，其他指令都不是条件执行的。

```assembly
;最大公约数算法
gcd
	CMP r1,r2;比较r1和r2比较指令是一个不返回的减法指令
	BEQ complete;如果此时r1==r2那么，EQ检查nZcvq后执行B指令跳转到complete，这里是B指令加了EQ条件码，并不是条件执行指令。
	BLT lessthan;这里的LT也是一个条件码，如果小于的话跳转到lessthan
	SUB r1,r1,r2;如果不等于不小于，r1>r2则循环
	B gcd
lessthan;正常来讲是不需要进行跳转的，直接由条件执行代码判断执行即可。
	SUB r2,r2,r1
	B gcd
complete
...
```

现在与全部使用条件执行的代码来比较。可见，使用条件执行可大幅度地减少指令数目。

```assembly
gcd
	CMP r1,r2
	SUBGT r1,r1,r2;如果nz，则说明r1大于r2，执行SUB指令，而不是跳转
	SUBLT r2,r2,r1;如果Nz，说明r1小于r2
	BNE gcd;如果不相等跳转回gcd循环
```

### 3.9总结

本章讲述了ARM指令集。所有ARM指令都是32位的。算术指令、逻辑指令、比较指令及MOVE指令可使用内嵌的桶型移位器，以便在第2个寄存器Rm进入ALU之前对它进行预处理。比如乘除

ARM指令集有3种类型的load-store指令：单寄存器load-store指令(STR/LDR)、多寄存器load-store指令（保存上下文，LDMIA/STMDB/LDMFA/STMED）以及交换指令(SWP，信号量)。多寄存器load-store指令为堆栈的push-pop操作提供了一种有效的实现方式。ARM-Thumb过程调用标准(ATPCS，ARM处理器对寄存器的使用规则)把堆栈定义为递减式满堆栈。向下增加、sp指向存在数据的存储单元

软件中断指令产生一个软中断，使得处理器进入SVC模式，（lr=pc/spsr_svc=cpsr/pc=vectors+0x8/cpsr_USER=SVC/cpsr_I=i）这条指令调用了特权操作系统例程。程序状态寄存器指令可对cpsr和spsr进行读/写。ARm中海油专门用于优化32位常量 装载操作的特殊位指令LDR/ADR。具体执行伪指令还是LDR指令由常量作为地址决定。

ARMv5E扩展引入了零计数、饱和运算及增强乘法指令。零计数指令可计算一个二进制数的前导零的个数；饱和运算用来处理超过32位整数值的算法计算；增强乘法指令为16位乘法提供了更大的灵活性。

大多数的ARM指令的可被条件执行，对一个特定的算法，使用条件指令可大幅度减少所需的指令数目，不需要额外的跳转判断指令。直接由执行的指令进行判断即可。

## 第四章、Thumb指令集

- Thumb寄存器的使用，（不同模式有着banked寄存器，不同状态还区分寄存器）
- ARM-Thumb交互，（两种指令集的交互应该和未定义模式有关）
- 其他分支指令，（之前只了解到条件分支）
- 数据处理指令
- 单寄存器load-store指令
- 多寄存器load-store指令
- 堆栈指令
- 软件中断指令，（看起来Thumb指令和ARM指令种类差不多）
- 总结

本章介绍Thumb指令集。Thumb把32位ARM指令集的一个子集进行编码，称为一个16位的指令集。在16位外部数据总线宽度下，在ARM处理器上使用Thumb指令的性能要比使用ARM指令的性能更好；而在32位外部数据总线宽度下使用Thumb指令的性能差。因此，Thumb指令多用于**存储器受限的一些系统中**。

相对于ARM指令集，使用Thumb指令集可获得更高的代码密度-一个可执行的程序在内存中所占的空间。在存储器受限的嵌入式系统中，代码密度很重要，成本压力也会限制存储器的大小、数据宽度和速度。

平均而言，对于同一个程序，使用Thumb指令实现所需的存储空间，要比等效的ARM指令实现少30%左右。图4.1显示了对于实现同样的除法运算，使用ARM指令和使用Thumb指令的汇编代码。虽然Thumb指令的实现使用了更多的指令，但是它所占的总的存储空间却比较小。（Thumb指令没有条件执行，无法添加后缀）。代码密度是Thumb指令集的一个主要优势。由于Thumb指令集的设计是**面向编译器的，而不是针对手写汇编**，所以推**荐使用高级语言C或者C++来变成，然后用编译器生成Thumb指令的目标代码**。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1681370192477.png" alt="1681370192477" style="zoom:33%;" />

ARM指令虽然因为条件执行的原因数量少，但每个指令是32位的，反而更占用空间，而Thumb指令数量多，但是每个指令16位。

每一条Thumb指令都和一条32位的ARM指令相关，下图显示了一条Thumb加法指令ADD译码成等效的ARM加法指令。

下表给出了在ARMv5TE架构下的THUMBv2中的所有的Thumb指令（ARMv7是ARM指令集的版本，THUMBv2是Thumb指令集的版本）。在ThumbISA(Thumb指令集架构)中，只有分支指令可被条件执行；同时由于16位空间的限制，桶型移位操作入ASR(有符号的算术移位)、LSL、LSR和ROR(循环右移)，也变成单独的指令。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1681370712070.png" alt="1681370712070" style="zoom:33%;" />

ThumbISA下的ADD指令是两个参数，直接将立即数3相加存入r0中

### 4.1Thumb寄存器的使用

在Thumb状态下，不能直接访问所有的寄存器，只有寄存器r0~r7是可以被任意访问的，寄存器r8~r12只能通过MOV或者ADD或CMP指令访问。（这正是分组寄存器，快速中断可以全访问，其他异常模式只能访问r13/r14）CMP指令和所有操作r0~r7的数据处理指令都会影响cpsr中的条件标志。

| 寄存器 | 访问                                            |
| ------ | ----------------------------------------------- |
| r0~r7  | 完全访问，未分组寄存器                          |
| r8~r12 | 只能通过MOV，ADD及CMP访问，快速中断独享的寄存器 |
| r13sp  | 限制访问                                        |
| r14lr  | 限制访问                                        |
| r15pc  | 限制访问                                        |
| cpsr   | 只能间接访问                                    |
| spsr   | 不能访问，只有发生中断或异常才能进行备份        |

从上表可以看出，不能直接访问cpsr和spsr，换句话说，**没有与MSR和 MRS等价的Thumb指令**，这两个指令在ARM状态下是只有异常模式才能使用的指令。在Thumb状态下没有相应的指令。

为了改变cpsr或spsr的值，必须切换到ARM状态，使用MSR和MRS来实现。同样在Thumb状态下**没有协处理器指令**，要访问协处理器来配置cache和进行内存管理，也必须在ARM状态下。

### 4.2ARM-Thumb交互

ARM-Thumb交互是指对汇编语言和C/C++语言的ARM和Thumb代码进行连接的方法。他进行两种状态间的转换。在进行这种转换时，有时必须使用额外的代码，这种代码被称为胶合(venerr)。ATPCS定义了ARM和Thumb过程调用的标准。（ARM处理器对寄存器使用的规则）

从一个ARM例程调用一个Thumb例程，内核必须切换状态。状态的变换由cpsr的T位来显示。在跳转到另一个状态的例程时，**BX和BLX分支指令可用于ARM和Thumb状态的切换**。BXlr指令从一个例程返回，如果需要，也可以进行状态切换。

BLX指令在ARmv5T指令集版本中引入。在ARmv4T核中，连接器在子程序调用时，使用胶合来完成状态的切换。连接器不是直接调用例程，而是通过调用胶合，**由胶合使用BX指令切换到Thumb状态。**

有两个版本的BX和BLX指令：ARM指令和等效的Thumb指令。ARM的BX指令**只有当Rn中地址的最低位为1时，才进入Thumb状态**；否则进入ARM状态，Thumb的BX指令同样。

语法：

```assembly
BX Rm
BLX Rm|label
```

| BX   | Thumb版本分支切换         | pc = Rn&0xfffffffe;最后一位为0，T=Rn[0]，T位由Rn第0位赋值，为1会进入Thumb状态 |
| ---- | ------------------------- | ------------------------------------------------------------ |
| BLX  | Thumb版本带链接的分支切换 | lr=BLX后面的指令地址+1；这里是执行完会跳转回来；pc = label，T=0;pc=Rm&0xfffffffe;T=Rm[0]; |

与ARM版本的BX指令不同，Thumb BX指令不能被条件执行。

例4.1显示使用ARM BX和Thumb BX的一个小代码段。

可以看到，进入Thumb的分支地址的最低位是置1的，这将是置位cpsr中的T位而进入Thumb状态。使用BX指令时，返回地址不是自动保留的，所以在跳转指令调用前，通过显式地使用MOV指令来设置返回地址。

```assembly
;ARM代码
CODE32;字对齐
LDR r0,=thumbCode+1;这里使用伪指令，将常量地址加载到r0中，+1表示进入Thumb状态
MOV lr,pc;设置返回地址，因此pc中保存的是下一条指令，并不是当前正在执行的指令地址。二级流水线中pc保存的是当前执行指令的下一条指令，三级是下两条指令，这里其实有点问题。
BX r0;根据r0的地址最后一位决定切换到什么状态
;继续其他代码
;Thumb代码
CODE16;半字对齐
thumbCode
	ADD r1,#1
	BX lr;返回ARM状态，怎么确定thumbCode标志地址末尾不是0的呢，是字节对齐导致的。
```

如果没有通过位0的强制置1来进行状态转换，那么分支切换指令也可以用作一个绝对跳转指令。

下面是具体的展示下切换跳转到的地址

```assembly
;address(thumbCode)=0x00010000
;cpsr=nzcvqIFt_SVC
;r0=0x00000000
0x00009000 LDR r0,=thumbCode + 1
;cpsr=nzcvqIFT_SVC
;r0=0x00010001
0x000090008 BX r0
;cpsr=nzcvqIFT_SVC
;r0=0x00010001
;pc=0x00010000，这个是重点，最低位置1只是为了修改cpsr的T位，跳转的地址依旧是r0
```

例4.2使用BLX指令代替BX指令简化了Thumb例程的调用，因为BLX指令在链接寄存器中自动设置了返回地址。

```assembly
CODE32
	LDR r0,=thumbRoutine+1;进入Thumb模式
	BLX	r0;跳转到Thumb代码
	;其他代码
CODE16
	ThumbRoutine
        ADD r1,#1
        BX r14;返回ARM状态，这段指令就是BLX自动设置的了
```

### 4.3其他分支指令

有两个标准分支指令的变体，B指令：第一个变体与ARM版本指令相似，可条件执行，跳转被限制在有符号8位立即数所表示的范围内，或者是-256~254直接；第二个变体不可条件执行(没有条件码部分)，但扩展了有效跳转范围-有符号的11位立即数表示的范围，或-2048~+2046字节。

条件分支指令是Thumb指令中唯一可以条件执行的指令。

语法：

```assembly
B<cond> label
B label
BL label
```

| B    | 分支指令         | pc=label                     |
| ---- | ---------------- | ---------------------------- |
| BL   | 带链接的分支指令 | pc=label;lr=BL后的指令地址+1 |

BL指令不可条件执行，可以在大约+/-4MB的范围内跳转，因为BL和BLX**指令被转换成一对**16位的Thumb指令，因而上述跳转范围是合理的。这对指令中的第一条包含跳转偏移量的高位部分。第二条包含其低位部分，这些指令必须成对使用。

这里列出了从BL子程序调用返回的不同指令：

```assembly
MOV pc,lr;
BX lr
POP {pc}
```

POP堆栈操作指令并没有写具体情况，是满堆栈、向下增长的情况。

### 4.4数据处理指令

数据处理指令可以操作寄存器中的数据，包括MOV指令、算术指令、移位指令、逻辑指令、比较指令和乘法指令。Thumb数据处理指令是ARM处理指令的一个子集。

这些指令与等价的ARM指令使用 相同的格式，大多数的Thumb数据处理指令操作寄存器r0~r7，同时会更新cpsr。但是下列指令是例外：(ARM指令中的比较指令和数据处理指令中的饱和算术指令QADD是不需要后缀S也可以更新cpsr的标志位的)

```assembly
MOV	Rd,Rn
ADD Rd,Rm
CMP Rn,Rm
ADD sp,#immediate
SUB	sp,#immediate
ADD	Rd,sp,#immediate
ADD	Rd,pc,#immediate
```

这些指令可以操作寄存器r8~r14和pc，在使用r8~r14时，除了CMP指令外，其他指令不改变cpsr中的条件标志，CMP指令总是更新cpsr的。

例4.3一个简单的Thumb ADD指令

指令带有两个寄存器r1和r2，把它们相加后的结果放到寄存器r0，同时更新cpsr的值。

```assembly
PRE
	cpsr = nzcvqIFT_SVC
	r1 = 0x80000000
	r2 = 0x10000000
	ADD r0,r1,r2
POST
	r0 = 0x90000000
	cpsr = NzcvqIFT_SVC;为什么这里N变成负数了，如果是有符号的32位最大只能是0x7fffffff，而且书里没有q标志位
```

例4.4与ARM方式不同，Thumb的桶形移位操作（ASR/LSL/LSR/ROR）是单独的指令。并不是（MOV r0,r1,LSL,#1）这种配合MOV一起执行的指令。

这个例子显示了逻辑左移LSL指令，把寄存器r2乘以2。

```assembly
PRE
	r2 = 0x00000002
	r4 = 0x00000001
	LSL r2,r4;这里应该是把r4中的内容当成立即数表示移位<<1，10<<1=100=0x4
POST
	r2 = 0x00000004
	r4 = 0x00000001
```

### 4.5单寄存器load-store指令

Thumb指令集支持寄存器的装载和存储，即LDR和STR指令。这些指令使用前变址寻址方式：寄存器偏移和立即数偏移。执行前改变。

下表列出了不同的寻址方式，第一种寻址方式为寄存器偏移，使用过一个基址寄存器Rn加上寄存器偏移量Rm;第二种寻址方式使用基址寄存器Rn加上一个5位的立即数或者一个依赖于数据尺寸的值。5位的偏移在指令中的编码根据8位访问、16位访问及32位访问，分别乘以1,2,4。（数据尺寸是什么？这里的访问位数不同还需要额外乘数是考虑到三种状态吗）

| 类型             | 语法                |
| ---------------- | ------------------- |
| load/store寄存器 | [Rn,Rm]             |
| 基址寄存器+偏移  | [Rn,#immediate]     |
| 相对寻址         | [pc\|sp,#immediate] |

移位和load/store的Thumb状态指令都增加了可以使用寄存器值进行偏移的功能。

例4.5显示两个使用前变址寻址方式的Thumb指令，他们执行前的条件是一样的。

```assembly
PRE
	Mem32[0x9000] = 0x00000001
	Mem32[0x9004] = 0x00000002
	Mem32[0x9008] = 0x00000003
	r0 = 0x00000000
	r1 = 0x00009000
	r4 = 0x00000004
	LDR r0,[r1,r4];r0 = [r1+r4]=[0x00009004]=0x2
POST
	r0 = 0x00000002
	r1 = 0x00009000;因为并不是回写前变址所以r1的值不变
	r4 = 0x00000004
	LDR r0,[r1,#0x4];和上面没区别
POST
	r0 = 0x2
```

这2条指令执行同样的操作。唯一的区别就是第二条LDR使用了一个固定偏移，而第一条LDR的偏移依赖于寄存器r4。

### 4.6多寄存器load-store指令

Thumb指令集的多寄存器load-store指令是ARM指令集的多寄存器load-store指令的简化形式。在Thumb指令集的多寄存器load-store指令只支持后增量IA寻址方式。（单寄存器就是通过[r0,#1]，[r0],#1,[r0,#1]!）这是三种来识别的前变址、后变址和回写前变址的。

语法：<LDM|STM>IA Rn1,{low register list:r0~r7}

| LDMIA | 装载多个寄存器 | {Rd}*N<-mem32[Rn+4 *N],Rn=Rn+4 * N |
| ----- | -------------- | ---------------------------------- |
| STMIA | 存储多个寄存器 | {Rd}*N->mem32[Rn+4 *N],Rn=Rn+4 *N  |

这里N是寄存器列表中寄存器的数目。从表中可看到，指令执行后总是更新基址寄存器，机制寄存器和可以使用的寄存器列表仅限于r0~r7。

例4.6保存r1~r3到内存地址0x9000~0x900c，并且更新基址寄存器r4.。徐璈指出的是这里更新字符！不是可选的，是固定的。

```assembly
PRE
	r1 = 0x00000001
	r2 = 0x00000002
	r3 = 0x00000003
	r4 = 0x9000
	STMIA r4!,{r1,r2,r3};这里的回写是不可修改的
POST
	mem32[0x9000] = 0x00000001
	mem32[0x9004] = 0x00000002
	mem32[0x9008] = 0x00000003
	r4 = 0x900c;这里是会+4三次地址，最后得到0x900c
```

### 4.7堆栈指令

Thumb的堆栈操作与等效的ARM指令是不同的，因为他们使用了更传统的POP和PUSH的概念。

语法：

```assembly
POP{low_register_list{,pc}}
PUSH{low_register_list{,lr}}
```

| POP  | 出栈 | Rd*N<-mem32[sp+4 *N],sp=sp+4 *N       |
| ---- | ---- | ------------------------------------- |
| PUSH | 入栈 | Rd * N->mem32[sp+4 * N],sp = sp-4 * N |

注意：在指令中没有堆栈指令，这是因为在Thumb操作中，**寄存器r13是固定作为堆栈指针用的**，**sp是自动更新的**。可操作的寄存器列表仅限于寄存器r0~r7。

PUSH指令可以操作的寄存器还包括链接寄存器lr，同样POP指令可以操作pc。这为子程序的进入和退出提供了支持。**堆栈指令仅支持递减式满堆栈操作**。ARM状态也是如此，只使用到LDMFD+STMFD

例4.7使用PUSH和POP指令，子程序ThumbRoutine使用带链接的分支指令BL来调用。

```assembly
;调用子程序
BL	ThumbRoutine
;其他代码
ThumbRoutine
PUSH	{r1,lr};进入子程序，因为只能对堆栈指针操作，所以这里不显式sp，等价于STMFD sp!,{r1,lr}入栈是从右到左出栈是从左到右
MOV		r0,#2;
POP		{r1,pc};从子程序返回
```

链接寄存器lr和r1被压入堆栈，在返回时，寄存器r1的值被原来的r1出栈恢复，pc被原来入栈的lr的值覆盖。完成从子程序返回，lr的值应该是指向当前正在被执行的指令的下一个指令。

### 4.8软件中断指令

与ARM指令集下的软件中断指令相似，Thumb软件中断指令SWI也产生一个软件中断异常。在Thumb状态下，如果有任何中断或者异常标志出现，那么处理器就会自动回到ARM状态去进行异常处理。SWI指令的高八位清除掉就是软中断号。

语法：SWI	immediate

| 汇编指令 | 指令名称 | 具体实现                                                     |
| -------- | -------- | ------------------------------------------------------------ |
| SWI      | 软件中断 | lr_svc = pc;因为软中断在用户模式触发进入管理模式执行spsr_svc = cpsr;pc = vectors+0x8;cpsr_MODE = USER->SVC;cpsr_I=1;cpsr_T=0; |

这里多了最后一步就是切换回ARM状态。其实不仅仅要置位T还有J只有两者都为0才表示进入ARM状态。

Thumb SWI指令与等效的ARM指令有同样的作用和几乎完全相同的语法。区别是**Thumb SWI数目限制在0~255**，并且不能条件执行。（只有跳转指令B可以条件执行）。

例4.8显示Thumb SWI的执行。

注意：在执行该指令后，处理器从Thumb状态切换到ARM状态。

```assembly
PRE
	cpsr = nzcVqifT_USER;溢出、中断不屏蔽，Thumb状态，USER模式
	pc = 0x00008000
	lr = 0x003fffff
	r0 = 0x12
	0x00008000 SWI 0x45;这里0x45是SWI软中断号
POST
	cpsr = nzcVqift_SVC;这里为啥是i而不是I，之前在ARM状态下也是i
	spsr = nzcVqifT_USER
	pc = 0x00000008
	lr = 0x00008002;这里石锤了，果然是lr = pc+2，因为16位所以地址加两个存储单元。
	r0 = 0x12
```

### 4.9总结

本章主要介绍了Thumb指令集。所有的Thumb指令长度都是16位，Thumb代码可以提供比ARM代码高大约30%的代码密度。大多数Thumb代码都是由C或者C++这样的高级语言编译而成的。（因为Thumb指令对于大多数指令不支持条件执行，所以编写起来麻烦一些，往往是编写c/c++然后由汇编器生成Thumb指令）。

ATPCS定义了ARM和Thumb代码如何相互调用，称为ARM-Thumb交互，交互使用分支切换指令BX和带链接的分支切换指令BLX来改变状态，并跳转到特定的例程。(=Thumb+1)

在Thumb指令集中，只有分支B系列指令可以条件执行，桶形移位操作（ASR/LSR/LSL/ROR)是单独的指令。(ROR是无符号循环右移，A开头的是算术右移有符号的)。

多寄存器load-store指令只支持**后增量IA寻址方式**。Thumb指令集包括POP和PUSH指令，用以进行堆栈操作，这些指令只支持递减式满堆栈。(ARM处理器把堆栈定义成递减式满堆栈，但是ARM状态下存在递增式空堆栈的指令，而Thumb指令没有)。

Thumb指令不可以访问协处理器、cpsr和spsr。（不可以直接访问，没有MSR和MRS指令同样也没有MRC和MCR指令）

## 第五章、高效的C编程

- C编译器及其优化概述
- 基本的C数据类型
- C循环结构
- 寄存器分配
- 函数调用
- 指针别名
- 结构体安排
- 值域
- 边界不对齐数据和字节排序方式（大小端）
- 除法
- 浮点运算
- 内联函数和内嵌汇编
- 移植问题
- 总结

本章将帮助读者在ARM处理器上编写高效的C代码。我们将通过许多小的例程来说明编译器如何把C代码转换成ARM汇编代码。当读者了解这种转换后，就可以区分出执行速度快和慢的C代码。这些例子都是基于普通C语言的，但这些技术也同样适用于C++语言。

本章首先介绍C编译器机器优化，帮助读者理解C编译器在优化代码时所碰到的一些问题。理解这些问题，将有助于编写出在提高执行速度和减小代码尺寸方面更高效的C源代码。后面的小节是按主题来组织的。

5.2和5.3节以一个数据包校验和的简单程序为例。分析、说明了如何优化一个基本的C循环。5.4和5.5节介绍了如何优化一个完整的C函数体，包括在一个函数内编译器如何分配寄存器，如何减少函数调用时的开销。

5.6~5.9节分析了有关存储器操作的问题，包括指针操作、数据打包和高效的存储器访问。5.10~5.12节描述了ARM指令通常不直接支持的一些基本操作，也可以使用内联函数和内嵌汇编来增加自己的基本操作。

最后总结了把C代码从其他的体系结构移植到ARM结构时会碰到的一些问题。

### 5.1C编译器及其优化概述

本章假定读者熟悉C语言，也有一些汇编语言编程方面的知识。后者虽然不是必须的，但是对于理解后面例子编译后的汇编输出结果会有帮助。

众所周知，优化代码需要花费时间，而且会降低源代码的可读性。所以通常只对**经常被调用且对性能影响较大的函数**进行优化。为了找到这些函数，推荐使用大多数ARM编译和调试器都带的性能分析工具。另外，用源代码注释来评注那些不容易理解的优化代码，可以提高代码的可维护性。

C编译器必须逐字逐句地把C程序转换成汇编程序，这样编译器就不会漏掉所有可能输入。实际上，许多输入组合是不可能的或不会出现的。首先来看一个例子，函数memclr()用来清除从地址data开始的n字节的存储单元内容。从这个例子中可以看到编译器会碰到的问题。

```c
void memclr(char *data,int N)
{
    for(;N>0;N--)
    {
        *data = 0;
        data++;
    }
}
```

首先，编译器无论多高级，也不可能知道N的输入值是否可以是0。因此，在第一个循环开始之前，编译器需要对这个问题进行明确的检查。

其次，编译器也不知道数组指针data是否是4字节边界对齐的。如果是4字节对齐的，那么编译器就可以使用init而不是char类型的指针，这样一次就可以清除4字节的存储单元。而且，编译器也不知道N是否是4的整数倍，如果N是4的整数倍，那么编译器可以重复循环体中的内容4次或者利用int类型的指针一次存储4字节。

然而，编译器必须是保守的，只能假设N的所有可能的值和data所有可能的边界值。这些问题将在5.3节中详细讨论。

总之，要编写高效的C代码，必须了解哪些地方C编译器是保守的，编译器涉及到的处理器结构的限制，以及一些特殊的C编译器限制。

本章大部分内容都围绕着上述前两点，并适用于所有的ARM C编译器。第3点就要依赖于编译器供应商和编译器的修订版本了，读者须参考编译器的有关文档，或者亲自对编译器做各种测试。

为了保证例子的一致性，已经用下面的C编译器测试过所有程序：

- ARM Developer Suite version 1.1(ADS 1.1)的armcc可直接从ARM购买这个版本或后续版本的使用许可。
- Arm-elf-gcc version 2.95.2是GNU C编译器的ARM版本gcc，是免费使用的。

本书中，使用ADS1.1下的armcc来生成例子中的汇编输出结果。下面的脚本显示了如何对C文件test.c使用armcc。可以使用这种方法来重新生成程序的编译结果。

```shell
armcc -0time -c -o test.o test.c
fromelf -text/c test.o > test.txt
```

armcc默认是全部优化功能有效(-02命令行选项)。-0time选项表示执行速度优化高于代码空间的优化，这主要是影响编译器针对for和while循环的处理。（对于编译器优化，我只知道volitate可以强制编译器从主存中读取数据，属于防止编译器优化的一部分）

如果使用gcc编译器，那么下面的脚本可以生成类似的汇编输出：

```shell
arm-elf-gcc -02 -fomit -frame -pointer -c -o test.o test.c
arm-elf-objdump-d test.o > test.txt
```

第二行表示把test.o的内容覆盖到test.txt。GNU编译器在默认状态下所有优化都是关掉的。-fomit -frame -pointer选项阻止GNU编译器保留**结构指针**寄存器。结构指针可以帮助调试窗口**显示存储在堆栈的局部变量**。但是，如果保留，效率将会降低，所以对性能有要求的代码就不要使用结构指针。

项目中使用的是通用交叉编译器。

```shell
arm-none-linux-gnueabihf-gcc
```

### 5.2基本的C数据类型

首先来研究一下ARM编译器如何处理基本的C数据类型，将会发现其中一些数据类型用作局部变量时，执行效率要比其他类型的高。同时，在一定的寻址模式下，装载/存储不同类型的数据，效率是不一样的。

ARM处理器内部是32位寄存器和32位的数据处理操作。其体系结构是RISC load/store结构。换句话说，数据在使用前必须将其从内存装载到内部寄存器，任何算术或者逻辑指令都不能直接在存储器里进行数据操作。

早期版本的ARM结构(ARMv1~v3)为装载和存储无符号8位和无符号/有符号32位数据提供了硬件支持。这些体系结构都是用于比ARM7TDMI更早的处理器。8位或者16位数据在装载/存储ARM寄存器之前，先要扩展成32位。无符号数把0作为扩展位，有符号数则按照符号位扩展。这意味着装载int类型的数据无须花费多余的指令时间来进行位扩展。同样在存储时，8位或者16位的数据必须放到寄存器的低8位或者低16位。而一个int或更小类型的传送，存储时就不需要花费额外的指令时间了。

ARMv4及其以后的体系结构可以使用新增的指令来直接装载和存储一个带符号8位和16位数据。由于这些指令都是后来增加的，他们并不支持早于ARMv4指令集的许多寻址方式。在后面小结中的例子checksum_v3将会看到这种影响。

ARMv5增加了支持64位数据的load和store指令，ARM9E及其以后的核都支持这些指令。

比ARMv4早的ARM处理器并不能很好地处理有符号的8位或者任何16位数据，因此，在ARM C编译器中定义的char类型是8位无符号的，而不像其他编译器默认是8位有符号的。

下表中说明了armcc和gcc编译器对ARM文件所使用的数据类型映射。当把代码从其他体系结构的处理器移植到ARM处理器时，对于char数据类型要特别注意，因为他可能会引入一些问题。比如经常使用一个char类型的数据i作为循环计数器，循环的持续条件是i>=0。由于i对ARM编译器来说是一个无符号的数，这个循环将永远不会结束。

幸运的是，armcc在这种情况下会给出一个警告：unsigned comparison with 0。另外，编译器也提供了补充选项，，可以使char类型变成带符号的。例如，在gcc中命令行选项-fsigned-char就可以将char转换成有符号类型。在armcc中命令行选项-zc也有同样的效果。

与本书的其他部分一样，这里都是假定使用ARMv4体系结构及其以上的处理器，包括ARM7TDMI及其以后所有的处理器。

| C数据类型 | 表示的意义         |
| --------- | ------------------ |
| char      | 无符号8位字节数据  |
| short     | 有符号16位半字数据 |
| int       | 有符号32位字数据   |
| long      | 有符号32位字数据   |
| long long | 有符号64位双字数据 |

#### 5.2.1局部变量类型

基于ARMv4体系结构的处理器能高效地装载和存储8位、16位和32位数据。但是，大多数的ARM数据处理操作都是32位的。基于这个原因，局部变量应尽可能使用32位的数据类型int或者long。即使在处理8位或者16位的数值时，也应避免使用char和short数据类型作为局部变量。（为什么这里要单独举出局部变量呢）

唯一的例外情况是，需要使用char或者short类型的数据溢出归零特性时，如模运算255+1=0，就要使用char类型。

为了说明局部变量类型的影响，先来看一个简单的例子：checksum校验和函数的功能是计算一个数据包内的数据总和。这个例子具有很普遍的意义，因为大多数的通信协议都有校验或者循环冗余校验CRC程序来检查一个数据包里是否有错误。

下面的程序用来计算一个包含64个字的数据包的校验和。其说明了为什么对局部变量应该避免使用char类型。

```c
int checksum_v1(int*data)
{
    char i;
    int sum=0;
    for(i=0;i<64;i++)
    {
        sum+=data[i];
    }
    return sum;
}
```

初看一下，似乎声明i为char类型是没有什么问题的，甚至可能会觉得一个char类型的数据比int类型的数据占用更小的寄存器空间或者更小的ARM堆栈空间。其实对ARM来说，这两个设想都是错误的。所有的ARM寄存器都是32位的，所有的堆栈入口也是32位的。而且，为了正确执行i++，编译器必须解决i=255时的情况，因为对于char数据类型的i来说，255+1=0。因为编译器并不知道要循环到64，只是知道如果循环到256的话就会溢出。

这个函数经过编译后的输出结果如下，这里增加了标号和注释，以使汇编语言更加清晰。

```assembly
checksum_v1
	MOV r2,r0;r2 = r0
	MOV r0,#0;r0 = 0
	MOV r1,#0;i=0
checksum_v1_loop
	LDR r3,[r2,r1,LSL,#2];r3 = data[i]，这里是先对r1进行逻辑左移也就是无符号的向左移动2位，乘4，r3 = [r2 + r1*4]这里其实就是将i*4这是因为data数组是32位的所以应该偏移4取地址
	ADD r1,r1,#1;r1 = i + 1
	AND r1,r1,#0xff;i = (char)r1这里实现了强制转换的原理，就是取低八位存入r1中。就是这里实现的溢出问题
	CMP	r1,#0x40;compare i,64判断当前i是否大于64，对于比较函数是自动更新cpsr寄存器的条件标志的。
	ADD r0,r3,r0;r0 = r3 + r0，sum += r3，为什么这里判断完不是跳转而是继续执行。要么ADD变成ADDEQ
	BCC checksum_v1_loop;if(i<64)loop，这里是助计符CC表示小于，CS表示大于，但常用的是GT大于，LT小于
	MOV pc,r14;return sum
```

----

实际上溢出问题：强制转换在汇编上的实现是取低八位存入本身。AND进行与运算。

------

现在把上面的程序段与把i声明为unsigned int类型时比较下：

```assembly
checksum_v2
	MOV r2,r0;r2 = data
	MOV r0,#0;r0 = 0
	MOV r1,#0;i = 0
checksum_v2_loop
	LDR r3,[r2,r1,LSL #2];r3 = data[i];这里i需要乘4
	ADD r1,r1,#1;r1++
	CMP r1,#0x40;i比较64
	ADD r0,r3,r0;sum += r3
	BCC checksum_v2_loop;if(i<64) goto loop
	MOV pc,r14;return sum，这里r14是链接寄存器，存入pc中表示跳转到下一条指令。
```

第一种情况，在i和64直接比较前，编译器额外增加了AND指令来保证i的范围为0~255，在第二种情况下，这条指令省略了，毕竟2^8=256这是太小了，编译器认为存在溢出的情况，所以需要增加溢出的具体实现。

接下来，假设数据包中的数据是16位的，需要计算一个16位的校验和功能。试写出下面的C代码：

```c
short checksum_v3(short * data)
{
	unsigned int i;
    short sum = 0;
    for(i = 0;i < 64;i++)
    {
        sum = (short)(sum + data[i]);//这里采用的校验方法是求和校验
    }
    return sum;
}
```

读者可能会疑惑，为什么循环体内的代码不是sum+=data[i]，如果选择了armcc编译器中隐式数据宽度窄化警告(implicit narrowing cast warning)选项-W+n，编译上述代码时会出现一个警告。

其实就是说**表达式sum+data[i]是整数类型的**，所以**只能进行数据宽度窄化**(隐式或者显式，其实就是强制转换成short类型)，再赋给一个short类型的数据。见下面的汇编输出结果，注意编译器必须增加指令来实现数据宽度窄化

```assembly
checksum_v3
	MOV r2,r0;r2 = data
	MOV r0,#0;sum = 0
	MOV r1,#0;i = 0
checksum_v3_loop
	ADD r3,r2,r1,LSL #1;r3 = &data[i]，这里是将r1*2因为short16位，与data基地址偏移后的地址存入r3。
    LDRH r3,[r3,#0];这里是将r3寄存器保存的地址中读取2个存储单元，这里+0没意义，r3 = data[i]，这里的意思就是LDRH不支持移位
    ADD r1,r1,#1;i++
    CMP r1,#0x40;compare i,64
    ADD r0,r3,r0;r0 = sum+r3
    MOV r0,r0,LSL #16;将r0左移16位，此时此时只保留最低位的16位
    MOV r0,r0,ASR #16;再右移16位，然后把符号位补齐左侧空缺。高16位被符号位填充
    BCC checksum_v2_loop
    MOV pc,r14
```

这个循环要比前面的例子checksum_v2的循环多了三个指令，对于额外的指令有以下两种解释：

- LDRH指令不能像checksum_v2中的LDR指令一样支持移位地址偏移，就是不支持移位地址寻址方式，**不能在LDRH指令中同时实现地址偏移和地址寻址操作**。所以在循环体中第一条ADD指令用来计算数组下标i的地址。LDRH指令只能从一个没有偏移量的地址装入数据。由于LDRH指令是ARM指令集后增加的，所以相对于LDR指令，他的寻址方式较少。

- 使得total+array[i]强制转换成short类型需要两条MOV指令。编译器先左移16位，然后右移16位，以此实现一个16位符号扩展。右移是符号位扩展移位，复制了符号位来填充高16位。

  -----

  之前并没有做过算术右移ASR的例子，这里指的是算术右移若干位，左侧的位置用最高位也就是符号位补齐。

  ----

要避免第二个问题（校验和每次循环强转成short），可以**使用int类型的变量来计算**、保持校验和，只是在函数退出时，**将和转换成short类型**。

第一个问题是新提出来的。（LDRH无法偏移地址寻址方式），可以通过递增指针data，而不是用数组data[i]的下标来访问数组。这是忽视数组类型长度或元素尺寸的有效方法(指的是根据下标来偏移地址的方式)。ARM所有的load和store指令都支持后增量(postincrement)寻址方式。

例5.1checksum_v4代码解决了本节讨论的第二个问题。使用了**指针data代替原来使用数组的下标**。

```c
short checksum_v4(short * data)
{
    unsigned int i ;
    int sum = 0;
    for(i = 0;i < 64;i++)
    {
        sum += *(data++);//看起来是这种方式编译器不会认为是整数类型
    }
    return (short)sum;
}
```

操作 * (data++)只需一条ARM指令装载数据并增加指针data的值。当然，也可以根据各自的喜爱，写成sum+=data;data++或者*data++。这是先偏移地址后寻址（从右到左优先级）。编译器会产生下面的输出结果。相对于checksum_v3，在内部循环体中3条指令 被剔除了，这样对于每个循环来说节约了3个周期。

```assembly
checksum_v4
	MOV r2,#0;sum = 0
	MOV r1,#0;i=0
checksum_v4_loop
	LDRSH r3,[r0],#2;这是后变址，先寻址然后r0+2，使用数组下标，是默认左移1位，对下标进行移位获得偏移地址再加到基地址上。而这里作为指针就是直接对保存指针的寄存器r0进行指针加法和寻址。
	ADD r1,r1,#1
	CMP r1,#0x40
	ADD r2,r3,r2
	BCC checksum_v4_loop
	MOV r0,r2,LSL #16
	MOV r0,r0,ASR #16
	MOV pc,r14
```

在函数返回时，编译器仍然需要把指令数据转换成16位的。如果返回值是int类型，那么这一步就不需要了。5.2.2小节将进一步讨论返回值是int类型的情况。

#### 5.2.2函数参数类型

在5.2.1小节中已经看到，把局部变量从char或者short类型转换成int类型，可以改善性能并减小代码尺寸。其实，这种转换对函数参数也有着同样的效果。看下面的例子，将2个16位的值相加，其中第二个数先减半，然后返回一个16位的和：

```c
short add_v1(short a,short b)
{
    return a + (b>>1);
}
```

虽然这个函数只是一个简单的算术运算，但是对于观察编译器所碰到的问题是一个很好的例子。输入值a，b和返回值都存放在32位的ARM寄存器中。编译器是否应该考虑这些32位数值在short类型的范围之内。编译器是否应该通过对低16位数据进行符号位扩展，填充32位寄存器，强制把数值限制在上述范围之间。

编译器必须对函数调用者和被调用者作出一致的决策。不是调用者就是被调用者，必须把数据转换为short类型。

如果参数可以**不缩小到所定义的数据类型范围**，那么成这种函数参数传递是宽的，反之称为窄的。观察add_v1的汇编输出结果，就可以知道编译器所采用的是哪种形式。

- 如果编译器传递参数是宽的，那么被调用者必须把参数缩小到正确的范围；
- 如果编译器传递参数是窄的，那么调用者就必须缩小参数；
- 如果编译器返回值是宽的，那么调用者就必须把**返回值缩小**到正确的范围；
- 如果编译器返回值是窄的，那么被调用者就必须在返回前**缩小**返回值的**范围**。

上面这段话意思是宽就不需要强制转换成int->short，如果是窄就必须强转

对于ADS（这里指的应该是英菲普的编译环境）的armcc来说，函数参数传递和返回值都是窄的。换句话说，调用者要处理调用参数，而被调用者要处理返回值，编译器采用函数的ANSI原型(这是C的一种版本，也叫做C89，这里的函数原型其实就是由返回值类型，函数名称，形参组成的函数声明)来决定函数参数的数据类型。

函数add_v1在armcc下的输出结果显示，编译器把返回值的类型转换为short，而没有处理输入参数。他认为调用者已经保证在r0和r1中的32位的数值是在short类型的范围之内。这就说明参数传递和返回值都是窄的。(我的理解就是所谓设定编译器为窄之后，默认参数传递和返回值的数值是很小的，即使是int类型也只占用了低16位，所以面对返回值是short类型时依旧不需要处理int类型)

```assembly
add_v1
	ADD r0,r0,r1,ASR #1;r0 = (int)a + ((int)b >> 1)
	MOV r0,r0,LSL #16
    MOV r0,r0,ASR #16;这两行是很典型的short强制转换，先逻辑左移16位，此时只剩下低16位，然后算术右移16位，原本的低16位回到低位，高位用符号位填充。
    MOV pc,r14;return r0
```

gcc编译器更为谨慎，对参数值的范围不做任何假设。这个版本的编译器，在调用者和被调用者中都将输入参数缩小到short类型的数据范围，同时也都将返回值转换为short类型。下面是add_v1由gcc编译后的代码：

```assembly
add_v1_gcc
	MOV r0,r0,LSL #16
	MOV r1,r1,LSL #16
	MOV r1,r1,ASR #17;在强制转换short之后右移1位
	ADD r1,r1,r0,ASR #16;强转r0为short，然后让r1 = r0+r1
	MOV r1,r1,LSL #16
	MOV r1,r1,ASR #16;将r1强转为short
	MOV pc,lr
```

gcc编译器是把参数和返回值都强转，这里属于是窄的规则。宽应该是不强转，认为即使是int类型，也是只有低16位上有效，所以还是在short范围内。

尽管宽和窄的函数调用规则各有其优点，但char或者short类型的函数参数和返回值都会**产生额外的开销**，导致性能下降。（指令不针对16位或8位，寄存器是32位的，强转成short需要符号位填充）并**增加了代码尺寸**。所以，即使是传输一个8位数据，函数参数和返回值使用**int类型也会更有效**。

#### 5.2.3有符号数和无符号数

前面说明了对于局部变量和函数参数，使用int类型比使用short类型更好。本小节将对有符号整数(signed int)和无符号整数(unsigned int)类型的执行效率进行分析比较。

如果程序中只有加法、减法和乘法，那么有符号和无符号数的执行效率没有任何差别。但是，如果有了除法就不一样了。看下面一个关于求2个整数平均值的简单例子：

```c
int average_v1(int a,int b)
{
    return (a + b)/2;
}
```

编译后

```assembly
average_v1
	ADD r0,r0,r1;r0 = a + b
	ADD r0,r0,r0,LSR #31;r0 = r0+r0>>31，后者是求符号位，如果符号位=0则为正数，r0=r0+0，反之r0++
	MOV r0,r0,ASR #1;r0 = r0>>1，这里就是求平均
	MOV pc,r14
```

---

注意：在汇编代码中，如果r0是负数，在右移前编译器先对r0进行加1操作。换句话说，就是把x/2替换成：

```c
(x<0)?((x+1)>>1):(x>>1)
```

这一步是必须做的，因为x是有符号数。在ARM C中，如果x是负数，（负数在计算机中的表示比较复杂涉及到补码的问题，所以移位也不是那么容易的）。

对于一个负整数，除法的结果是向0的方向舍入，而算术右移的结果是向-8的方向舍入。对于除法来说，使用无符号数效率更高。编译器可以将2的倍数的无符号除法直接用右移代替。对于一般的除法运算，C库文件中的除法程序对于无符号运算执行速度也更快。

摘要 C数据类型的有效用法

- 对于存放在寄存器中的局部变量，除了8位或16位的算术模运算外，尽量不要使用char和short类型，而要使用有符号或者无符号int类型。除法运算时使用无符号数执行速度更快。
- 对于存放在主存储器中的数组和全局变量，在满足数据大小的前提下，应尽可能使用小尺寸的数据类型，这样做可以节省存储空间。ARMv4体系结构可以有效地装载和存储所有宽度的数据，并可以使用递增数组指针来有效地访问数组。对于short类型数组，要避免使用数组基地址的偏移量，因为LDRH指令不支持偏移寻址。
- 通过读取数组或者全局变量并赋给不同类型的局部变量时，或者把局部变量写入不同类型的数组或者全局变量时，要进行显式数据类型转换。这种转换使编译器可以明确、快速地处理，把存储器中数据宽度比较窄的数据类型扩展，并赋给寄存器中较宽的类型。通过打开编译器的隐式数据宽度窄化警告选项，可以观察到隐式数据类型转换。
- 由于隐式或者显式的数据类型转换通常会有**额外的指令周期开销**，所以在表达式中应尽量避免使用。load和store指令一般不会产生额外的转换开销，因为load和store指令是**自动完成数据类型转换**的。
- 对于函数参数和返回值应尽量避免使用char和short类型。即使参数范围比较小，也应该使用int类型，以防止编译器做不必要的类型转换。

### 5.3C循环结构

循环体是程序设计和优化的重点考虑对象。本节将着重研究在ARM上处理for和while循环最有效的方法。首先研究循环次数固定大小的循环体，然后转移到可变次数的，最后将分析循环体展开。

#### 5.3.1固定次数的循环

什么是ARM上编写for循环效率最高的方法？再回到前面的checksum例子，研究下循环结构。

下面是在5.2节中讨论的64个字数据包校验和程序的最后版本，说明了编译器如何使用增量计数i++来处理一个循环。

```c
int checksum_v5(int * data)
{
    unsigned int i;
    int sum=0;
    for(i = 0;i < 64;i++)
    {
        sum +=*(data++);//采用指针，不需要考虑类型转换
    }
    return sum;
}
```

编译后生成：

```assembly
checksum_v5
	MOV r2,r0;r2 = data
	MOV r0,#0;sum = 0
	MOV r1,#0;i = 0
checksum_v5_loop
	LDR r3,[r2],#4;r3 = *(data++)
	ADD r1,r1,#1;i++
	CMP r1,#0x40
	ADD r0,r3,r0;sum = sum +*(data)
	BCC checksum_v5_loop;CC是判断下cmp是否小于，如果小于就跳转
	MOV pc,r14
```

这里用了3条指令来实现for循环结构：

- 一条ADD指令，增加i的值；
- 一条CMP比较指令，检查i是否小于64；
- 一条BCC条件分支指令，如果i<64则继续循环。

这种循环执行效率不高，在ARM上，一个循环其实只要2条指令就够了：

- 一条减法指令，进行循环减计数，同时设置结果的条件标志；
- 一条条件分支指令。

这里的关键是，循环的终止条件应为减计数到零(count down to zero)，而不是计数增加到某个特定的限制值。由于减计数结果已存储在条件标志里，与零比较的指令就可以省略了。由于不再使用i作为数组的下标索引，采用减计数就没有任何问题。

例5.2表明采用减计数循环(decrementing loop)要比增计数循环更好。

```c
int checksum_v6(int * data)
{
    unsigned int i;
    int sum = 0;
    for(i = 64;i!=0;i--)
    {
        sum+=*(data++);
    }
    return sum;
}
```

编译后输出：

```assembly
checksum_v6
	MOV r2,r0
	MOV r0,#0
	MOV r1,#0x40
checksum_v6_loop
	LDR r3,[r2],#4
	SUBS r1,r1,#1;后缀+S会自动更新cpsr的条件标志位
	ADD r0,r3,r0
	BNE checksum_v6_loop;(NE表示不等于0也就是z循环)
	MOV pc,r14
```

这里，SUBS和BNE指令实现了循环。这个校验和例程中，每次循环只用了4个指令，比checksum_v1中的6条减少了很多。

对无符号的循环计数值i来说，循环继续的条件既可以是i!=0，也可以是i>0.由于i不可能是负数，所以这两个条件是等价的。而对于一个有符号的循环计数值来说，用条件i>0来作为继续循环的条件是一件冒险的事情。读者可能会期望编译器生成下面的两条指令来实现循环：

```assembly
SUBS r1,r1,#1;这里先减法，根据运算结果更新cpsr，
BGT loop
-----
SUB r1,r1,#1;这里是先-1然后比较
CMP r1,#0;这里由CMP指令更新cpsr
BGT loop
```

不是编译器的无能，当i=-0x80000000时，它必须小心，因为上面2段汇编代码在这种情况下会产生不同的结果。对于第一段汇编代码，SUBS指令将i与1比较，然后减1，由于-0x80000000<1，循环终止。而对于第二段汇编代码，先将i减1，然后与0比较。模运算意味着现在i的大小是+0x7fffffff，这样循环就能继续下去。（有符号整数的运算比较麻烦，有可能导致溢出）

当然，实际上i很少会是-0x80000000.编译器一般不可能碰到这种情况，特别是当循环是以一个可变的计数值开始的。

总而言之，无论对于有符号还是无符号的循环计数值，都应使用i!=0作为循环结束条件。对于有符号数i，这比使用条件i>0少了一个指令。

#### 5.3.2不定次数的循环

现在假定checksum程序要处理任意长度的数据包，这样就须传递一个变量N作为数据包的长度。从5.3.1小结的经验可知，可使用减计数直到N=0，也不需要额外的循环计数值i。

例子checksum_v7显示编译器如何处理不定次数N的循环。

```c
int checksum_v7(int * data,unsigned int N)
{
    int sum = 0;
    for(;N!=0;N--)
    {
        sum += *(data++);
    }
    return sum;
}
```

编译后生成：

```assembly
checksum_v7
	MOV r2,#0
	CMP r1,#0;不定次数无法获知当前值是否可以进入循环，先判断下
	BEQ checksum_v7_end
checksum_v7_loop
	LDR r3,[r0],#4
	SUBS r1,r1,#1;
	ADD r2,r3,r2;
	BNE checksum_v7_loop
checksum_v7_end
	MOV r0,r2
	MOV pc,r14
```

注意：在函数的入口处，编译器先检查N是否为0.由于数组通常不会为空，所以一般来说检查是不必要的。下面的例子说明使用do-while循环会比for循环呈现出更好的性能和代码密度。

例5.3显示如何使用do-while循环去除for循环中出现的对N是否为0的判断。

```c
int checksum_v8(int*data,unsigned int N)
{
    int sum = 0;
    do{
        sum += *(data++);
    }while(--N!=0);
    return sum;
}
```

编译后变成：

```assembly
checksum_v8
	MOV r2,#0
checksum_v8_loop
	LDR r3,[r0],#4
	SUBS r1,r1,#1;这里有点问题，按照c应该是先减后比较
	ADD r2,r3,r2
	BNE checksum_v8_loop
	MOV r0,r2;r0作为返回值需要设置r0，r0寄存器本身作为返回值的存储，这是r0的用法。
	MOV pc,r14
```

反正这部分乱乱的。这些都是使用的寄存器，函数本身的栈帧结构没体现出来，在汇编层面上就是装载和保存，不会观察到一个独立的栈帧结构。

#### 5.3.3循环展开

在5.3.1小节中可以发现，每次循环需要在循环体外加2条指令：一条减法指令来减少循环计数值和一条条件分支指令(循环体分为循环开销+循环主体)。通常把这些指令称为循环开销。在ARM7或者ARM9处理器上，减法指令需要1个周期，条件分支指令需要3个周期，这样每个循环就需要四个周期的开销。

可通过展开循环体-重复循环主体多次，并按同样的比例减少循环次数，来降低循环开销。例如，把数据包校验和程序展开四次。这里指的就是多次重复循环主体在一次循环中，这样就降低循环开销了。

例5.4把数据包校验和程序展开4次。

假定数据包中的数据个数N是4的倍数。

```c
int checksum_v9(int *data,unsigned int N)
{
    int sum = 0;
    do{
        sum += *(data++);
        sum += *(data++);
        sum += *(data++);
        sum += *(data++);
        N-=4;
    }while(N!=0);
    return sum;
}
```

---

```c
//重新提下*data++
*data++==*(data++);//*和++是同一个优先级，从右到左，所以先执行++后执行*
(*data)++;//此时是先获得data指向的首元素，然后首元素自加。
*++data;//这里是先执行++data然后执行*，相当于获取第二个元素
```

-----

编译后生成：

```assembly
checksum_v9
	MOV r2,#0;sum = 0
checksum_v9_loop
	LDR r3,[r0],#4
	SUBS r1,r1,#4;为什么减法要在这里进行，这里是先比较再减法
	ADD r2,r3,r2
	LDR r3,[r0],#4
	ADD r2,r3,r2
	LDR r3,[r0],#4
	ADD r2,r3,r2
	LDR r3,[r0],#4
	ADD r2,r3,r2
	BNE checksum_v9_loop
	MOV r0,r2
	MOV pc,r14
```

这里把循环开销从4N个周期减少到 4N/4=N个周期。在ARM7TDMI上，把原来一次累加需要的8个周期减少到20/4=5个周期，几乎加速了2倍。对于ARM9TDMI，由于她有更快的load指令，效果更好。

这种展开循环体的做法就是脱裤子放屁，确实减少了，但是谁知道循环次数呢，所以还是从C语言优化的，而不是从编译器实现的优化。

在展开一个循环时，读者一定会问到两个问题：

- 到底应该展开循环几次
- 如果循环的次数不是循环展开数的倍数该怎么办？例如，在例checksum_v9中，如果N不是4的倍数怎么办

首先，对于第一个问题，只有当循环展开对提高应用程序的整体性能非常重要时，才进行循环展开；否则得益不大反而会增加代码尺寸，甚至会因为**替换掉cache中更重要的代码**（什么意思）而降低了总体性能。

假定循环对整个程序的性能是非常重要的，比如，占了整个程序执行的30%；假设展开循环至0.5KB的代码量(128条指令)，这样，相对于循环主体的128个周期，循环一般的开销最多只有4个周期，占了3/128，约3%，而循环占整个程序的30%，这样循环的一般开销只占了整个程序执行的1%。进一步展开代码对性能好处不多，但对cache内容造成了很大的影响。通常，对性能改善小于1%，那么循环就不值得进一步展开了。

对于第二个问题，应设法使得循环的次数是循环展开数的倍数。如果难以实现，那么就要增加额外的代码来处理数组的剩余元素。这将增加少许代码量，但可以保持较好的性能。

例5.5采用4次展开的循环，可对任意大小的数据包进行校验和计算。

```c
int checksum_v10(int *data,unsigned int N)
{
    unsigned int i;
    int sum = 0;
    for(i = N/4;i!=0;i--)
    {
        sum +=*(data++);
        sum +=*(data++);
        sum +=*(data++);
        sum +=*(data++);
    }
    for(i=N&3;i!=0;i--)//比如101这是5,11这是3，取交集后1所以i=1，确保剩余的循环次数有第二个for补全
    {
        sum +=*(data++);
    }
    return sum;
}
```

第二个for循环解决了当N不是4的倍数时的数组剩余元素问题。

注意:N/4和N&3都可能是零，所以就不能使用do-while结构的循环。这循环是先执行后判定。

小结：高效地编写循环体

- 使用减计数到零的循环结构，这样编译器就不需要分配一个寄存器来保存循环终止值，而且与0比较的指令也可以省略；
- 使用无符号的循环计数值，循环继续的条件为i!=0，这样保证循环开销只有两条指令，不需要比较指令
- 如果事先知道循环体至少会执行一次，那么使用do-while循环要比for循环号，这样可以使编译器省去检查循环计数值是否为零的步骤；
- 展开重要的循环体可降低循环开销，但不要过渡展开，如果循环的开销对整个程序来说占的比例很小，那么循环展开反而会增加代码量并降低cache的性能；
- 尽量使数组的大小是4或者8的倍数，这样就可以容易的以2/4/8等多种选择展开循环，而不需要担心剩余数组元素的问题。

### 5.4寄存器分配

编译器会试图对C函数中的每一个局部变量分配一个寄存器。如果几个局部变量不会交迭使用，那么编译器会对他们分配同一个寄存器。当局部变量多于可用的寄存器时，编译器会把多余的变量存储到堆栈（八股文的时候学过，如果只有4个以内的话寄存器足够的）。由于这些变量被写入了存储器，所以被称为溢出或者替换变量，就像虚拟存储器的内容被替换到硬盘一样。与分配在寄存器中的变量相比，对溢出变量的访问要慢得多。

为了高效地执行一个函数，应该做到：

- 使溢出变量的数量最少
- 确保最重要的和经常用到的变量被分配在寄存器。

首先，来了解下ARM C编译器能够分配给局部变量的寄存器数目。表5.3显示了当C编译器采用ARM-Thumb过程调用标准(ATPCS)时，内部寄存器的编号、名字和分配方法。

| 寄存器编号 | 可选寄存器名字 | ATPCS寄存器用法                                              |
| ---------- | -------------- | ------------------------------------------------------------ |
| r0         | a1             | 参数寄存器，在**调用函数时**，用来存放前4个函数参数和返回值。在函数内，如果把这些寄存器作为临时过渡寄存器来使用，则会破坏他们的值。这里的是调用函数中的参数 |
| r1         | a2             |                                                              |
| r2         | a3             |                                                              |
| r3         | a4             |                                                              |
| r4         | v1             | 通用变量寄存器。调用函数必须保存在**被调用函数**存放在这些寄存器中的变量值。r4-r7表示保存被调用函数的参数。 |
| r5         | v2             |                                                              |
| r6         | v3             |                                                              |
| r7         | v4             |                                                              |
| r8         | v5             |                                                              |
| r9         | v6 sb          | 通用变量寄存器。在于读写位置无关的编译情况下，r9中保存**静态基本地址**，这个地址是读写数据的地址；否则必须保存这个寄存器中**被调用函数的变量值**。 |
| r10        | v7 sl          | 通用变量寄存器，在使用堆栈限制检查的编译情况下，r10保存堆栈限制的地址；否则必须保存这个寄存器中**被调用函数的变量值**。就是堆栈限制，sp不断的指向堆栈结构中的存储单元，寻址前比较下堆栈限制，因为堆栈的地址是向下增长的，sp如果小于r10就下溢了。 |
| r11        | v8 fp          | 通用变量寄存器。除了在使用结构指针的变异情况下，必须保存这个寄存器中**调用函数的变量值**外，只有老版本的armcc编译器使用一个结构指针。用来显示堆栈的局部变量，这就是帧指针 |
| r12        | ip             | 通用临时过渡寄存器，函数调用时会破坏其中的值，**调用函数的变量值** |
| r13        | sp             | 堆栈指针，指向下增长满堆栈的堆栈                             |
| r14        | lr             | 连接寄存器。在函数调用时，这个寄存器保存返回地址             |
| r15        | pc             | 程序计数器                                                   |

假如编译器不使用软件堆栈检查或者结构指针，那么C编译器就可以使用寄存器r0~r12和r14来存放变量。如果要用到这些寄存器，那么就必须用堆栈来保存r4~r11和r14的值。

----

这里就是说，r0-r3这四个寄存器是专门用来存放局部变量和返回值的，但理论上r4-r11和r14也可以保存被调用函数的局部变量和返回值，但这种情况下，需要备份到堆栈中。

----

理论上，C编译器可以分配14个变量到寄存器而不会溢出。实际上，一些编译器对某些寄存器有特定的用途，例如用r12作为临时过渡寄存器使用，编译器就不再分配任何变量给他了。另外，对于复杂的表达式，也需要过渡寄存器来计算、求值。因此，为了确保对寄存器有良好的分配，并取得较好的性能，应该尽量限制，使函数丶内部循环最多只使用12个局部变量，加上返回值占用一个、r12一个正好14个。

如果编译器确实需要替换变量，那么编译器将会根据变量的使用频率来选择要替换的变量。一个循环内的变量使用频度会高很多，所以可以按照变量所在循环层次来决定其重要性。一般最内层循环体内的变量就是最重要的。

在C语言中，关键词register表示编译器应该分配给指定变量一个寄存器。但是，不同的编译器对这个关键词的处理也不完全相同，不同的结构状态下可供分配的寄存器数目也不相同。比如Thumb和ARM，因此应尽量避免使用register关键词，应依赖编译器正常的寄存器分配策略来分配。

---

编译器功能：编写的C语言是通用在任何架构上的，需要选择相应架构的编译器将C语言编译成对应的汇编语言，并且编译器还会管理该架构上的寄存器功能。编译器负责管理硬件功能以及编译汇编指令 。

无法直接编写汇编是因为寄存器功能无法确定。

----

小结高效的寄存器分配

- 应该尽量限制函数内部循环所用局部变量的数目，最多不超过12个，这样编译器就可以把这些变量分配给ARM寄存器
- 可以引导编译器，通过查看是否属于最内层循环的变量来确定某个变量的重要性。

### 5.5函数调用

ARM过程调用标准APCS定义了如何通过寄存器传递函数参数和返回值。最近的ARM-Thumb过程调用标准ATPCS又增加了ARM和Thumb互相调用的说明。

函数中最前面的四个整形参数 是通过ARM的前4个寄存器r0,r1,r2,r3来传递的。随后的整形参数是通过下降式满堆栈来传递。下图显示了参数的存放情况。函数返回的整形数据通过寄存器r0来传递。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1683455859715.png" alt="1683455859715" style="zoom:50%;" />

堆栈是向下增长的，地址是向上增加的，函数参数入栈是从右到左一次入栈，所以最左侧的函数参数地址是最低的。这涉及到了优先确定参数个数的问题。

这里的描述只针对整形和指针类型的参数。双字类型的参数，例如long long类型或者double类型，是通过一对连续的寄存器传递的，双字类型的返回值存放在r0和r1中。编译器可以通过寄存器或根据命令行参考来传递结构体。

首先应指出的是，过程调用标准是4寄存器规则。带有4个或者更少参数的函数，要比多于4个参数的函数执行效率高得多。对带有少于4个参数的函数来说，编译器可以用寄存器传递所有的参数；而对于多于4个参数的函数，函数调用者和被调用者都必须通过访问堆栈来传递一些参数。

注意：在C++中，一个对象方法的第一个参数总是this指针。这个参数是隐式的。

如果一个函数的参数多于4个，或者C++中的显式参数多于3个，那么通常使用结构体，执行效率会更高。将多个相关的参数组织到一个结构体中，传递一个结构体指针来代替多个参数。那些参数应该归到一个结构体，这依赖于应用程序。所以结构体是传递一个指针给寄存器实现的么。

下面的例子说明了使用结构体指针的好处。这是一个典型的子程序：从数组data插入N个字节到一个队列里面。这里用一个起始地址是Q_start、结束地址是Q_end的循环缓冲区来实现这个队列。iio_buffer就是使用kfifo双向循环队列实现的。

```c
char *queue_bytes_v1(
char *Q_start,char *Q_end,char *Q_ptr,char *data, unsigned int N)
{
    do{
        *(Q_ptr++) = *(data++);//数组插入到队列
        if(Q_ptr == Q_end)//队列结束返回开头
        {
            Q_ptr = Q_start;
        }
    }while(--N);
    return Q_ptr;
}
```

编译后生成

```assembly
queue_bytes_v1
	STR r14,[r13,#-4]!;这是把lr保存到[r13-4]中，并且回写到r13=r13-4，r13是sp堆栈指针，而sp指向第五个参数，这里保存的是32位的指针，所以是整形int的，sp指向N，此时是将lr保存到[sp-4]，确实记得sp-4保存返回地址，但是栈帧结构中不一致
	LDR r12,[r13,#4];将r12=[sp-4+4]=N，将插入数据的数目存入r12中，这里不写回r13
queue_v1_loop
	LDRB r14,[r3],#1;r14 = *data++确实挺精妙，因为之前保存r14了，所以这里r14可以用来保存，r0-r3分别对应不含返回值的前四个参数，而data指针指向的是char单字节，所以用LDRB
	STRB r14,[r2],#1;*Q_ptr++ = r14，将数组元素存入队列中
	CMP r2,r1;比较Q_ptr和Q_end
	MOVEQ r2,r0;如果Q_ptr==Q_end,Q_ptr=Q_start
	SUBS r12,r12,#1;N = N-1，先比较然后减法
	BNE queue_v1_loop;如果N!=0，其实是先比较N和1，然后N=N-1，到这行如果N!=0，跳转
	MOV r0,r2;返回值 = Q_ptr
	LDR pc,[r13],#4;此时r13 = sp-4 = lr，PC = lr，后变址会更新基址寄存器，类似回写。sp回到原本的sp
```

这个例子很好，清晰的看到r14备份后被存储数据了。以及r0-r3保存的前四个参数，sp-4保存返回地址。

可以将这个例子与使用3个函数参数的结构化的例子进行比较。

上面例子并没有添加结构体。所以分别保存在r0-r3以及sp指向的主存中。

```c
typedef struct {
    char *Q_start,
    char *Q_end,
    char *Q_ptr,
}Queue;
void queue_bytes_v1(Queue * queue,char *data,unsigned int N)
{
    char *Q_ptr = queue->Q_ptr;
    char *Q_end = queue->Q_end;
    do{
        *Q_ptr++ = *data++;
        if(Q_ptr == Q_end)
        {
            Q_ptr = queue->Q_start;
        }
        
    }while(--N);
    queue->Q_ptr = Q_ptr;
}
```

编译后生成

```assembly
queue_bytes_v2
	STR r14,[r13,#-4];[sp-4] = lr
	LDR r3,[r0,#8];这里暴露出了结构体成员的入栈地址，是从上到下地址依次增加。r0 = queue指针，r0+8指向queue->Q_ptr的地址，r3 = queue->Q_ptr
	LDR r14,[r0,#4];r14 = queue->Q_end
queue_v2_loop
	LDRB r12,[r1],#1;r12 = *(data++)
	STRB r12,[r3],#1;虽然r3没用上，只有三个参数，但是循环前设定了r3，*Q_ptr++ = *(data++)
	CMP r3,r14;比较Q_ptr和Q_end
	LDREQ r3,[r0,#0];r3 = queue->Q_start
	SUBS r2,r2,#1;N--
	BEN queue_v2_loop
	STR r3,[r0,#8];queue->Q_ptr = queue->Q_start
	LDR pc,[r13],#4
```

queue_bytes_v2比queue_bytes_v1多了一条指令，但实际上总体效率更高。相比前面的5个参数，在第二个例子中仅有3个函数参数，所以每次函数调用只需设置3个寄存器。而在第一个例子中，每次调用要有4个寄存器设置、一个压栈一个退栈。在函数调用开销方面，净省了两条指令。

对于被调用函数来说，可以节省更多，因为只需分配一个寄存器给queue结构指针，而不需要像前面非结构化的例子中分配3个寄存器。

如果函数体很小，只用到很少的寄存器，那么还有一些其他的方法来减小函数调用的开销。可以把调用函数和被调用函数放在同一个C文件中，这样编译器就知道了被调用函数生成的代码，并以此对调用函数进行一些优化：

- 调用函数不需要保护被调用函数没有用到的寄存器，调用函数也不需要保护所有ATPCS占用的寄存器。
- 如果被调用的函数很小，那么编译器可以在调用函数中内联被调用函数的代码，将被调用函数在调用函数内展开，彻底去掉函数调用的开销。

例5.7函数uint_to_hex把一个32位的无符号整数转换为8个十六进制数。这个函数调用了一个辅助函数nybble_to_hex，把一个在范围0~15的数字d转换为一个十六进制数字。

```c
unsigned int nybble_to_hex(unsigned int d)
{
    if(d<10)
    {
        return d+'0';//这就是32位数字小于10转换成10进制的字符
    }
    return d-10+'A';//十六进制大于10转换成对应的字母字符。
}
void uint_to_hex(char *out,unsigned int in)
{
    unsigned int i;
    for(i=8;i!=0;i--)
    {
        in = (in << 4)|(in >> 28);//循环左移4位，左移4位去掉了高4位，右移28位，只保留高4位，并在一起，将高四位转移到低四位，循环最后恢复原样
        *(out++) = (char)nybble_to_hex(in&15);//这里取in的低4位送入函数中，实际上是从高4位开始每4位送入一次。每4位二进制等于一个16进制，这里是获得字符形式的16进制的一位。
    }
}
```

----

```c
//突然间明白了怎么实现797回文数辨别，分别除以100,10和1，获得百位十位个位上的数字，转换成字符
int num = 797;
int num1 = num/100;
int num2 = num%100/10;
...
char c = num1+'a';//获得在字母上对应的字符，比较字符是否相等即可
```

编译后，可以看到函数uint_to_hex根本没有调用函数nybble_to_hex，在下面的编译后的代码中，编译器内联了nybble_to_hex的代码，这将比函数调用效率高很多。内联就是把函数在调用处展开，不再以被调用函数的身份加入调用函数中。

```assembly
uint_to_hex
	MOV r3,#8;i = 8;r3保存局部变量
uint_to_hex_loop
	MOV r1,r1,ROR #28;第一次使用循环右移，循环体现在被移除的位在另一侧弥补回来，c是循环左移4位，所以这里就右移28位。r1>>28|r1<<4
	AND r2,r1,#0xf;r2 = r1&1111，c中是将r2送入nybble_to_hex函数中，下面直接内联了
	CMP r2,#0xa;if(r2<=>10)
	ADDCS r2,r2,#0x37;r2是低4位，根据ASCII码，'A'=0x41,x41-10=0x37
	ADDCC r2,r2,#0x30;0x30在ASCII码上对应'0'
	STRB r2,[r0],#1;将r2保存在out指针指向的地址上，*(out++) = r2
	SUBS r3,r3,#1;i--
	BNE uint_to_hex_loop
	MOV pc,r14
```

编译器只会内联比较小的函数。也可以使用_inline关键字要求编译器内联一个函数，不过这个关键字只是一个提示，编译器可能会忽略它。内联一个大的函数将会大大增加代码量，性能却不会有大的改善。因为这会导致调用函数的参数大大增加，寄存器不够用的话，只能使用堆栈了。

小结高效的调用函数

- 尽量限制函数的参数，不要超过4个，这样函数调用的效率会更高。也可以将几个相关的参数组织在一个结构体中，用传递结构体指针来代替多个参数。可以节省寄存器
- 把比较小的被调用函数和调用函数放在同一个源文件中，并且先定义，后调用，编译器就可以优化函数调用或者内联较小的函数。
- 对性能影响较大的重要函数使用过关键字_inline进行内联。

### 5.6指针别名

当两个指针指向同一个地址对象时，这两个指针被称为该对象的别名(alias)。如果对其中一个指针进行写入，就会影响另一个指针的读出。在一个函数中，编译器通常不知道哪一个指针是别名，哪个不是，或者哪个指针有别名，哪个没有。编译器必须非常悲观的认为，对任何一个指针的写入，都将影响从任何其他指针的读出，但这样会明显降低代码执行的效率。

先看一个非常简单的例子。下面的函数对2个定时器值使用一个步进量进行累加:

```c
void timer_v1(int *timer1,int *timer2,int *step)
{
    *timer1 += *step;
    *timer2 += *step;
}
```

编译后生成：

```assembly
timers_v1
	LDR r3,[r0,#0];r3 = *timer1
	LDR r12,[r2,#0];r12 = *step，r12也是调用函数的参数寄存器。
	ADD r3,r3,r12;r3 = r3 + r12
	STR r3,[r0,#0];*timer1 = r3，这里是写入到地址上
	LDR r0,[r1,#0];r0 = *timer2;此时r0存放timer1的使命结束，挪用存放*timer2
	LDR r2,[r2,#0];r2本来存放的指针，改成内容r2 = [r2] = *step
	ADD r0,r0,r2;r0 += r0 + *step
	STR r0,[r1,#0];*timer2 = r0
	MOV pc,r14
```

注意编译器装载step两次。第一次装载到r12，第二次装载到r2。通常，一种被称为公共子表达式消除的编译器选项，可以使编译器优化*step，只装载一次；第二次使用时，其值会被重复使用。

但是在这里编译器不能使用这种优化。指针timer1和指针step可能互为别名。第二次*step的值将与第一次的不同，将会是 *timer1的值。所以重新去step地址上寻址。如果是别名的话，寻址回来也是 *timer的值。

如果使用结构体来代替直接的指针访问，也会出现同样的问题。下面的代码编译后的结果执行效率也不高：

```c
typedef struct {
    int step;
}State;
typedef struct {
    int timer1,timer2;
}Timers;
void timers_v2(State *state,Timers *timers)
{
    timers->timer1 += state->step;
    timers->timer2 += state->step;
}
```

为了保证state->step的值不会被影响，可以使用局部变量被保存step的值。这样编译器只进行一次装载了。

例5.8在timers_v3diamante中，使用一个局部变量step来保存state->step的值。现在编译器就不需要担心state和timers的别名问题了。

```c
void timers_v3(state * state,Timers *timers)
{
    int step = state->step;
    timers->timer1 += step;
    timers->timer2 += step;
}
```

另外，对其他一些不明显的别名情况也要小心。当调用其他函数时，被调用的函数可能会改变存储器的内容，这样也就可能改变了所有涉及存储器读的表达式的值，编译器将会重新对相关表达式进行求值。假设先读state->step，调用一个函数后，再读state->step。编译器必须假定调用 的函数会改变内存中state->step的值，因此就会执行两次读操作，而不是再次使用第一次读到的state->step的值。（有用么，如果改变了内存中的step值，再读一次不也是在内存中读取吗）

另一个问题，是获取局部变量的地址。一旦这么做了，这个变量就被一个指针所对应，有可能与其他指针产生别名。万一别名发生，编译器宁可从堆栈重新读数据。考虑下面的例子，读入一个数据包并计算他们的校验和。

```c
int checksum_next_packet(void)
{
    int *data;
    int N,sum = 0;//这里没对N赋值
    data = get_next_packet(&N);
    do{
        sum += *(data++);
    }while(--N);
    return sum;
}
```

这里的get_next_packet函数返回下一个数据包的地址和大小，N保存大小。下面是编译后生成的代码：

```assembly
checksum_next_packet
	STMFD r13!,{r4,r14};入栈，从sp-4开始保存，堆栈是向下增长满堆栈，分别保存lr和r4，执行完sp = sp-8
	SUB r13,r13,#8;sp = sp-8-8，这里额外空出来两个存储单元
	ADD r0,r13,#4;r0 = sp-8-8+4，将第一个存储单元地址给r0=&N
	MOV r4,#0;sum = 0;
	BL get_next_packet;r0 = data跳转并返回，这里就是被调用函数了，具体应该是r0先作为参数把&N传递进函数，最后函数返回值通过r0传出。&N的值通过堆栈查找
checksum_loop
	LDR r1,[r0],#4;r1 = *data++
	ADD r4,r1,r4;r4 = *data + sum
	LDR r1,[r13,#4];r1 = [sp-8-8+4]==N
	SUBS r1,r1,#1;N--
	STR r1,[r13,#4];将*&N = r1，这里将N修改完保存进堆栈中。
	BNE checksum_loop;如果N!=0，跳转循环
	MOV r0,r4;r0 = r4返回值保存在r0中
	ADD r13,r13,#8;sp = sp-8，此时sp指向r4，删除局部变量，之前局部变量保存在堆栈上，现在重置sp指针等于删除局部变量
	LDMFD r13!,{r4,pc};之前入栈，现在出栈，sp返回原来的sp位置，sp-8保存给r4，sp-4=lr保存给pc。
```

这里感觉将r0 = &N这个过程是有必要的，需要将&N传递给被调用函数，最后r0 = data是因为被调用函数返回值由r0返回。并且对于循环N次数，每次修改完还入栈保存。直接存在寄存器中呗。

注意对于每一次N--，编译器是如何从堆栈读写N的，一旦得到了N的地址，并将它传递给get_next_packet，编译器就需要担心别名问题，因为指针data和&N可能回收别名。为了避免这种情况，不要使用局部变量的地址。如果非得这么做，可以在使用之前先把他的值复制到另外一个局部变量。

读者可能会疑惑，为什么编译器要分配两个堆栈变量的空间，而实际只用了1个。这是为了保持堆栈的8字节对齐，（我就疑惑了，存储空间保持8位，分配int类型所以需要4个存储空间，地址-4，为了实现8字节对齐(就是说指针只能+-8)，地址只能是8的倍数所以-8）在ARMv5TE体系结构中的LDRD指令要求这么做，上面的例子实际上没有使用LDRD，但是编译器不知道get_next_packet是否会使用这条指令。

小结避免指针别名

- 不要依赖编译器来消除包含存储器访问的公共子表达式，应建立一个新的局部变量来保存这个表达式的值，这样可以保证只对这个表达式求一次值。就是两个指针互为别名的问题。
- 避免使用局部变量的地址，否则对这个变量的访问效率会比较低。取地址会导致别名问题。

### 5.7结构体安排

通常，使用结构体是因为觉得结构体能明显地改善性能和增强代码密度。在ARM上使用 结构体有两个问题需要考虑：结构体地址边界对齐和结构体总的大小。

对于ARMv5TE及其以上的体系结构，load和store指令仅仅保证从与访问宽度尺寸对齐的地址来装载和存储数据。

基于这个原因 ，ARM编译器将会自动把一个结构体的起始地址与该结构体中最大访问数据宽度的倍数对齐，并通过插入填充位把结构体地址边界与他们的存取宽度相对齐。

例如，看下面的结构体：

```c
struct {
    char a;
    int b;
    char c;
    short d;
}
```

结构体的成员地址是按照声明顺序由小到大，d的地址最大。4字节对齐，所以占用12字节大小。

对于小端存储器系统，编译器会增加填充位pad安排数据，以确保先下一个目标与其尺寸要求的地址相对齐。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1683530180661.png" alt="1683530180661" style="zoom: 50%;" />

占用了12个字节，四字节对齐所以是三行，第一行是字符类型的a只在低字节上，第二行就是int类型的b，第三行是字符类型的c以及short类型的d，其中d占据两个高位字节，c占用32位中的低字节。

| 传递的字节数 | 指令            | 字节地址            |
| ------------ | --------------- | ------------------- |
| 1byte        | LDRB/LDRSB/STRB | 任何字节地址对齐    |
| 2bytes       | LDRH/LDRSH/STRH | 2字节的倍数地址对齐 |
| 4bytes       | LDR/STR         | 4字节的倍数地址对齐 |
| 8bytes       | LDRD/STRD       | 8字节的倍数地址对齐 |

为了提高存储器的空间利用率，应该重新安排各变量元素的位置：

```c
struct {
    char a;
    char c;
    shortd;
    int b;
}
```

这样结构体的大小从12字节减少到8字节。下面是重新编排

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1683530742210.png" alt="1683530742210" style="zoom:50%;" />

因此，这是组织一个结构体内各元素的好方法，这样，结构体存储时就不需要插入不必要的填充位。armcc编译器支持一个关键字__packed，表示去除所有的填充位。比如下面的结构体

```c
__packed struct{
    char a;
    int b;
    char c;
    short d;
}
```

在内存中将会安排为充分利用代码空间，数据边界不对齐。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1683531004119.png" alt="1683531004119" style="zoom: 50%;" />

这样，存储空间是不浪费了，但访问packed结构体的速度慢了，而且效率比较低。

**由于数据边界不对齐，编译器只能通过多个边界对齐的操作，把结果合并、重组，来模拟边界不对齐的load和store操作。**（这句话没看懂，load和store操作只适用于边界对齐的情况下，不然的话，需要多次装载和保存，这里可能说的是这个意思）

所以，一般只有在程序的代码空间比执行效率更重要，而且重新排序并不能减少填充位的情况下，才使用__packed关键字。还有就是在移植一个在存储器中有确定结构安排的代码时，也会用到它。

在存储器中对一个结构体的确切安排**依赖于编译器供应商和所使用的编译器版本**。在API定义中，**人为将不可以去掉的填充位插入结构体中**，不失为一种好方法。这种明确的结构体安排方法，对连接不同供应商和版本的编译器生成的代码是有利的。

另一个不明确的问题是枚举类型。不同的编译器根据枚举的范围，对于枚举类型会分配不同的空间大小。例如，考虑类型

```c
typedef enum{
    FALSE,
    TRUE
}Bool;
```

在ADSI.1中的armcc编译器认为Bool是1字节的数据类型，因为Bool只使用值0和1.在一个结构体中，Bool仅仅占用8位的空间。但是gcc认为Bool是一个字类型，在一个结构体中会占用32位的空间。为了避免这种不确定性，最好在API使用的结构体中避免使用enum类型。

另一个需考虑的问题是结构体的尺寸和结构体中各元素的偏移量，这是一个在Thumb指令集下编译时最为敏感的问题。Thumb指令只有16位宽度，因此从一个结构体基地址指针起，只允许较小的元素偏移量。这里指的是基地址指针的偏移量大小。

| 指令            | 从基寄存器起的有效偏移量 |
| --------------- | ------------------------ |
| LDRB/LDRSB/STRB | 0~31个字节               |
| LDRH/LDRSH/STRH | 0~31个半字(0~62字节)     |
| LDR/STR         | 0~31个字(0~124字节)      |

因此编译器产生一条指令，只能访问存放在结构体前32字节中的一个8位大小的结构体元素。单一指令只能访问存在于结构体前64字节中的一个16位大小的元素，或者存在于结构体前128字节中的一个32位大小的元素。一旦超过了这个限制，对结构体访问的效率将会变得很低。就是说结构体不能太大

遵循下面的规则来组织元素构造一个结构体，可以获得最高效率：

- 把所有8位大小的元素安排在结构体的前面；
- 依次安排16位、32位和64位的元素；
- 把所有数组和比较大的元素安排在结构体的最后；
- 对于一条指令，如果结构体太大而不能访问所有的元素，那么把元素组织到一个子结构体中，编译器可以**维持单独的子结构体的指针**。

小结高效的结构体安排

- 结构体元素要按照元素的大小来排列，以最小的元素放在开始，最大的元素安排在最后；
- 避免使用很大的结构体，可以用层次化的小结构体来代替；
- 为了提高可移植性，人工对API的结构体增加填充位，这样结构体的安排讲不好依赖于编译器；
- 在API的结构体中要谨慎使用枚举类型，一个枚举类型的大小是编译器相关的。

### 5.8位域

位域可能是在c89规范中最小的标准化部分了。位域被声明用来存放特定数目的位。（这里的位域就是内核提到的位图吧）编译器可以选择各个位的分配位置，单单就这个原因，应该避免在一个联合体或者API结构体中使用位域。（联合体同时只能存在一个成员，并且成员从低地址开始，API结构体是插入了不可删除的填充位）。不同的编译器可以对相同的位域分配不同的位置。

避免使用位域对提高效率是有好处的。位域是结构体的元素，通常使用结构体指针进行访问；所以他们也同样存在着指针别名的问题。每一个对位域的访问实际上就是对存储器的访问，可能出现的指针别名问题使得编译器需要经常重新装载位域。

下面的例子，dostages_v1举例说明了这个问题。同时也显示了编译器不会很好地倾向于去优化位域测试。

```c
void dostageA(void);
void dostageB(void);
void dostageC(void);
typedef struct{//结构体中的每个成员就是位域，
    unsigned int stageA:1;//位域只有一位
    unsigned int stageB:1;
    unsigned int stageC:1;
}Stages_v1;
void dostages_v1(Stages_v1 *stages)
{
    if(stages->stageA)
    {
        dostageA();
    }
    if(stages->stageB)
    {
        dostageB();
    }
    if(stages->stageC)
    {
        dostageC();
    }
}
```

这里使用了3个位标志来表示处理的3个不同阶段。这个例子编译后生成：

```assembly
dostages_v1
	STMFD r13!,{r4,r14};lr和r4入栈
	MOV r4,r0;r4 = stages指针
	LDR r0,[r0,#0];r0 = stages->stageA
	TST r0,#1;位测试，判断stages->stageA和立即数1
	BLNE dostageA;如果不相等跳转到函数dostageA执行完跳转回来
	LDR	r0,[r4,#0];重新设置r0 = stages->stageA
	MOV r0,r0,LSL #30;左移30位，第1位移到了第31位，这里stage结构体成员共有3位，所以CBA占据了210位。此时就是r0 = stages->stageB，虽然三个成员类型是int类型，但是只有1位，所以结构体内存上分布就是32位中只占用3位
	CMP r0,#0;if(stages->stageB)
	BLLT dostageB;如果r0<0跳转到dostageB()这里写错了吧
	LDR r0,[r4,#0];r0 = stages->stageA
	MOV r0,r0,LSL,#29;r0 = stages->stageC
	CMP r0,#0;
	LDMLTFD r13!,{r4,r14};这里应该是LDMFD+LT，如果小于的话出栈将sp指向的依次返回到lr和r4，这一行有啥必要么
	BLT dostageC;如果小于的话跳转到dostageC
	LDMFD r13!,{r4,pc};将pc = lr
```

注意编译器一共访问了包含位域的存储器位置3次，因为位域存储在存储器中，dostage函数可能会改变值。另外编译器使用两条指令测试位于中的bit1和bit2.

使用一个整型数来代替一个位域，可以产生效率高得多的代码。使用enum或者#define屏蔽来把一个整型数分成几个不同的域。位域就是结构体，只不过成员是位为单位。

例5.9下面的代码使用逻辑操作而不是位域来实现dostages函数。

```c
typedef unsigned long Stages_v2//定义新类型位Stages_v2
#define STAGEA (1ul << 0)
#define STAGEB (1ul << 1)
#define STAGEC (1ul << 2)
void dostages_v2(Stages_v2 * stages_v2)
{
    Stages_v2 stages = *stages_v2;
    if(stages & STAGEA)//比较ul类型的stages的第0位
    {
        dostageA();
    }
    if(stages&STAGEB)
    {
        dostageB();
    }
    if(stages&STAGEC)
    {
        dostageC();
    }
}
```

既然一个unsigned long 类型包含了所有的位域，那么就可以把这些位域的值保存到一个局部变量stages，这可以避免内存变量别名问题。

编译器生成下面的代码，代码量比前面使用ANSI位域的版本减少了33%：

```assembly
dostages_v2
	STMFD r13!,{r4,r14}
	LDR	r4,[r0,#0];r4 = *stages_v2
	TST r4,#1;ul类型的r4与1进行与运算,然后将运算的结果与0进行比较，不等于0的话就更新cpsr的z条件标志
	BLNE dostageA;不相等的话执行dostageA，这里应该是相等执行吧
	TST r4,#2;r4&b10
	BLNE dostageB
	TST r4,#4;r4&100
	LDMNEFD r13!,{r4,r14}
	BNE dostageC
	LDMFD r13!,{r4,pc}
```

---

TST汇编指令是让A和B进行与运算，**运算结果与0进行比较**，然后更新cpsr的标志位

----

也可以使用屏蔽位来设置和清除位域，这和测试位域一样简单，下面的代码显示了如何使用STAGE屏蔽位来设置、清除或者取反位：

```c
stages |= STAGEA;//enable
stages &= ~STAGEB;//disable
stages ^= STAGEC;//相等就取反
```

这几个位的设置、清除和取反操作都只是用了一条ARM指令，分别为ORR，BIC和EOR指令。另外还可以使用一条指令同时处理几个位域。例如：

```c
stage |= (STAGEA|STAGEB);
stages &= ~(STAGEA|STAGEC);
```

小结位域

- 应避免使用位域，而使用#define或者enum来定义屏蔽位；位域是结构体成员，涉及到结构体指针的别名问题
- 使用整型逻辑运算AND/OR、异或操作和屏蔽对位域进行测试、取反和设置操作。这些操作编译效率高，还可以同时对多个位域进行测试、取反和设置

### 5.9边界不对齐数据和字节排序方式(大小端)

边界不对齐数据和字节排序方式这两个问题，可使内存访问和移植问题复杂化。需考虑数组指针是否边界对齐，ARM设置是大端还是小端的存储器系统。

ARM的load和store指令假定地址是正在装载和存储的数据类型长度的倍数。如果装载和存储的地址与数据类型边界不对齐，那么可能会产生异常的结果，比如数据异常或者装载了一个错位的值。对于质量好、可移植的代码，应尽量避免使用边界不对齐的访问。

通常情况下C编译器假定指针是边界对齐的。如果边界不对齐，那么程序的执行会产生不正确的结果。这样，把代码从那些允许边界不对齐访问的处理器移植到ARM时就会出现问题。

对armcc编译器来说，保留关键字__packed（取消无效填充）告诉编译器一个数据可以放在任何字节对齐的位置，这对移植代码是很有用的，但会影响性能。

为了说明问题，看下面的简单例子readint。这个函数返回由data指地址的一个整数，并且已经使用了__packed告诉编译器：这个整数可能不是边界对齐的。

```c
int readint(__packed int *data){
    return *data;
}
```

编译后生成

```assembly
readint
	BIC r3,r0,#3;r3 = data &0xfffffffc，清除11位
	AND r0,r0,#3;data = data & 0x3
	MOV r0,r0,LSL,#3;data = data<<3
	LDMIA r3,{r3,r12};这里不是堆栈操作不用那套指令，这是执行后增加，r12 = [r3]
	MOV r3,r3,LSR r0;r3 = r3>>r0
	RSB r0,r0,#0x20;r0 = 0x20-r0，32位逆向减法
	ORR r0,r3,r12,LSL r0;逻辑或
	MOV pc,r14
```

注意这段代码的大小和复杂度。编译器使用2个边界对齐的访问和数据处理操作来仿真边界不对齐的问题，开销很大，并说明了为什么要避免使用__packed，代替的做法是，**使用类型char*来指向可以出现在任何边界的数据**，这样就不会出现不对齐的访问。后面将介绍从一个char *指针读32位字的更高效的方法。

通常计算机之间传输信息，在读数据包或者文件时，就会碰到边界对齐问题。网络报文和压缩过的图像文件就是很好的例子。在这些文件中，2字节或者4字节的整数可能会出现在任意的偏移量位置。数据以尽可能被压缩，损害了边界对齐。

从数据包或压缩过的文件中读数据时，数据字节排序也是很大的问题。ARM核可以被配置成小端，或者大端工作模式，通常是小端模式。

ARM的字节排列方式通常在电源启动时设置，以后一直保持不变。下标说明了ARM中8位、16位、32位的load和store指令对于不同的字节排序方式是如何工作的。这里假定字节地址A与存储器传输的大小是对齐的。表格显示了存储器中字节方式的地址如何映射到load和store指令操作的32位寄存器。

| 指令    | 宽度/bits | b31~b24            | b23~b16 | b15~b8 | b7~b0 |
| ------- | --------- | ------------------ | ------- | ------ | ----- |
| LDRB    | 8         | 0                  | 0       | 0      | B(A)  |
| LDRSB   | 8         | S(A)就是符号位填充 | S(A)    | S(A)   | B(A)  |
| STRB    | 8         | X忽略即可          | X       | X      | B(A)  |
| LDRH    | 16        | 0                  | 0       | B(A+1) | B(A)  |
| LDRSH   | 16        | S(A+1)             | S(A+1)  | B(A+1) | B(A)  |
| STRH    | 16        | X                  | X       | B(A+1) | B(A)  |
| LDR/STR | 32        | B(A+3)             | B(A+2)  | B(A+1) | B(A)  |

处理字节排列方式和边界对齐问题的最好方法，对执行速度要求不是很严格的程序，用下面的例子说明问题。该例从边界可能不对齐的存储器中读一个4字节的整数。地址边界是否对齐在程序编译时刻是未知的。只有到运行时才知道，如果已经装载了一个大端数据的文件，比如JPEG图像，那就用readint_big;而对小端数据的字节流，就调用read_little。如果不考虑ARM配置的存储器字节排序方式，那么2个函数都能正确地执行。

例5.10从一个data指向的字节流读一个32位整型数据的函数。

字节流可以分别包含小端或者大端数据。这两个函数和ARM配置的存储器系统字节排序方式无关，因为他们只用字节访问。 

```c
int readint_little(char *data)
{
    int a0,a1,a2,a3;
    a0 = *data++;
    a1 = *data++;
    a2 = *data++;
    a3 = *data++;//a3的地址最高，小端的话高字节要在高地址上
    return a0|(a1<<8)|(a2<<16)|(a3<<24);
}
int readint_big(char *data)
{
    int a0,a1,a2,a3;
    a0 = *data++;
    a1 = *data++;
    a2 = *data++;
    a3 = *data++;
    return (((((a0<<8)|a1)<<8)|a2)<<8)|a3;
}
```

如果对程序执行速度有严格要求，那么最便捷的方法是写几个**关键程序的变体**（这是什么意思），对每种可能的边界对齐和ARM字节排序方式编写 不同的程序段。这样就可以根据实际情况调用不同的已经优化过的程序段。

例5.11read_samples程序处理从一个以地址in起始的N个16位的音频采样数据。这个音频采样数据是小端的。而且是字节对齐的。程序把采样数据复制到以out指向的short类型的数组。这些采样数据将会根据ARM内存的字节排序方式来存储。

这个程序段高效地处理了所有可能出现的情况，也不管输入边界对齐和ARM字节排序方式的配置。（大小端会导致字节流的顺序，边界对齐会导致无效数据填充）

```c
void read_samples(short *out,char *in,unsigned int N)//使用char*类型指针接收数据就是确保可以指向任意字节边界的数据。
{
    unsigned short *data;
    unsigned int sample,next;
    switch((unsigned int)in&1)//这里的强转没啥关系，转换的是地址本身，而不是指向的内容。这里是判断最低位的地址情况，如果结果是0说明地址是偶数的，也就边界对齐了，至于几字节对齐不知道
    {
        case 0://in指针地址与运算1结果是0说明边界对齐。
            data = (unsigned short*)in;
            do{
                sample = *(data++);
        #ifdef __BIG_ENDIAN
                sample = (sample >>8)|(sample <<8);//sample是16位的，其实就是循环右移，让低位字节和高位字节互换
        #endif
                *(out++) = (short)sample;//送入out指针中
            }while(--N);
            break;
        case 1:
            data = (unsigned short*)(in-1);//如果没有边界对齐，把地址-1，此时指针指向了偶数地址。
            sample =*(data++);
            #ifdef __BIG_ENDIAN
            	sample = sample&0xff;//取16位中的低八位，因为本来就是char类型，现在被强制转换成short类型，那么16位中就会有8位被填充了。
            #else
            	sample = sample >> 8;//不是大端模式的话取高字节
            #endif
            do{
                next = *(data++);//获取下一个16位的数据
            #ifdef __BIG_ENDIAN
                *out++ = (short)((next & 0xff00)|sample);//因为边界不对齐的原因，获得两个16位数据中的八位数据或运算。
            #else
                *out++ = (short)((next << 8)|sample);//否则就是小端模式
                sample = next >> 0;
            #endif
                
            }while(--N);
            break;
    }
}
```

这个程序的大小端变换我看明白了，边界对齐没搞懂。

整个程序对每一种字节对齐方法和边界对齐给出了不同的代码段。字节排序方式在编译时用__BIG_ENDIAN编译器标志表示。边界对齐在运行时使用switch状态语句来分别处理。

为进一步提高程序执行效率，甚至可以用32位读/写来代替16位读/写，在switch语句中产生了4个分支，每个分支处理一种可能的地址边界对齐问题。（为啥是四个分支）

小结字节排列方式和边界对齐

- 尽量避免使用边界不对齐的数据；
- 使用类型char*可指向任意字节边界的数据。通过读字节来访问数据，使用 逻辑操作来组合数据，这样代码就不会依赖于边界是否对齐或者ARM的字节排序方式的配置；
- 为了快速访问边界不对齐的结构体，可以根据指针边界和处理器的字节排序方式写出不同的程序变体。

这里说的程序变体就是switch中不同的分支。

### 5.10除法

ARM硬件上不支持除法指令。编译器是通过调用C库函数来实现除法运算 的。有许多不同类型的除法程序来适应不同的除数和被除数。第7章将着重分析汇编除法程序。C库函数中的标准整数除法程序，根据执行情况和输入操作数的范围，要话费20~100个周期。

除法和模运算/%执行起来比较慢，尽量避免使用，但是除数是常数的除法运算和用同一个除数的重复触发，执行效率会比较高。本节描述了如何用乘法运算代替除法运算，以及如何使除法调用的次数最少化。

对环形缓冲区操作经常要用到除法，其实完全可以避免这些除法运算。假定有一个buff_size大小的环形缓冲区，offset指定目前所在的位置。通过increment字节来增加offset的值，一般是这样写的：

```c
offset = (offset + increment)%buffer_size//环形缓冲区需要保证offset始终在buffer_size内
//还可以写成下面写法
    offset += increment;
	if(offset >= buffer_size)
    {
        offset -= buffer_size;
    }
```

第一种写法需花费50个周期，而第二种因为没有除法运算，需要花费3个周期。这里假定increment<buffer_size。

如果不能避免除法运算，那么就应尽量使除数和被除数是无符号的整数。有符号的除法运算更慢，因为需要先得到除数和被除数的绝对值，再调用无符号除法运算，最后再确定结果的符号。

许多C语言库中的除法函数返回商和余数。换句话说，每一个除法运算，余数是可以无偿得到的，例如，要在屏幕缓冲区找到偏移量为offset的屏幕位置(x,y)，可以这样写：

```c
typedef struct {
    int x;
    int y;
}point;
point getxy_v1(unsigned int offset,unsigned int bytes_per_line)
{
    point p;
    p.y = offset/bytes_per_line;
    p.x = offset-p.y*bytes_per_line;
    return p;
}
```

这里，似乎对p.x使用减法和乘法，少了一次除法运算；但是，实际上使用模运算或者取余运算效率更高。

例5.12在getxy_v2中，对除法程序，商和余数操作只需要一次调用。

```c
point getxy_v2(unsigned int offset,unsigned int bytes_per_line)
{
    point p;
    p.x = offset % bytes_per_line;
    p.y = offset / bytes_per_line;
    return p;
}
```

从下面编译器的输出结果可以看到，只有一次除法调用。实际上，这个程序要比前面的getxy_v1少4条指令。

注意：并不是对所有的编译器和C库都有这样的结果。

```assembly
getxy_v2
	STMFD r13!,{r4,r14};入栈
	MOV r4,r0;r4 = p,这里r0存放p指针
	MOV r0,r2;r0 = bytes_per_line
	BL	__rt_udiv;(r0,r1) = (r1/r0,r1%r0)，这里就是商和余数
	STR r0,[r4,#4];p.y = offset/bytes_per_line
	STR r1,[r4,#0];p.x = offset%bytes_per_line
	LDMFD r13!,{r4,pc}
```

#### 5.10.1带余数的无符号重复除法

在程序中，同一个除数的除法经常会出现很多次。在前面的例子中，bytes_per_line的值在整个程序中都是固定不变的。

如果使用3到2笛卡尔坐标表示，那么就可以使用同一个除数两次：

```mathematica
(x,y,z)->(x/z,y/z)
```

直接跳过

小结除法

- 尽可能避免使用除法，对环形缓冲区的处理可以不用除法。

### 5.11浮点运算

大多数ARM处理器硬件上并不支持浮点运算。这样在一个对价格敏感的嵌入式应用系统中，可节省空间和降低功耗。除了硬件向量浮点累加器VFP和ARM7500FE上的浮点累加器FPA外，C编译器必须在软件上提供浮点支持。（正因为处理器硬件不支持浮点运算，并且需要软件提供支持，所以避免在内核空间进行浮点运算，应用空间提供了C库函数进而支持模拟浮点数运算）

实际上，这意味着C编译器要把每一个浮点操作转换成一个子程序的调用。**C库函数**中的子程序使用整型运算来模拟浮点操作。这些代码是用高度优化的汇编语言编写的。尽管如此，浮点运算执行起来还是要比相应整型运算慢得多。

如果要快速执行并得到小数的值，那么就应使用定点或者块浮动算法。在音频、视频等许多数字信号处理中经常用到小数/分数。这是软件编程的一个很大也很重要的方面，要想获得最好的性能，就要用汇编语言来实现算法。

### 5.12内联函数和内嵌汇编

在5.5节介绍了如何高效地调用函数。使用内联函数可以完全去除函数调用开销。另外许多编译器允许在C源码中使用内嵌汇编。使用包含汇编的内嵌函数，可以使得编译器支持通常不能有效使用的ARM指令和优化方法。本节的例子将在armcc中使用内嵌汇编。

不要把内嵌汇编程序和汇编器armasm或者gas混淆（armasm这是ARM汇编编译器，输入汇编指令，输出二进制。汇编器就是把汇编编译成二进制的编译器，gas是Linux平台标准的汇编器），内嵌汇编是C编译器的一部分。C编译器仍然执行寄存器分配、函数进入和退出。同时编译器也会试图优化内嵌汇编，或者位调试模式分开优化。尽管C代码编译输出的结果在功能上与内嵌汇编程序是等价的。但他们是不完全相同的。

内联函数和内嵌汇编最大的好处是，可以实现一些在C语言部分中难以完成的操作。使用内联函数要比使用宏定义更好，因为后者不检查函数参数和返回值类型。（没错，在汇编层面上内联函数和宏定义一样，内联函数是把该函数在调用函数内部直接展开，不需要跳转的过程。宏定义是在预处理阶段进行宏替换，同样不需要跳转）

编译器会用内联代码来代替每个qmac函数调用。插入diamante来代替调用函数。

例5.16显示使用内嵌汇编高效实现qmac函数。

这个例子支持armcc和gcc两种内嵌汇编格式。他们有较大的差异。下面只列出内嵌汇编的部分

```c
#ifdef __ARMCC_VERSION
__asm
{
    ADDS i,i,i
    EORVS i,mask,i,ASR 31
    ADDS a,a,i
    EORVS a,mask,a,ASR 31
}
#endif
#ifdef __GNUC__
asm("ADDS %0,%1,%2 ":"=r"(i),"r"(i):"CC");//asm是用来声明内嵌汇编的
asm("EORVS %0,%1,%2,ASR #31":"=r"(mask),"r"(i):"CC");
asm("ADDS %0,%1,%2 ":"=r"(i),"r"(a):"CC");
asm("EORVS %0,%1,%2,ASR #31 ":"=r"(a):"r"(mask),"r"(a):"CC");
#endif
```

对于gcc编译器来说，内嵌汇编需要声明asm。

小结内联函数和内嵌汇编

- 使用内联函数来声明新的操作或者C编译器不支持的基本操作。
- 使用内嵌汇编可以利用到C编译器不支持的ARM指令，比如协处理器指令或者ARMv5E扩展指令。（如果C编译器不支持ARM指令，那么也编译不出来对应的汇编指令吧）

### 5.13移植问题

这里是把代码从其他处理器移植到ARM上可能会碰到的问题总结。

- char类型，在ARM上，默认char是无符号的，而不像许多其他处理器那样认为是有符号的。一个经常会碰到的问题是：在循环体中，使用一个char类型的循环计数值i，循环继续的条件是i>=0，这在ARM上就变成了无穷的循环。这种情况下，armcc会出现一个无符号数与0比较(unsigned comparison witch zero)的警告。可通过编译器选项使得char变成有符号的类型，或者把循环计数值改成int类型，解决这个问题。
- int类型，一些老的体系结构的int类型是16位的，当这些16位的int类型需要移到ARM的32位int类型上时，可能会带来一些问题。因为表达式在求值前已经被转换成int类型，因此，如果i=-0x1000，那么表达式i==0xf000在16位的机器上是真，在32位的机器上是假。
- 不对齐的数据指针，一些处理器支持从不对齐的地址装载short和int类型数据的值。C程序可以直接操作指针，这样可能会造成边界不对齐，比如，把一个char*转换成 int *。直到ARMv5TE，ARM体系结构都不支持边界不对齐的指针。并且在ARM上运行的程序要使用边界检查。把边界不对齐的访问定义为数据异常。
- 字节排列方式（大小端），C代码可以对内存系统的字节排列方式进行假设。
- 函数原型，armcc编译器传递参数是窄的，意味着数据要缩小到参数类型的范围。（如果函数参数传入int类型0x1，形参是short类型也可以就是宽的）如果函数原型不正确，那么函数可能会返回错误的结果。其他编译器传递参数是宽的，即使函数原型不正确，也可能产生正确的结果。
- 位域的使用，在一个位域中，各个位的编排和字节排列方式有关。如果C代码假定是以固定的次序来编排各个位的，那么这个代码就不是可移植的。
- 枚举的使用，虽然enum是可移植的，但不同的编译器你会对一个枚举类型分配不同数目的字节。gcc编译器分配4字节给一个枚举类型，armcc编译器只分配一字节。
- 内嵌汇编，在C代码中使用内嵌汇编会降低不同体系结构之间代码的可移植性。（不同编译器的内嵌汇编不同）可以把内嵌汇编分成几个小的容易被替换的内嵌函数，用C来实现函数。
- volatile关键字，对ARM的存储器映像外设端口类型定义要使用volatile关键字。这个关键字阻止编译器优化相关的存储器访问，也保证编译器生成正确类型的数据访问。指的就是只能访问[rx,#x]，而不能直接从寄存器读取。目前还没学到从cache中读取。这个要借助cp15协处理器实现。例如，如果定义了一个存储器位置是volatile short类型，那么编译器将会使用16位的load-store指令LDRSH和STRH来访问它。

### 5.14总结

通过一定的风格来编写C程序，可以帮助C编译器生成执行速度更快的ARM代码。对性能有严格要求的应用，经常会包含一些对系统性能起决定作用的关键程序，那么就要使用本章所列举的方法重点编写这些程序。

这里是本章设计的性能关键点：

- 对局部变量、函数参数和返回值要使用signed和unsigned int类型。可以避免类型转换（因为表达式会默认为int类型），而且可以高效地使用ARM的32位数据操作指令。
- 最高效的循环体形式是减计数到零的do-while循环
- 展开重要的循环来减小循环开销。
- 不要依赖编译器来优化掉重复的存储器访问。指针别名会阻止编译器的这种优化。
- 尽可能把函数参数的个数限制在4个以内，如果函数参数都存放在寄存器内，那么函数调用会快得多。
- 按元素尺寸从小到大排列的方法来安排结构体，特别是在thumb模式下编译。
- 不要使用位域，用掩码和逻辑操作来代替。
- 避免除法，可以用倒数的乘法代替。
- 避免边界不对齐的数据。如果边界不对齐（说明此时指针的地址是乱七八糟的）使用char*类型指针访问。（这个指针的地址是一字节对齐，不怕边界不对齐）
- 在C编译器中使用内嵌汇编可以利用到C编译器本不支持的指令或者优化。

## 第六章、ARM汇编与优化

- 编写汇编代码
- 性能分析和周期计数
- 指令调整
- 寄存器分配
- 条件执行
- 循环结构
- 值操作
- 高效的switch
- 边界不对齐数据的处理
- 总结

在一个嵌入式软件系统中 ，经常包含一些决定整个系统性能的关键程序，通过优化这些程序，可以降低系统的功耗和实时操作所需的时钟频率。优化可以把一个不可行的系统变成可行，也可以把一个毫无竞争力的系统变得极有竞争力。

如果认真地使用第五章中介绍的方法来编写C代码，那么就会获得相对较高的程序执行效率。但若要获得最好的性能，就要通过手写汇编来优化那些关键程序。手工编写汇编代码，可以直接控制在C语言编程时不能有效使用的3个优化工具：

- 指令调整，调整一段代码中的指令序列，以避免处理器的暂停等待。ARM指令执行是在指令流水线中进行的，所以一条指令执行的时间会受其相邻指令的影响。（C是不会考虑到流水线的效率问题）
- 寄存器分配，决定如何分配变量给ARM寄存器或者堆栈，以获得最好的性能。目标是要使访问存储器的次数降到最低。
- 条件执行，可以使用ARM条件代码和条件指令的全部功能。（这里的条件指的是cpsr的条件标志位吧）

优化汇编程序需要付出很多额外的努力，因而不必费力去优化那些对性能影响不大的程序。花时间去优化一个程序，其实也会有一些额外的收获，比如对运算法则，程序瓶颈和数据流等问题都有更好的理解。

6.1节将首先介绍ARM上的汇编程序编程方法，说明了如何把一个C函数替换为一个可以优化的汇编函数。

然后描述了针对ARM汇编的一般优化技术。这里不再专门论述Thumb汇编，因为使用32位数据总线时，32位的ARM汇编会有更好的性能。Thumb对减少C代码编译后的目标代码大小是最有帮助的，而在16位数据总线上，对性能和程序执行效率没有太大影响。当然，这里涉及的许多方法对ARM和Thumb是同样有效的。

对一个程序最好的优化是应根据目标硬件板上ARM核的不同而改变优化方法，特别是针对数字信号处理。当然，也可以写出一个对所有ARM核都相当有效的代码。为了保持一致，本章所有例子都使用针对ARM9TDMI的优化和周期计数。这些例子也可以有效地运行在从ARM7TDMI到ARM10E的所有ARM核上。

### 6.1编写汇编代码

本节给出的例子说明了如何编写基本的汇编代码。这里，假定读者熟悉第3章描述的ARM指令集也熟悉ARM和Thumb过程调用标准ATPCS。

和本书的其他部分一样，本章所有例子都使用ARM宏汇编器armasm，也可以使用GNU汇编器gas。

例6.1描述通常汇编优化的第一步：如何把一个C函数转换为汇编函数。看下面一个简单的C程序main.c：打印整数0~9的平方数。

```c
#include <stdio.h>
int square(int i);
int main(void)
{
    int i;
    for(i = 0;i <10;i++)
    {
        printf("Square of %d\n",i,square(i));
    }
}
int square(int i)
{
    return i*i;
}
```

来看下如何将square函数改写成执行结果相同的汇编函数。去除square中除声明以外的其他C代码，创建一个新的C文件main1.c，然后添加armasm汇编文件square.s。汇编文件内容如下：

```assembly
	AREA |.text|,CODE,READONLY;保留字AREA命名代码所在的区域，使用了非阿拉伯数字的字符作为标号或名字，最好用两个垂直的线把名字括起来；否则许多非阿拉伯数字的字符就会表示其他一些特殊的含义。这里定义了一个名为.text的只读代码区。
	EXPORT square;保留字EXPORT表示符号square可以用作外部连接。
; int square(int i)
square;armasm把不缩进的正文作为一个标号定义
	MUL r1,r0,r0;
	MOV r0,r1;
	MOV pc,r14;
END
```

C语言的内存包括了只读代码区。难道命名是由汇编实现的么。square被调用时，参数传递由ATPCS定义。输入参数通过寄存器r0传递，最后返回值也通过寄存器r0返回。ARM乘法指令有一个限制，就是目标寄存器不能和第一个参数寄存器相同，所以先把乘法结果放到r1，然后再送到r0。

保留字END表示汇编文件的结尾，分号表示注释的开始。

下面的命令举例了如何用命令行工具来生成这个例子的可执行文件。正常生成mian1.o文件，因为square文件用汇编写的，所以用armasm汇编器生成.o文件最后用过链接器生成main1.axf可执行文件。

```shell
armcc -c main1.c
armasm square.s
armlink -o main1.axf main1.o square.o
```

例6.1必须用ARM代码方式32位来编译，才能正确执行。如果以Thumb代码方式16位来编译，那么汇编子程序必须使用BX指令来返回。要切换回ARM状态。

例6.2当从以Thumb方式编译的C程序中调用ARM汇编代码时，例6.1的汇编代码唯一要改变的就是把返回指令改用BX。BX指令会根据lr寄存器的位0来判断是返回到ARM，，还是返回到Thumb状态。因此这个子程序既可以在ARM状态下，也可以在Thumb状态下被调用。只要处理器支持BX指令，就可用Bx lr来代替MOV pc，lr。创建一个新的汇编文件square2.s如下：

```assembly
	BX lr
```

使用Thumb C编译器tcc来构建这个例子，设置交叉工作方式允许，这样连接器就可以允许Thumb C代码调用ARM汇编代码。使用下面的命令来重建这个例子：

```shell
tcc -c main1.c
armasm -apcs/interwork square2.s
armlink -o mian2.axf main1.o square2.o
```

例6.3说明如何在一个汇编程序里调用一个子程序。

把例6.1整个程序转换成汇编程序，然后调用C库函数中的printf子程序。创建一个新的汇编文件main3.s，内容如下：

```assembly
	AREA |.text|,CODE,READONLY
	EXPORT main;输出main函数外部链接
	IMPORT |Lib$$Request$$armlib|,WEAK
	IMPORT __main ;C library entry
	IMPORT printf ;prints to stdout，printf是库函数需要链接进来
i	RN 4;允许i作为r4的替换名字
	;int main(void)
main
	STMFD sp!,{i,lr};保存寄存器上下文
	MOV i,#0
loop
	ADR r0,print_string;地址装载伪指令，第一次出现，意思是把printf函数地址送入r0中
	MOV r1,i;r1 = i = r4 = 0
	MUL r2,i,i;r2 = i*i
	BL printf
	ADD i,i,#1
	CMP i,#10
	BLT loop;i<10循环
	LDMFD sp!,{i,pc};出栈
print_string
	DCB "Square of %d is %d\n",0;DCB保留字用来定义一个字符串，或者以逗号分割的多个字节数据
END
```

使用下面的命令行脚本来构建这个例子，这里入栈sp和r4，是因为mian函数作为调用函数只能使用r0-r3寄存器，r4-r10寄存器是留给被调用函数存放参数的，而r11反正也需要保存，r14是sp肯定要保存的。这里因为被调用函数和函数定义都在同一个文件中，所以编译器优化为内部展开了，不需要调用成本

```shell
armasm mian3.s
armlink -o main3.axf main3.o
```

注意例6.3也假定代码从ARM状态被调用。最后来看一个例子，这个例子传递了多于4个的函数参数。ATPCS把前4个参数放在寄存器r0~r3.其余的参数存放在堆栈里。

例6.4定义一个函数sumof，可以求任意数目的整数的和。

参数是求和整数的个数和一串求和的整数。函数sumof用汇编语言编写，可以接受任意多个数目的参数。把这个例子的C代码部分放在文件main4.c：

```c
#include <stdio.h>
int sumof(int N,..);
int main(void){
    printf("Empty sum = %d\n",sumof(0));
    printf("1 = %d\n",sumof(1,1));
    printf("1+2=%d\n",sumof(2,1,2));
    printf("1+2+3=%d\n",sumof(3,1,2,3));
    printf("1+2+3+4=%d\n",sumof(4,1,2,3,4));
    printf("1+2+3+4+5=%d\n",sumof(5,1,2,3,4,5));
    printf("1+2+3+4+5+6=%d\n",sumof(6,1,2,3,4,5,6));
}
```

下一步在汇编文件sumof.s中定义sumof函数：

```assembly
	AREA |.text|,CODE,READONLY
	EXPORT sumof
N RN 0;N是r0的名称
sum RN 1;sum是r1的名称
;int sumof(int N,...)
sumof 
	SUBS N,N,#1;N保存了个数
	MOVLT sum,#0;如果结果小于0，就是N<1
	SUBS N,N,#1;
	ADDGE sum,sum,r2;如果N大于等于1，sum = sum+r2
	SUBS N,N,#1
	ADDGE sum,sum,r3;如果N大于等于1，sum = sum +r3
	MOV r2,sp;r2 = r14，为啥要送入r2中
loop
	SUBS N,N,#1
	LDMGEFD r2!,{r3};N>=1的话，r2 = r3
	ADDGE sum,sum,r3
	BGE loop
	MOV r0,sum
	MOV pc,lr
END
```

没看懂。我现在对于条件后缀有点糊涂了，nzcvq，z是为零 ，c是进位，v是溢出，q是饱和，这涉及到饱和运算，n是负数。SUBS是根据操作的结果来更新cpsr的。

代码把需要求和整数的剩余数目计数保存在N。前3个值在寄存器r1,r2,r3中，剩余的值放在堆栈。可以用下面的命令行来构建这个例子：

```shell
armcc -c main4.c
armasm sumof.s
armlink -o main4.axf main4.o sumof.o
```

### 6.2性能分析和周期计数

任何优化的第一步都是要找出对性能影响较大的程序段，并且测量它们目前的性能状况。**CPU性能分析器**可用来测量在每一个子程序上所花的**时间比例和执行周期**。因此，可以使用CPU性能分析器来判断对性能影响最大的程序。**周期计数器**用来测量一个特定程序段所占用的**周期数**。使用周期计数器来衡量某个子程序优化前后的性能情况，可以评估优化工作的成效。

ADS1.1调试器使用的ARM软件仿真器叫做**ARMulator**提供了性能分析和周期计数的功能。ARMulator性能分析器以一定的时间间隔来对程序计数器pc进行采样。性能分析器标识pc所指向的函数，并更新与之相遇的每一个函数的命中计数器的值。另外还可以使用性能分析器跟踪的输出作为一个源文件来进一步分析。

必须了解所使用的的性能分析器是如何工作的，以及他的精度限制。如果基于pc采样的性能分析器记录的采样点太少，那么产生的结果也就毫无意义。也可以采用硬件系统的pc采样性能分析器，也就是利用定时器中断来采集pc数据。

注意：定时器中断会降低正在被测量的系统的运行速度。

ARM提供的工具通常并不包含周期计数硬件部件。最简单的做法还是使用ARM调试器所带的ARM软件仿真器来测量周期计数。对于不同的硬件平台，可以把ARMulator配置为仿真不同的ARM核来获得周期计数基准。

### 6.3指令调整

指令的执行时间依赖于流水线的实现。本章内容假定使用ARM9TDMI的流水线定时，下面的规则总结了ARM9TDMI上一些公共指令的周期数情况。

指令执行依赖于在cpsr中的条件标志。如果条件不匹配，那么指令占用一个周期；如果条件匹配，那么就依照下面的规则：

- ALU操作，比如加法、减法和逻辑操作，占用一个周期，包括由一个立即数决定的移位。如果使用特定的寄存器移位，那么就要增加一个周期。如果指令是写入pc的，就要增加2个周期。
- 从存储器装载N个32位字的装载指令，比如LDR和LDM，将占用N个周期。但是要注意，接下来的一个周期，装入的最后一个字还不能被使用。再下一个周期是更新装载地址。这里假设是针对没有cache的零等待的存储器，或是带有cache并cache命中的情况。只装载一个值的LDM指令是个例外，需要花费2个周期。如果指令装载pc，那么也要增加2个周期。
- 从存储器装载16位或者8位数据的装载指令，比如LDRB,LDRSB,LDRH和LDRSH占用1个周期。在接下来的2个周期中，装入的结果还不能 被使用。下一个周期是更新装载地址。
- 分支指令占用3个周期
- 存储指令中，存储N个值占用N个指令周期。如果只存储一个值的STM指令，要花费2个周期。
- 乘法指令依赖于第二个操作数的值会有多个不同 周期数。

为了理解在ARM上如何有效进行指令调整，就需要了解ARM流水线及其相关性。ARM9TDMI处理器可并行地执行5个操作：

- 取指，在地址pc处从存储器中取出指令。指令被装载到内核中，然后进入指令流水线。
- 译码，对前一个周期中取到的指令进行译码。如果操作数还没准备好，那么处理器可以通过前向通道之一从寄存器堆中读入操作数。
- ALU，执行前一个周期译码的指令。注意这条指令是从地址pc-8(ARM状态)或者pc-4(Thumb状态)取到的。通常，这一步包括了计算数据操作的结果，或计算装载、存储、跳转操作的地址。在这一步，一些指令会花费几个周期。
- LS1，通过装载/存储指令来**装载/存储**特定的数据。如果不是装载或者存储指令 。那么这个步骤完全没有任何作用。
- LS2，对通过字节或者半字装载的数据进行**截取和左端补0**，或符号位扩展。如果指令不是装载一个8位字节或者16位半字的，那么该步骤也没有任何意义。

下图是5级ARM9TDMI流水线的简化功能图。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1683706010623.png" alt="1683706010623" style="zoom: 50%;" />

没啥问题，当前pc取指的地址是pc，译码的指令地址就是pc-4

一条指令完成了流水线的5个步骤后，最后结果写入寄存器。

流水线是如何影响指令执行时间的，考虑下面的例子，这些例子说明了指令执行的周期数是如何改变的，由于当前指令在流水线中继续之前，必须等前一条指令完成某个步骤；并且使用指令周期事件来计算一段代码需要花费的周期数。

如果一条指令需要前一条指令的执行结果，而这时结果还没有出来，那么处理器就会等待。这称为流水线相关。或者流水线互锁。

例6.5没有互锁的情况

```assembly
ADD r0,r0,r1
ADD r0,r0,r2
```

这两条指令占用了2个周期。ALU用1个周期计算r0+r1，因此这个结果在第二个周期ALU计算r0+r2时已经准备好了。

例6.6显示由于装载产生了1个周期互锁

```assembly
LDR r1,[r2,#4]
ADD r0,r0,r1
```

这两条指令占用了3个指令周期。在第一个周期，ALU计算地址r2+4，同时译码ADD指令，但是因为装载指令还没有把r1的值装载进来。ADD在第二个周期就不能继续下去。因此流水线等待了1个周期，直到装载指令完成LS1步骤，当r1准备好后，处理器在第3个周期ALU执行ADD操作。

下图说明了互锁是如何影响流水线的。ADD指令在流水线的ALU阶段暂停了一个周期，等待装载指令完成LS1步骤。图中这个暂停用斜体的*ADD*表示。由于LDR指令在流水线继续执行，而ADD指令中断了他们之间出现了一个间隙。这个间隙被称为流水线气泡。这个流水线气泡是一个机器周期长度。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1683708118883.png" alt="1683708118883" style="zoom:50%;" />

指令周期就是指令从取指到执行完毕的时间。上图中两个指令之间差了LS1的时间。在LDR指令没有执行完LS1阶段时，ADD只能被暂停。这里的周期是指令周期的时间。要不然从ALU到LS1本身就花费一个机器周期了。

例6.7显示由于延迟装载引起的1个周期的互锁。

```assembly
LDRB r1,[r2,#1]
ADD r0,r0,r2;没用到r1所以不产生流水线气泡
EOR r0,r0,r1;
```

这三条指令占用了4个周期。虽然ADD紧跟在装载字节后的周期进行，但是EOR指令不能在第3个周期开始。寄存器r1的值移植要到装载指令完成流水线的LS2阶段才会准备好，处理器中止EOR指令一个周期。

注意ADD指令一点也没有影响流水线时钟。无论ADD指令是否存在，整个流程总是占用4个指令周期。这里是因为使用的字节装载指令，在LS1阶段装载到寄存器后还没结束，还需要进行左端补0或符号位扩展。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1683715506238.png" alt="1683715506238" style="zoom:50%;" />

不过这里的周期吧，如果是指令周期，其实两个指令花费的时间小于指令周期，因为并行执行功能部件的缘故，实际上也就花费6个机械周期。不知道这里怎么计算的，所谓的延迟也不是LDR指令被延迟，而是后一个指令被延迟了一个机器周期而已，就是机器周期，所谓的三条指令占用了四个周期，这里占用是认为三条指令同时执行。

例6.8说明为什么分支指令要占用3个周期。处理器在跳转到一个新的地址时必须刷新流水线。

```assembly
	MOV r1,#1
	B case1
	AND r0,r0,r1
	EOR r2,r2,r3
case1
	SUB r0,r0,r1
```

3条执行的指令一共占用了五个周期，MOV指令 在第一个周期你执行 。在第二个周期，分支指令计算 目标地址，这时需要刷新流水线，用新的pc值填入。重新填入花费了两个周期。（这里花费的两个周期指的是会产生两个流水线气泡）最后，SUB指令正常执行。下图显示了流水线每一个周期的状态。流水线在跳转发生时会丢弃分支指令之后的两个指令（这就是所谓的花费了两个机器周期）。因为流水线的问题，花费了两个周期就是指的并行执行的两个机器周期的产物被放弃。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1683716341261.png" alt="1683716341261" style="zoom:50%;" />

###### load指令的调整

装载指令在编译后的代码中出现的频率很高，计算下面 大约占所有指令的1/3,。所以，仔细安排装载指令的时间次序可以防止流水线终止，改善性能。编译器会 尽量安排好代码执行的时间顺序，但是5.6节中描述的指针别名问题会影响编译器优化。如果不能保证 load和store指令中的2个指针不指向同一个地址，那么编译器就不能去除在store指令之前的load指令。

看一个关于密集存储器访问任务的例子。下面的函数str_tolower把一串以0结束的字符串从in复制到out，并在处理过程中把字符串转换成小写字母。

```c
void str_tolower(char *out,char *in)
{
    unsigned int c;
    do{
        c = *in++;
        if(c>='A'&&c<='Z')
        {
            c = c+('a'-'A');//取小写
        }
        *out++=(char)c;
    }while(c);
}
```

ADS1.1编译器生成了下面的输出结果。

注意：编译器优化了条件(c>='A'&&c<='Z')，变为检查0<=c-'A'<='Z'-'A'，因为编译器可以使用一条无符号比较指令来完成这个检查。

```assembly
str_tolower
	LDRB r2,[r1],#1;r2 = *(r1++)
	SUB r3,r2,#0x41;r3 = c-'A'，这要等待两个机器周期
	CMP r3,#0x19;if(c<='Z'-'A')
	ADDLS r2,r2,#0x20;c+='a'-'A'
	STRB r2,[r0],#1;*out++ = (char)c
	CMP r2,#0
	BNE str_tolower
	MOV pc,r14
```

遗憾的是，在LDRB指令装载了c之后，SUB指令立即使用c的值，这样ARM9TDMI流水线将等待2个周期。这是因为要等待LS2阶段完成，所以需要两个机器周期。由于load指令之后的每一条指令都要用到c这个值，因此编译器不能做任何更好的改进。但是，有两种方法，可以通过使用汇编，改变算法结构来消除等待周期。这里把这些方法称为通过预载和循环展开来调整、安排load指令。

1. 通过预载来调整load指令

   这种安排装载时序的方法，就是在本次循环的最后装载下次循环所需要的数据，而不是在本次循环的开始装载数据。为了不增加代码量，将不对循环进行展开。

   例6.9str_tolower使用了预载的方法

   ```assembly
       out RN 0
       in RN 1
       c RN 2
       t RN 3
       str_tolower_preload
       LDRB c,[in],#1;c = *in++
   loop
   	SUB t,c,#'A';t = c-'A';第一次循环开头会延迟两个周期
   	CMP t,#'Z'-'A'
	ADDLS c,c,#'a'-'A'
   	STRB c,[out],#1
   	TEQ c,#0;这里并不是条件执行，判断c==0，超出边界的数组元素默认是0
   	LDRNEB c,[in],#1;LDRB+NE，如果不相等则c = *in++，条件标志是防止数据超出边界。
   	BNE loop;跳转指令会导致两个周期空白，LDRNEB指令在LS2阶段时，BNE指令在LS1，ALU和译码空白，SUB指令在取指阶段，不会受到LDRNEB的影响。
   	MOV pc,lr
   ```
   
   循环体内部除了B导致的两周期空白外，没有延迟了，这个程序比C版本多了一个指令，在循环体结尾c = *in++。但是循环体内部少了两个周期。这使得在ARM9TDMI上每个字符的处理循环从11个周期减少到9个周期。性能提升了1.22倍。（关于这个指令周期和机器周期，书中明确提到周期指的是指令周期，但指令周期是指令从取指到执行完毕的时间，很明显不符合，但考虑到流水线并行问题，两个指令执行时间是两个指令周期，但这两个指令肯定有重合的地方，所以书中的指令周期肯定不是完整的流程时间，应该就是机器周期）
   
   因为ARM指令是可以条件执行的，所以ARM体系结构特别适合这种类型的预载。由于循环i装载的数据是为循环i+1准备的，这样对于第一次和最后一次循环存在问题。对第一次循环，可以在循环开始前通过增加额外的load指令来预载数据；但对最后一次循环，循环体已不需要再读取任何数据，读取的可能是超出数据边界的数据，可能会引起数据异常终止。abt模式吧，对于ARM，可以通过load指令的条件执行来解决问题。
   
2. 通过循环展开来调整load指令

   这种调整load指令的方法是通过循环展开来插入复制循环体的内容。一次循环执行i，i+1，i+2的循环体内容，当循环i中的某个操作结果还没有准备好时，可以先执行循环i+1中的操作。但这会导致顺序改变。

   例6.10对str_tolower函数使用了循环展开的方法来调整load指令

   ```assembly
       out RN 0
       in RN 1
       ca0 RN 2
       t RN 3
       ca1 RN12
       ca2 RN 14
       str_tolower_unrolled
       STMFD sp!,{lr}
   loop_next3
   	LDRB ca0,[in],#1
   	LDRB ca1,[in],#1
   	LDRB ca2,[in],#1
   	SUB t,ca0,#'A';执行SUB的ALU的时候LDRB已经结束了
   	CMP t,#'Z'-'A'
   	ADDLS ca0,ca0,#'a'-'A'
   	SUB t,ca1,#'A'
   	CMP t,#'Z'-'A'
   	ADDLS ca1,ca1,#'a'-'A'
   	SUB t,ca2,#'A'
   	CMP t,#'Z'-'A'
   	ADDLS ca2,ca2,#'a'-'A'
   	STRB ca0,[out],#1
   	TEQ ca0,#0
   	STRNEB ca1,[out],#1
   	TEQNE ca1,#0
   	STRNEB ca2,[out],#1
   	TEQNE ca2,#0
   	BNE loop_next3
   	LDMFD sp!,{pc}
   ```

   可以看到，这个循环的执行效率是最高的。在ARM9TDMI上对每个字符的处理操作只需要7个周期。比最初的str_tolower性能提高了1.57倍。而且由于ARM指令能条件执行，避免了访问超过字符串结尾的字符。

   但是，例6.10的改进也带来了一些额外的开销：代码量比原来增加了2倍。上面的代码假定在输入字符串的结尾后可以再读取2个字符，但如果字符串正好处在RAM的最后，就会产生数据异常。另外，对于很短的字符串，执行效率可能也会降低，这是因为：
   
   - 堆栈操作lr会引起额外的函数调用开销;这句话没理解，链接地址入栈为什么会引起额外的开销。
   - 在发现最后2个字符是越界字符前，程序可能已毫无意义地对这2个字符进行了操作。

在确定 数据量比较大的情况下，对实时要求高的部分应用程序使用循环展开的方法会比较合适。而且，如果在编译时就已经知道了数据量的大小，那么就可以解决越过数组边界的读取问题。

小结，指令调整

- ARM核是流水线结构的。如果指令的执行结果是后续指令的源操作数，那么处理器将会插入等待周期直至数据准备好，这样流水线就会产生几个周期的延迟。具体的周期数和流水线级数有关，也和数据在哪里被使用有关。
- load和乘法指令在许多情况下会产生延迟。
- 有2种软件方法可以解决由load指令导致的流水线互锁:预载--在循环i中预载循环i+1的数据;循环展开--在一次循环中插入原循环体i和+i+的代码。

### 6.4寄存器分配

可以使用ARM16个可见寄存器（通用寄存器）中的14个来保存通用数据，另外2个是堆栈指针r13和程序计数器r15.对于一个遵循ATPCS调用规则的函数，必须保护**被调用寄存器r4~r11的值**。ATPCS同时也规定了堆栈应是8字节边界对齐的，因此在调用子程序时必须保护边界。对优化过的、需要很多寄存器的汇编程序，可以使用下面的模板来保护寄存器：

```assembly
routine_name
	STMFD sp!,{r4-r12,lr};lr=r14
	;routine的主体
	;r0-r12+lr是可获得的
	LDMFD sp!,{r4-r12,pc}
```

栈操作（压栈和退栈）r12的唯一目的是：保证堆栈是8字节边界对齐的。如果程序不调用其他的ATPCS子程序，那么无须对r12进行栈操作。（这里的r12和运算有关的寄存器）对于ARMv5及其以上的体系结构，甚至当程序从Thumb代码中被调用时，也可以使用上面的模板。但在ARMv4T处理器上，如果程序可能从Thumb代码中被调用，那么应该把模板修改为：

```assembly
routine_name
	STMFD sp!,{r4-r12,lr}
	;
	;
	LDMFD sp!,{r4-r12,lr}
	BX lr;切换回ARM状态 
```

下面将着重分析对寄存器需求比较大的任务该如何较好地把变量分配到寄存器，如何处理局部变量超过14个的情况，以及如何最好地利用14个可用的寄存器。

#### 6.4.1分配变量给寄存器

编写一个汇编程序时，最好为变量使用寄存器名字，而不是直接使用寄存器编号。这样可以容易地更改变量分配的寄存器编号。如果变量不会交迭使用，那么还可以对同一个物理寄存器使用不同的寄存器名字。使用寄存器名字可以提高代码的清晰度和可读性。

对寄存器来说，大部分的ARM操作都是正交的。换句话说，特定的寄存器并**没有特定的角色**。在一个程序里，如果把2个寄存器Ra和Rb在所有出现的地方都互换，那么程序的功能并不会改变。但是，也有一些情况寄存器的物理编号是重要的：

- 参数寄存器，ATPCS规范定义了一个函数的前4个参数是分配在寄存器r0~r3的。其他的参数存放在堆栈，返回值必须存放在r0。
- 一个多次装载或存储操作所使用的寄存器，一条多寄存器装载或存储的LDM和STM指令。总是操作一组编号按增序排序的寄存器。如果r0和r1出现在操作寄存器中，那么处理器将总是在**低地址装载或存储r0**，然后是r1等等。多次装载是有顺序的，优先从r0开始
- 装载和存储双字，在ARMv5E上引入的LDRD和STRD指令，总是使用一对连续编号的寄存器Rd和Rd+1，而且，Rd必须是偶数编号寄存器。比如r0r2r4

举例来看编写汇编程序时如何分配寄存器。假定想要对存储器中N位数的一个数组向上移动k位(这里的意思是左移并且把被移除的位送入高位存储单元中)。为了简单起见，假定N是一个很大的数，而且是256的倍数，同时假定0<=k<32，输入/输出指针都是字边界对齐的。这种乘以2^k类型的操作，对于处理多精度数的算术运算是较普遍的。而且对于从一种位或者字节边界对齐，到另一种位或字节边界对齐的块拷贝操作是很有用的。例如，C库函数memcpy可以只用字访问来复制一字节的数组。

C函数shitf_bits实现了一个简单的对N位数的k位移位操作：

```c
unsigned int shift_bits(unsigned int *out,unsigned int *in,unsigned int N,unsigned int k)
{
    unsigned int carry =0,x;
    do{
        x = *in++;
        *out++ = (x<<k)|carry;
        carry = x>>(32-k);//这是循环左移，这不是乘法，没错，这里是将数据整体往高位移动。左移代表高位移动，所以这是小端。
        N- = 32;
    }while(N);
    return carry;
}
```

提高效率最明显的方法是展开循环来一次处理8个字也就是256位的数据。这样就可以利用多寄存器装载或存储load和store指令，一次装载和存储8个字的数据，以获得最高效率。先不考虑寄存器数量，编写出下面的代码：

```assembly
shift_bits
	STMFD sp!,{r4-r11,lr};这里是入栈操作，sp不断减少，所以从[sp--] = lr
	RSB kr,k,#32;32位逆向减法
	MOV carry,#0
loop
	LDMIA in!,{x_0-x_7};将in指针内容出栈到八个寄存器中。装载多个寄存器，I表示上升，A表示after。这里是x_0 = *in++
	ORR y_0,carry,x_0,LSL k;先将x_0左移k位，与carry进行逻辑或，结果存入y_0中，因为carry是0，所以y_0只有x_0的低位
	MOV carry,x_0,LSR kr;将x_0右移k位结果存入carry中
	ORR y_1,carry,x_1,LSL k;将x_1的低32-k位+x_0的高k位组成32位存入y_1中，这里地址是x_0从低开始的，相当于整体往高位移动了。
	MOV carry,x_1,LSR kr
	....
	STMIA out!,{y_0-y_7};这里是后增加，所以从y_0开始存储。
	SUBS N,N,#256;N = N-256
	BNE loop;如果N不等于0循环
	MOV r0,carry
	LDMFD sp!,{r4-r11,pc};满堆栈地址下降，装载寄存器，这里就是从这里的sp是需要上升的，因为只有高地址存储单元才有数据装载到寄存器中，等价于LDMIA，所以r4 = [sp++]
```

----

关于STMIA等多寄存器装载和存储操作中{r0-r11}到底从哪个寄存器开始，不同的指令可能会导致顺序不同，但是不变的是寄存器组从左到右对应的地址依次增加。根据这条规律可以推出方向

---

现在看寄存器分配，输入参数并不需要移动寄存器，可以立即指派：

```assembly
out RN 0
in RN 1
N RN 2
k RN 3
```

要使多次装载能正确工作，必须把x0~x7分配给编号连续递增的寄存器，y0~y7也一样。注意在开始y1操作之前，已完成了对x0的操作，所以可以对Xn和Yn-1指派同一个编号的寄存器。

当寄存器不够分配时：

- 在每一个循环中减少操作，以减少所需要的寄存器数目。这种情况 下，load可以每次只装载4个字的数据，而不是8个字。
- 使用堆栈来存储最少使用的值，以释放一些寄存器。这种情况下，可以把循环计数值N存放在堆栈。
- 改变代码的实现，以释放更多的寄存器。下面使用这种解决方法。

我们经常重申，一个算法的实现过程要通过多次调整寄存器分配，直到算法适合于14个有效寄存器。在上述例子中可以发现，变量carry根本不需要一直放在同一个寄存器中 。开始时carry存放在y0，当x0不再需要时，转移到y1，以此类推。这样就可以把kr分配给lr来完成这个程序，因为carry不再需要新的寄存器分配。

例6.11最后优化过的shift_bits程序，使用了全部14个可用的ARM寄存器。

```assembly
kr RN lr
shift_bits
	STMFD sp!,{r4-r11,lr}
	RSB kr,k,#32;逆向减法
	MOV y_0,#0
loop
	LDMIA in!,{x_0-x_7};x_0 = *in++n
	ORR y_0,y_0,x_0,LSL k
	MOV y_1,x_0,LSR kr
	...
	STMIA out!,{y_0-y_7}
	MOV y_0,y_7,x_7,LSL k
	SUBS N,N,#256
	BNE loop
	MOV r0,y_0
	LDMFD sp!,{r4-r11,pc}
```

#### 6.4.2使用超过14个的局部变量

如果需要在一个程序中使用多于14个32位的局部变量，那么就必须把一些变量存放在堆栈中。基本的做法是，从一个算法的最内层循环向外考察，因为最内层循环对性能的影响最大。（毕竟最内层的数据循环次数最多）

例6.12显示3层嵌套循环，每一层循环需要从他的外层循环继承的状态信息。

```assembly
nested_loops
	STMFD sp!,{r4-r1,lr}
loop1
	STMFD sp!,{loop1 registers};//保存寄存器
loop2
	STMFD sp!,{loop2 registers}
loop3
	B{cond} loop3
	LDMFD sp!,{loop2 register}
	B{cond} loop2
	LDMFD sp!,{loop1 register}
	B{cond} loop1
	LDMFD sp!,{r4-r11,pc}
```

可以发现，即使使用例6.12中的构造，对最内层循环还是没有足够的寄存器，那就需要交换内部循环变量到外部堆栈。如果直接用数字作为堆栈地址的偏移量，那么对于汇编代码来说是很难维护和调试的，汇编器会在分配变量到堆栈时自动计算偏移量。

例6.13显示如何使用ARM汇编保留字MAP和FIELD，以在堆栈中为变量和数组定义和分配空间。这两个保留字与C中的struct操作有相似的作用。

```assembly
	MAP 0
a	FIELD 4
b	FIELD 2
c	FIELD 2
d	FILED 64
length	FIELD 0
example
	STMFD sp!,{r4-r11,lr}
	SUB sp,sp,#length
	...
	STR r0,[sp,#a];当不使用多寄存器装载存储指令时，为了避免直接使用数字表示sp的偏移量，采用别名的形式。
	LDRSH r1,[sp,#b];16位
	ADD r2,sp,#d
	...
	ADD sp,sp,#length
	LDMFD sp!,{r4-r11,pc}
```

#### 6.4.3最大限度地使用寄存器

在像ARM这样的load-store体系结构处理器上，访问寄存器中的数据要比访问存储器中的数据效率高很多。这里有一些关于把几个小于32位长度的变量存放在一个32位寄存器的窍门，这样做可以减少代码尺寸，并改善性能。本小节列举了3个例子。说明如何把多个变量打包在一个ARM寄存器。

例6.14假定需要通过一个可编程的增量来遍历数组。一个普通的例子是通过一个可变采样率的声音来步进产生不同音调的音符。用C代码表示如下：

```c
sample = table[index]
    index += increment
```

通常变量index和increment都是很小的，足以保存在一个16位变量中。把这两个变量打包放入一个32位的变量indinc：

```c
indinc = (index << 16)+increment
```

这里将增量的本身放入高16位，增加量放入低16位。然后用一个32位变量indinc表示。将这行C代码转换成汇编，使用一个寄存器来存放indinc:

```assembly
LDRB sample,[table,indinc,LSR #16]
ADD indinc,index,increment,LSR #16
```

没太明白这里啥意思，不就是送入高16位吗

例6.15如果使用寄存器中的数值作为移位次数，ARM使用寄存器的位0~7作为移位值，并忽略寄存器的位8~31，那么就可以用位8~31来存放另一个变量。（这个操作似成相识，有一种SPARC体系结构不支持原子操作的汇编指令，低八位存放锁）

这个例子显示了如何组合寄存器指定的移位值shift和循环计数值count，把40个元素的数组右移shift位。我们定义了一个新变量cntshf来存放count和shift:

```c
cntshf = (count << 8) +shift
```

```assembly
out RN 0
in RN 1
cntshf RN 2
x RN 3
shift_right
	ADD cntshf,cntshf,#39 << 8
shift_loop
	LDR x,[in],#4;x = *in++
	SUBS cntshf,cntshf,#1 << 8;
	MOV x,x,ASR cntshf
	STR x,[out],#4
	BGE shift_loop
	MOV pc,lr
```

例6.16在处理8位或16位值的数组时，有时可以把多个变量同时放入一个32位的寄存器中。这称为单发射多数据处理。

直至ARMv5的体系结构版本并不显示地支持SIMD操作。但是，仍然有些地方可以进行SIMD处理。6.6节将介绍如何把多个循环变量存放在一个寄存器里。这里将研究一个关于图像的例子，使用普通的ADD和MUL指令处理一副图像中的多个8位像素，以完成一些SIMD操作。

假定需要把两幅图像X和Y合并成一副新的图像Z。分别用x,y,z来表示这些图像中的第n个8位像素。设范围为0~256的a为比例因子。为合并图像，设：

```mathematica
zn = (axn + (256 - a) * yn) / 256
```

换句话说，图像Z是图像X以比例a/256加到以1-(a/256)位比例的图像Y上。

直接看结果吧。

![1684483994923](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1684483994923.png)

然后把8位的数据通过一条AND指令和屏蔽寄存器将其变成16位数据。使用下面的符号：

![1684484120591](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1684484120591.png)

小结寄存器分配

- ARM有14个通用寄存器：r0~r12和r14，堆栈指针寄存器r13和程序计数器r15不能用于通用数据。操作系统中断时，经常假定用户模式下的r13指向有个有效的堆栈，因此不要试图去使用r13.其实就是被中断的指令地址。
- 如果使用的局部变量超过了14个，那么从最内层循环向外把剩余的变量放入堆栈。
- 在编写汇编程序时，应尽量使用寄存器名字，而不是物理寄存器编号。这样做可便于重新分配寄存器和维护代码。
- 为了有效利用寄存器，有时可以把多个变量存放在一个寄存器中。比如把循环计数值和移位值放在一个寄存器中，也可以把多个像素存放在一个寄存器中。

### 6.5条件执行

ARM指令集的一个重要特征就是大多数的指令均可包含一个可选的条件码。（这里指的就是可以更新cpsr条件标志位）当程序状态寄存器cpsr中的条件标志满足指定条件时，**带条件码的指令才会执行**。条件执行基于**15个条件码**之一。若没有指定条件，则汇编器默认为无条件执行AL，其他14个条件被分成7对。这些条件依赖于cpsr寄存器中的4个条件标志NZCV。

默认情况下，ARM指令并不会更新ARM寄存器cpsr中的N,Z,C,V标志。对大多数的指令，若要更新这些标志，则需要对指令助记符加后缀S。例外的是不写入目标寄存器的比较指令，他们**唯一的目的就是更新这些标志**，因此不需要S后缀。其实还包括饱和运算指令，QADD不需要后缀就可以更新Q标志。

通过组合使用条件执行和条件标志设置，可以简单地实现if语句，而不需要任何分支指令。这里可以改善性能，因为分支指令会占用较多的周期数;同时也可以减少代码尺寸。

例6.17下面的C代码把一个unsigned integer类型的i(0<=iM=15)转换成一个十六进制的字符c：

```c
if(i < 10)
{
    c = i + '0';
}
else{
    c = i + 'A' - 10;
}
```

这个早就学过了。

小结条件执行

- 利用条件执行可实现大部分if条件语句，比使用条件分支指令效率高很多；
- 可使用带有条件码的比较指令来实现带有几个类似的逻辑AND或者OR的if条件语句。

### 6.6循环结构

大部分对性能影响较大的程序都会包含循环体。在5.3节中提到使用减计数到零结构的ARM循环执行速度是最快的。本节将会讨论如何用汇编来实现高效的循环体；同时也会介绍如何展开循环已获得最好的性能。

#### 6.6.1

#### 6.6.2

#### 6.6.3多层嵌套循环

多层嵌套循环需要多少个循环计数器，实际上，一个计数器就可以满足对循环计数总值不超过32位的循环体。可以把多个循环计数值组合放在一个寄存器，最内层的循环计数值放在寄存器的最高位。本小节给出了一个例子，以说明如何做这件事，循环计数从max-1减到0，计数值变成负数时循环结束。

#### 6.6.4其他计数循环

在循环体中，有时循环计数值是作为一个输入值参与运算的：而且也并不是在所有情况下，循环计数值计数都是从N减到1或者从N-1减到0.比如一次从一个数据寄存器选择某些位，则需要一个每次循环乘以2的屏蔽。

下面将介绍一些不同计数形式的循环结构。这些例子都只使用了一条有分支功能的条件执行指令来实现循环。

##### 6.6.4.1负数索引

这个循环的计数值计数-N~0，每次累加的大小是STEP。

```assembly
RSB i,N,#0;i = 0 - N
loop
	ADDS i,i,#STEP
	BLT loop;如果i有符号小于0则循环
```

#### 6.6.4.2对数索引

这个循环结构每次以2的幂从2^N递减到1.比如，N=4，计数值为16,8,4,2,1。

```assembly
MOV i,#1
MOV i,i,LSL N
loop
	MOVS i,i,LSR #1;逻辑右移1位也就是/2
	BNE loop;
```

下面的循环结构计数值从N位屏蔽到1位屏蔽。这种方式是针对奇数的。

```assembly
MOV i,#1
RSB i,i,i,LSL N;i = i<<N - i
loop
	MOVS i,i,LSR #1
	BNE loop
```

##### 小结 循环结构

- 对ARM来说，需要2条指令来实现一个计数循环：一条设置标志的减法指令和一条条件分支指令。
- 展开循环可以改善性能。但不要过渡展开，因为这会影响cache的性能。只有对大的循环次数的循环进行展开才有意义，对于循环次数很少的循环展开并不能提高效率。
- 多层嵌套的循环只需要一个循环计数寄存器。这样做可以节省寄存器，移作他用。
- ARM可以高效地实现以负数和对数方式索引的循环。

### 6.7位操作

压缩的文件格式以位的粒度来打包数据项，以获得最高的数据密度（指的是存储单元中没有空闲的位)。这些数据项或者是固定宽度的，或者是可边长度的。比如用来表示长度的域或者表示版本的域是固定宽度的；而Huffman编码就是可变宽度的，因为Huffman编码是与特征位有关的编码方法，因而它赋予出现频度较短的编码，而对很少出现的信号赋予较长的编码。

本节将**讨论如何高效地处理位流**。首先论述固定宽度的编码，然后是可变宽度的编码。7.6节会介绍一般的位操作函数。比如位反转和字节排序方式。

#### 6.7.1固定宽度的位域打包和解包

如果事先已经设定了屏蔽码，那么从ARM寄存器的任意位置截取一个无符号的位域只需要1个周期；否则需要2个周期。截取一个带符号的位域一般需要2个周期，除非位域正好位于一个字的高位顶部（此时位域的最高符号位就是寄存器的最高符号位，只需要一个周期装载一个字32位即可）。在ARM上，一般使用逻辑操作和桶型移位器来打包和解开代码。请参见下面的例子。

例6.22显示如何把寄存器r0中的位4~15提取出来，结果放到寄存器r1。

```assembly
;mask = 0x00000FFF
AND r1,mask,r0,LSR #4;r1 = mask & r0>>4获得15~4
```

例6.23把r1的值放入寄存器r0的特定位域中。

如果r1的值已经被限定在正确的范围内，r0的相应位也被清除，那么就只需要1个周期。在这个例子中，把r1的12位数据插入到r0的位4~15。

```assembly
ORR r0,r0,r1,LSL #4;r0 = r0|r1<<4
```

否则就需要设置一个屏蔽寄存器：（防止堆栈访问过界也会设置一个堆栈限制r10）

```assembly
AND r1,r1,mask
BIC r0,r0,mask,LSL #4;清除目标位
ORR r0,r0,r1,LSL #4;拼接新数据
```

#### 6.7.2可变宽度编码的位流打包

这里的任务是要把一系列可变长度的diamante打包成一个位流。典型的就是把长度不定的Huffman编码或者其他算术编码数据压缩成一个数据流。但这里并不关心所用的编码方式的效率。

首先需要仔细地了解打包数据的字节排列方式。许多压缩文件格式使用大端方式打包，这种方式下，第一个数据的编码放置在第一个字节的最高端。为了统一起见，下面的例子都采用了大端方式打包。（高位字节在高位地址上）这种方式有时也被称为网络次序。下图显示了如何使用大端方式把长度不定的位编码打包成一个字节流。high和low表示字节的最高位和最低位。

为了在ARM上高效地实现打包工作，我们使用一个32位的寄存器作为缓冲器，以大端方式来保存四字节的数据。换句话说，就是把字节流中的字节0放在寄存器的最高8位。然后依次从高位到低位，每次把一个编码插入寄存器。（这里就是低位字节0放在最高位上）。

一旦寄存器满，就把32位的数据存放在存储器。注意对一个大端方式的存储系统，可以不加任何修改来存储一个字；而对小端方式的存储系统，就可以在存储一个字之前调整字节顺序。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1685521456668.png" alt="1685521456668" style="zoom:50%;" />

存放插入编码的寄存器称为bitbuffer，现在还需要一个寄存器bitsfree来记录bitbuffer中没有被使用的位的数量。换句话说，bitbuffer中包含了32-bitsfree个编码位，和bitfree个0位，下图所示，要把k位的编码插入bitbuffer，就要从bitsfree减去k，然后对编码左移bitsfree位后插入。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1685521934859.png" alt="1685521934859" style="zoom:50%;" />

同时也要注意边界对齐问题。由于字节流不保证字边界对齐，所以不能使用字访问来写入。为了能够采用字方式访问，可以退后到从上一个字对齐的地址开始。用32位的寄存器bitbufer填充前面的那些数据，这样就可以使用32位的字进行读/写了。

例6.24提供3个函数bitstream_write_start,bitstream_write_code,bitstream_write_flush。

由于这3个函数假定了寄存器在2个函数调用之间是受保护的，因此他们并不是ATPCS标准兼容的函数。实际上，这也不是什么问题，因为可以使用内联这些函数的代码，同时可以提高效率。

bitstream_write_start函数的功能是使位流指针bitstream的边界对齐，并初始化32位缓冲器bitbuffer。每次调用bitsream_write_code函数插入一个位长度codebits的值code。最后，bitsream_write_flush函数把剩余的字节写入位流来结束。

#### 6.7.3可变宽度编码的位流解包

解开一个可变宽度编码的位流要比打包困难得多，主要是因为通常不知道正在解的位流中的编码宽度。对Huffman编码的位流，必须根据一串位的顺序来得到编码的长度并计算出相应的编码。

这里将使用查表的方式来提高解包的速度。这种方法是取位流的后续N位，然后在2个表look_codebits[]和look_code[]中进行查找，每一个表的大小是2^N个项。如果这N位可以决定编码，那么从这两个表中就可以分别得到编码长度和编码值。如果这N位不能决定编码，那么表格look_codebits将会返回一个退出值0xff，表示这种情况是例外的。

在一个Huffman编码序列中，使用频率高的编码长度较短，使用频率低的编码长度较长。因此，可以使用查表的方法快速解码使用频率高的编码。在下面例子中，设N=8，表的大小为256项。

例6.25提供3个函数来完成对一个大端的位流进行解包。

同例6.24，这几个函数不符合ATPCS标准，一般需要使用内联函数。函数bitstream_read_start初始化程序，开始对位于字节地址bitsream的位流进行解码。每次调用函数bitsream_read_code，就在寄存器code中返回下一个编码。这个函数只对能从查找表中读到的短编码进行处理。长编码在标号long_code处被处理，但这个功能的实现依赖于正在解码的具体要求。

这段代码使用了一个寄存器bitbuffer，包含了从最高符号位开始的N+bitsleft个编码位。

这里的位操作不学了。

##### 小结 位操作

- ARM可以使用逻辑操作和桶形移位器进行高效地对位流进行打包和解包操作。
- 可以使用一个32位的寄存器作为位缓冲器来高效地访问位流，再使用一个寄存器来保存位缓冲器中有效位的数目。
- 为了高效地对位流进行解码，使用查表方法来扫描位流中的后续N位。通过查表可以对长度小于或等于N位的位流直接返回编码，或者对长编码返回一个退出值。

### 6.8高效的switch

一条switch或多路分支语句表示在多个不同的动作之间进行选择。在这里假定这些不同的动作依赖于一个变量x。对不同的x值，需要执行不同的动作。本节将讨论对不同类型的x，如何用汇编语言高效地实现switch结构。

#### 6.8.1在范围0<=x<N的switch

这个例子中C函数ref_switch根据不同的x值执行了不同的操作。这里只关心x的值在范围0<=x<8。用ARM汇编来实现这种结构，有两种有效的方法。第一种方法是使用一个函数地址的表格，通过x的值从表格中索引并装载pc。

例6.26switch_absolute代码**使用一个内联的函数指针表格实现switch结构**。

```assembly
x RN 0
switch_absolute
	CMP x,#8
	LDRLT pc,[pc,x,LSL #2];如果r0小于8的话，pc = *(pc + r0<<2)，这里就是平移一个32位变量的地址，其实就是一个32位的函数地址，说白了就是选择将哪一个送入函数地址送入pc中，这里我糊涂了
	B method_d
	DCD method_0;DCD表示预备出32位的存储空间
	DCD method_1
	DCD method_2
	DCD method_3
	DCD method_4
	DCD method_5
	DCD method_5
	DCD method_6
	DCD method_7
```

由于pc寄存器是**流水化操作**的（我不懂流水化操作），所以这个程序可以正确执行。当ARM执行LDR指令时，pc指向字method_0。

上面的这种方法执行速度很快，但是有一个缺点：由于存储的是函数的绝对地址，这样代码就不是位置无关的。位置无关的代码通常是模块化的，并在运行时才被装入系统。下面的例子将介绍如何解决这个问题。

例6.27这里的代码switch_relative与上面的switch_absolute相比，执行速度相对慢一点。但是这段代码是位置无关的。

```assembly
switch_relative
	CMP x,#8
	ADDLT pc,pc,x,LSL #2;pc = pc+x<<2;存储的是函数地址的地址
	B method_d
	B method_0
	B method_1
	B method_2
	B method_3
	B method_4
	B method_5
	B method_6
	B method_7
```

还有最后一个优化可以做。如果功能函数比较短，那么就可以直接使用内嵌指令来代替分支指令。

例6.28假定每一个跳转功能都由4条指令来实现。那么就可以用下面的代码：

```assembly
CMP x,#8
ADDLT pc,pc,x,LSL #4
B method_d
Method_0;直接把函数实现拿出来，不再使用DCD预留函数地址
;
Method_1
```

#### 6.8.2基于通用变量x的switch

现在假定x不是像6.8.1小节中那样在0到一个较小范围内，那么如何才能在不轮流测试每种可能的x值的情况下，高效地实现switch结构。

在这种情况下，可以使用一种非常有用的技术，即散列hashing函数。散列函数可将任何函数y = f(x)中我们感兴趣的值映射到一个连续的范围0<=y<N，这样，可以把基于x的switch，替换为基于y = f(x)。如果出现冲突，就是如果2个x映射到同一个y，那么也会出现问题。这种情况下，就须使用额外的代码来测试可能导致冲突的所有可能的x的值。但是对我们这里的目的，一个好的散列函数应该是很容易计算得到的。

为了执行这种switch，我们引入散列函数，并对散列值y使用6.8.1小节中优化过的switch代码。在2个x映射到同一个散列值y的地方，需要执行一个显式的测试；但对于一个好的散列函数，这种测试应该是罕见的。

例6.29假定对8种可能的k，当x=2^k时，要调用method_k。换句话说，我们希望switch发生在x值等于2的幂时，对于其他的x值，秩序调用一个默认的method_d函数。需要找一个2的幂减一的乘积形式的散列函数。尝试不同的乘数。

下面的汇编代码switch_hash使用这个散列函数执行这个switch。注意其他不是2的幂的值将对应相同的散列值。这样switch语句的各种情况就转化成了一个简单的可以明确测试的2的幂的情况。如果x不是2的幂，那么就调用默认函数method_d。

```assembly
x RN 0
hash RN 1
switch_hash
	RSB hash,x,x,LSL #4
	RSB hash,hash,hash,LSL #5
	AND hash,hash,#7<<9
	ADD pc,pc,hash,LSR #6
	NOP
	TEQ x,#0x01;这里的EQ并不是条件执行
	BEQ method_0
	TEQ x,#0x02
	BEQ method_1
	TEQ x,#0x40
	BEQ method_6
	TEQ x,#0x04
	BEQ method_2
	TEQ x,#0x20
	BEQ method_5
	TEQ x,#0x10
	BEQ method_4
	TEQ x,#0x08
	BEQ method_3
	B method_d
```

小结 高效的switch

- 对于N值比较小的情况，应确保switch的判断值x在范围0<=x<N；也可以使用一个散列函数来达到这个目的。
- 使用switch判断值来索引包含跳转函数指针的表格，或者跳转到有规则间隔的短代码段。第二种方法是位置无关的，而第一种不是。

### 6.9边界不对齐数据的处理

如果load或store指令使用的地址不是传输数据宽度的倍数，那么就称为边界不对齐的数据访问。为了使代码对于不同的ARM体系结构和实现有良好的可移植性，应避免边界不对齐的数据访问。5.9节介绍了用C实现对边界不对齐数据访问的解决方法。本节将讨论如何用汇编代码来处理边界不对齐的数据访问。

最简单的方法是使用一次只传送一字节数据的字节装载和存储。对于任何非速度敏感的访问，这是一种值得推荐的方法。下面的例子显示了如何使用这种方法来访问字变量。

例6.30显示使用边界不对齐的地址p来读写一个32位字。

使用了3个临时寄存器t0,t1和t2来避免流水线互锁。所有边界不对齐的字操作，在ARM9TDMI上要占用7个周期。

注意：对存储格式分别为大端和小端的32位数的操作要使用不同的函数处理。

```assembly
load_32_little
	LDRB x,[p]
	LDRB t0,[p,#1]
	LDRB t1,[p,#2]
	LDRB t2,[p,#3]
	ORR x,x,t0,LSL #8
	ORR x,x,t1,LSL #16
	ORR r0,x,t2,LSL #24
	MOV pc,lr
```

这里就是读取32位中的4个字节，然后按照大小端各自的字节序放入地址中。

如果对每次访问要达到比7个周期更好的性能，那么就要编写以上程序的几个不同的变体，每个变体处理不同的地址边界情况。这样对边界不对齐数据的访问操作可以减少3个周期：1条字装载和2条算术指令。

例6.31显示对于起始地址边界可能不对齐的字数据，生成N个字的校验和。这段代码是针对小端存储系统来编写的。注意如何使用汇编器保留字MACRO来生成四段程序。

小结 边界不对齐数据的处理

- 如果程序的性能不成问题，那么可使用多字节装载和存储来访问边界不对齐的数据。这种方法可以访问给定字节排列方法的数据，而不管指针对齐和存储器系统的字节排列方式。
- 如果对程序的性能要求比较高，那么可以使用几段程序，对每一种不同的边界情况使用不同的程序段。可以使用汇编器保留字MACRO来自动生成这些程序段。

### 6.10总结

在一个应用程序中，要实现最好的性功能，就需要编写优化的汇编程序。不过，只有对性能影响最大的关键程序才值得进行优化。可以使用性能分析器或者指令周期计数工具，找到这些敏感的关键程序段。

本章讨论的例子和使用的技术都是针对ARM汇编的。下面是一些关键的思想：

- 对代码进行合理的调整，这样就可以避免处理器流水线互锁或中止。
- 把尽可能多的数据存放在14个通用寄存器里，有时甚至应该把几个数据打包放入一个寄存器中。应避免把内层循环的变量放到堆栈中。
- 对于较小的if语句，使用条件数据处理操作比条件分支更好。
- 使用减计数到零的循环结构和循环展开方法，可以获得最高的循环执行效率。
- 对于打包和解包位流数据，使用32位的寄存器缓冲器可以提高效率，并可减小存储器数据带宽。
- 使用分支表格和散列函数来高效地实现switch语句。
- 为了高效地处理边界不对齐数据，可以使用多个程序段。针对输入和输出数组的特定边界情况，有多个不同程序段，并分别进行优化。运行时在其中选择一个程序段来执行。

## 第九章异常和中断处理

- 异常处理
- 中断
- 中断处理方法
- 总结

异常和中断处理是嵌入式系统的重要核心部分。它们负责处理错误、中断和其他由外部系统触发的事件。高效的异常处理能够大大改善系统的性能；同时，确定一个好的处理方法的过程，也是复杂，充满挑战而有乐趣的。

本章将介绍异常处理的理论与实践，特别是ARM处理器对中断的处理。ARM处理器有7种可以使正常指令顺序中止执行的异常情况：数据中止(abt)、快速中断请求(fiq)、中断请求(iq)、预取指中止、软件中断(svc)、复位（svc）以及未定义指令。（und）

本章分为三个主要部分：

- 异常处理，包括ARM处理器处理异常的一些特定细节；
- 中断，ARM把中断定义为一类特殊的异常，本节讨论了中断请求的使用，并介绍了一些有关中断处理的常用术语、特征和机制；
- 中断处理方法，最后一节提供了一整套中断处理方法，包括对应每种方法的实现例子。

### 9.1异常处理

异常是需要中止指令正常执行的任何情形，比如ARM内核产生复位，取指或存储器访问失败，遇到未定义指令，执行了软件中断指令，或者出现了一个外部中断等。异常处理就是处理这些异常情况的方法。

大多数异常都对应一个软件的异常处理程序，一个在异常发生时执行的软件程序。例如：一个数据中止异常就有一个数据中止处理程序。这个处理程序首先确定异常产生的原因，然后为该异常提供特定的服务。服务可以发生在处理程序内部，也可以跳转到一个专门的服务程序。复位异常是一个特例，他用来初始化一个嵌入式系统。

本节将介绍一下的异常处理主题：

- ARM处理器模式以及异常；
- 向量表；
- 异常的优先级；
- 链接寄存器偏移。

#### 9.1.1ARM处理器模式及异常

下表列出了ARM处理器的各种异常。每种异常都导致内核进入一种特定的模式。此外，可以通过编程改变cpsr，进入任何ARM处理器模式。用户和系统模式是仅有的可不通过相应异常进入的2种模式。换句话说，要进入这2种模式，必须修改cpsr。

当一个异常导致模式的改变时，内核自动地：

- 把cpsr保存到相应异常模式下的spsr；
- 把pc保存到相应异常模式下的lr；
- 设置cpsr为相应异常模式；
- 设置pc为相应异常处理程序的入口地址。

| 异常                 | 模式      | 主要目的                 |
| -------------------- | --------- | ------------------------ |
| 快速中断请求         | FIQ       | 快速中断请求处理         |
| 中断请求             | IRQ       | 中断请求处理             |
| SWI和复位            | SVC       | 操作系统的受保护模式     |
| 预取指中止和数据中止 | abort     | 虚存和存储器保护处理     |
| 未定义指令           | undefined | **软件模拟硬件协处理器** |

注意：当一个异常发生时，ARM处理器总是切换到ARM状态。这里的将pc设置为该中断入口地址是通过中断号传入计算出偏移然后加上向量表基地址得到的。

#### 9.1.2向量表

异常发生时，ARM内核跳转地址组成的表。这些地址通常包含以下形式的跳转指令。（向量表就是存储一系列指令的地址）

- B-这条分支指令实现了相对于pc的分支跳转。
- LDR pc,[pc,#offset]-这条寄存器装载指令把处理程序的入口地址从存储器装载到pc。该地址是一个32位的绝对地址，它存储在向量表附近。由于有额外的存储器访问，装载这4字节的绝对地址会使分支跳转到特定处理程序稍有延迟。不过，可以用这种方法，跳转到存储空间内的任意地址。
- LDR pc,[pc,#-0xff0]-这条寄存器装载指令把一个特殊的中断服务程序地址从地址0xfffff030装载到pc。只有当向量中断控制器存在时VIC PL190，才能使用这条特殊的指令。（向量表和控制器是同种定位的东西）
- MOV pc,#immediate-这条move指令把一个立即数复制到pc。他可跨越全部的地址空间，但要注意收到地址对齐问题的限制。这个地址必须是一个由8位立即数循环右移偶数次得到的。（大小端的时候用到了补位）

也可以在向量表中使用其他类型的指令。例如FIQ处理程序可以从地址偏移+0x1c处开始，这样FIQ处理程序就可以不用跳转，立即从FIQ向量地址处开始执行，因为它位于向量表的最后。跳转指令使pc跳转到一个特定地址，以便处理某个特定的异常。

下表列出了每种异常所对应的模式和向量表偏移量。

| 异常                                                         | 模式 | 向量表偏移 |
| ------------------------------------------------------------ | ---- | ---------- |
| 复位                                                         | SVC  | +0x00      |
| 未定义指令                                                   | UND  | +0x04      |
| 软件中断(SWI)(因为会根据SWI指令计算出软中断号，应该是先跳转到向量表偏移地址处执行SWI处理程序，在这里保存上下文跳转到软中断号对应的具体处理程序) | SVC  | +0x08      |
| 预取指中止                                                   | ABT  | +0x0c      |
| 数据中止                                                     | ABT  | +0x10      |
| 未分配                                                       | -    | +0x14      |
| IRQ                                                          | IRQ  | +0x18      |
| FIQ                                                          | FIQ  | +0x1c      |

例9.1下图给出了一个典型的向量表。未定义指令的入口地址是一条跳转到未定义处理程序的指令。其他向量使用指令LDR装载pc，以实现间接地址跳转。

注意：FIQ处理程序也使用指令LDR把地址装载到pc，而并没有利用它特殊位置（向量表最后一个）的好处，处理程序的入口可以直接放在FIQ向量入口地址处。

#### 9.1.3异常优先级

异常可以同时发生，因此处理器必须采用一种基于优先级的机制。下表列出了ARM处理器的各种异常及其对应的优先级。例如，复位异常的优先级最高，处理器上电时发生复位异常。所以，当产生复位时，他将优先于其他异常得到处理。同样，当一个数据中止发生时，他将优先于除复位异常外的其他所有异常。优先级最低的2种异常是：软件中断和未定义指令异常。可以通过设置cpsr中的1位或F位来禁止某些异常。

每一种异常将按照设置的优先级得到处理。下面从最高优先级异常开始，逐一介绍这些异常是如何被处理的。

复位异常是优先级最高的异常，一旦复位信号产生，总是会发生复位异常。复位异常处理程序对系统进行初始化，包括配置存储器和cache。外部中断源必须在IRQ或FIQ中断允许之前初始化，以避免在还没有设置好相应的处理程序前产生中断。复位处理程序还要为所有处理器模式设置堆栈指针。

在执行复位处理程序的开头几句指令时，假设不会有别的异常或中断发生。编程时应避免SWI、未定义指令及存储器访问导致的中止，即处理程序应仔细实现，以避免其他异常的再次触发。

数据中止异常发生在存储控制器或MMU指示**访问了无效的存储器地址**时（例如对于给定的一个地址，没有对应的物理存储器存在），或者当前代码在没有正确的访问权限时，试图读/写存储器。由于没有禁止FIQ异常，在一个数据中止处理程序中，可以发生FIQ异常。当FIQ服务完成后，控制权交还给数据中止处理程序。

| 异常         | 优先级 | I位  | F位  |
| ------------ | ------ | ---- | ---- |
| 复位         | 1      | 1    | 1    |
| 数据中止     | 2      | 1    | -    |
| 快速中断请求 | 3      | 1    | 1    |
| 中断请求     | 4      | 1    | -    |
| 预取指中止   | 5      | 1    | -    |
| 软件中断     | 6      | 1    | -    |
| 未定义指令   | 7      | 1    | -    |

快速中断请求FIQ异常发生在一个外部设备把内核的FIQ线置为nFIQ时。FIQ异常是优先级最高的中断。内核在进入FIQ处理程序时，把FIQ和IRQ都禁止了，因此任何外部中断源都不能再次中断处理器，除非在软件中重新允许了IRQ和FIQ。应该知悉设计FIQ处理程序，以便高效地为异常处理服务。

中断请求IRQ异常发生在一个外部设备把内核的IRQ线设置为nIRQ时。IRQ异常是第二优先级的中断。FIQ异常和数据中止异常都没有发生时，IRQ处理程序才能够进入。在进入IRQ处理程序时，内核禁止IRQ异常，直到当前中断源被清除。

预取指中止异常即**试图取指令而导致存储器访问失败**的情形。在流水线中，如果某条指令的执行阶段没有优先级更高的异常出现，将发生预取指中止异常。在进入相应的处理程序时，内核禁止IRQ异常，而保持FIQ不变。如果允许了FIQ，并且发生了一个FIQ异常，则它可在处理预取指中止过程中得到响应。

软件中断SWI异常发生在执行SWI指令，且没有更高优先级的异常标志置位的情况下。在进入相应处理程序时，cpsr将被设置成管理模式。如果系统使用嵌套SWI调用，则必须在跳转到嵌套的SWI之前，保存链接寄存器r14和spsr的值，以免其被破坏。

当一条不属于ARM或Thumb指令集的指令到达流水线的执行阶段时，若此时没有其他异常发生，就会产生未定义指令异常。ARM处理器会询问协处理器，看它能否将其当作一条协处理器指令来处理。由于协处理器在流水线之后，所以指令确认可以在内核的执行阶段进行。如果这条指令不属于任何一个协处理器，则会产生未定义指令异常。

SWI和未定义指令异常享有相同的优先级，因此不能同时发生。换句话说，正在执行的指令不可能既是一条SWI指令，又是一条未定义指令。

#### 9.1.4链接寄存器偏移

当一个异常发生时，连接寄存器就设置成基于当前pc值的一个特定地址。例如，当发生一个IRQ异常时链接寄存器lr指向最后执行的指令地址加上8。应确保异常处理程序不会破坏lr，因为lr保存的是异常处理程序的返回地址。只有在**当前指令执行完毕**后，才**进入IRQ异常处理**，所以返回地址应指向下一条指令，即(lr-4)处。下表提供了一组对应不同异常的有用地址。（这段话提的偏移没看懂）

| 异常       | 地址 | 用法                             |
| ---------- | ---- | -------------------------------- |
| 复位       | -    | 复位没有定义lr                   |
| 数据中止   | lr-8 | 指向导致数据中止异常的那条指令   |
| FIQ        | lr-4 | FIQ处理程序的返回地址            |
| IRQ        | lr-4 | IRQ处理程序的返回地址            |
| 预取指中止 | lr-4 | 指向导致预取指中止异常的那条指令 |
| SWI        | lr   | 指向SWI指令的下一条指令          |
| 未定义指令 | lr   | 指向未定义指令的下一条指令       |

上面的偏移没看懂。接下来的三个例子显示了从IRQ或FIQ异常处理程序返回的一种典型方法。

例9.2说明使用SUBS指令从IRQ和FIQ处理程序返回的一种典型方法。

```assembly
handler
	SUBS pc,r14,#4;pc = r14 - 4
```

因为在SUB指令尾部有一个S，并且pc是目的寄存器，所以cpsr将自动从spsr寄存器中恢复。（这里的意思是会自动更新cpsr顺便恢复回原来的处理器模式）

例9.3说明另一种方法-在处理程序开头处从链接寄存器lr减去偏移量。

```assembly
handler
	SUB r14,r14,#4
	MOVS pc,r14
```

服务完成后的返回是通过把链接寄存器r14的值写入pc，同时从spsr寄存器中恢复cpsr来实现的。

例9.4使用中断堆栈来保存链接寄存器。

这种方法首先从链接寄存器减去一个偏移量，然后把它保存到中断堆栈里。

```assembly
handler
	SUB r14,r14,#4;
	STMFD r13!,{r0-r3,r14}
	...
	LDMFD r13!,{r0-r3,pc}^
```

为了返回到正常的执行，使用LDM指令来装载pc。指令里的符号“^”强迫cpsr从spsr寄存器中恢复。

### 9.2中断

ARM处理器有两种类型的中断。第一类是由外设引起的，即IRQ和FIQ。第二类是一条引起中断的特殊指令SWI指令。2种中断都会挂起正常的程序执行。

本节的重点将放在IRQ和FIQ中断上，包括下列要点：

- 分配中断；
- 中断延迟；
- IRQ和FIQ异常；
- 基本的中断堆栈设计及实现。

#### 9.2.1分配中断

系统设计时可决定哪些硬件外设可以产生哪种中断请求。这种决定可通过硬件、软件来实现，并依赖与所使用的嵌入式系统特性。

---

标准中断控制器和中断向量控制器是同种定位的东西，异常向量表就是用来存放每种异常处理程序的地址。

----

中断控制器用于连接多个外部中断到ARM两个中断请求之一。复杂的控制器可以通过编程来选择、决定一个外部中断源产生的是IRQ还是FIQ中断。

在分配中断时，系统设计者应采用一些标准的设计惯例。

- 软件中断通常被保留，用来调用特权操作系统例程。例如，可以使用SWI指令改变一个在用户模式下运行的程序到一个特权模式。关于SWI处理程序的例子。
- 中断请求IRQ通常分配给通用中断。例如，一个周期性的定时器中断用来强制进行上下文切换，这往往就是一个IRQ异常。IRQ异常的优先级比FIQ异常低，并且中断延迟也更长。（异常向量表中存放的是通用的处理程序，由那些处理程序决定具体执行哪一个处理程序）
- 每个快速中断请求FIQ通常为要求快速响应的单个中断源保留。例如，直接存储器访问DMA专门用来传送存储器内的数据块（DMA不会占用CPU的。。。），因此在一个嵌入式操作系统设计中，FIQ异常一般用在专用场合，而IRQ异常则更多地用于操作系统的通用操作。

#### 9.2.2中断延迟

在中断驱动的嵌入式系统中，对中断延迟时间要求很苛刻。中断延迟是指：从外部中断请求信号发出到取出对应的中断服务程序ISR的第一条指令，这期间的间隔时间。

中断延迟依赖于软件与硬件的组合。体系结构设计师必须平衡系统设计，使多个并发的中断源能够得到处理，同时最小化中断延迟。如果中断不能得到及时处理，则系统会显现出很慢的响应，甚至导致系统瘫痪。

软件处理程序有两种主要的方法来缩短中断延迟。

第一种方法是使用嵌套中断，它允许正在为一个中断服务时，再次响应其他中断。通过在某中断源得到服务后尽快重新允许中断，而不是等中断处理全部完成后再允许中断，可以使用这种方法。一旦嵌套的中断服务完成，控制权又回到前一个中断服务例程。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1685621371932.png" alt="1685621371932" style="zoom: 25%;" />

第二种方法是引入优先级。通过编程中断控制器，使其忽略与正在处理的中断同级或更低优先级的中断，因此只有高优先级的中断可以打断正在执行的中断服务。设定这种工作方式后，需要在每个中断处理程序中重新允许中断（进入每个中断处理程序时自动关中断，计组中优先级是因为会自动关闭比自己优先级低的中断），这样高级的中断处理程序才能执行，并将先前正在处理的较低级中断挂起。

处理器在高优先级中断来到之前，处理低优先级的中断，因而与低优先级中断相比，高优先级中断的平均中断延迟较短。所以通过加速完成对时间敏感的中断。

#### 9.2.3IRQ与FIQ异常

只有当cpsr中相应的中断屏蔽被清除时，才有可能发生IRQ与FIQ异常。ARM处理器在处理中断前，继续执行已经处于流水线执行阶段的指令。这是一个在设计具有确定性中断处理时的重要因素，因为有些指令在执行阶段需要多个周期来完成。

一个IRQ或FIQ异常会使得处理器硬件经过以下的一个标准流程（假设中断未被屏蔽）：

- 处理器切换到一个特定的中断请求模式，表明产生了中断；
- 前一个模式的cpsr被保存到新的中断请求模式的spsr；
- pc被保存到新的中断请求模式的lr；
- 关闭中断，在cpsr中禁止IRQ，这回立即阻止相同类型的中断请求被响应；
- 处理器跳转到向量表中一个特定的入口。

这个流程根据产生的中断类型不同而稍有变化。以下将对2种中断举例说明。例9.5说明了 一个IRQ异常发生时的情况；而例9.6说明了一个FIQ异常发生时的情况。

下图说明了处理器在用户模式时响应了IRQ异常的情况。处理器从状态1开始。pc跳转到向量表对应的irq处理程序的地址。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1685623728304.png" alt="1685623728304" style="zoom:25%;" />

当发生了IRQ后，处理器进入状态2。这一转换自动将IRQ位置1，关闭其他的IRQ异常。但是FIQ异常仍然是允许的，cpsr里的处理器模式位变成IRQ模式。用户模式的cpsr自动复制到spsr_irq。

发生中断时，寄存器r14_irq保存了pc的值。然后pc被置为向量表中IRQ的入口地址0x18。

在状态3中，软件处理程序开始执行，并且调用适当的中断服务程序来为中断源服务。完成以后，处理器模式转换成状态1中最初的用户模式。

（我不禁有个疑问，上不上操作系统，这里的步骤是否会发生变化，上操作系统之后，涉及到中断线的问题，难道是只在软件处理程序部分修改么）

例9.6，下图说明了一个FIQ异常的例子。

处理器也经历了与IRQ异常类似的过程，但与IRQ异常仅屏蔽其他的IRQ异常不同，处理器还屏蔽了其他的FIQ异常。这意味着进入状态3中的软件处理程序时，IRQ和FIQ两种中断都被禁止了。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1685624595098.png" alt="1685624595098" style="zoom:25%;" />

变换到FIQ模式意味着没有必要保存寄存器r8~r12，因为这些寄存器在FIQ模式下是自动备份保护的。这些寄存器可以用来保存诸如缓冲区指针或计数器之类的临时数据。这种特性使得FIQ对于处理单个中断源、高优先级、低延迟的中断是很理想的。

下表说明了如何允许IRQ和FIQ中断。这一过程使用了3条ARM指令。

| cpsr的值 | IRQ             | FIQ             |
| -------- | --------------- | --------------- |
| 之前     | nzcvqIFt_SVC    | nzcvqIFt_SVC    |
| 代码     | enable_irq      | enable_fiq      |
|          | MRS r1,cpsr     | MRS r1,cpsr     |
|          | BIC r1,r1,#0x80 | BIC r1,r1,#0x40 |
|          | MSR cpsr_c,r1   | MSR cpsr_c,r1   |
| 之后     | nzcvq_iFt_SVC   | nzcvq_Ift_SVC   |

第一条指令MRS把cpsr的内容复制到寄存器r1；第二条指令清除IRQ或FIQ的屏蔽位；第三条指令把更新过的寄存器r1的内容复制回cpsr，以允许中断请求。后缀_c表明被更新的位域是cpsr的控制域位[7:0]。

下表说明了禁止，也就是屏蔽中断请求的类似操作过程。

| cpsr的值 | IRQ             | FIQ             |
| -------- | --------------- | --------------- |
| 之前     | nzcvqift_SVC    | nzcvqift_SVC    |
| 代码     | disable_irq     | disable_fiq     |
|          | MRS r1,cpsr     | MRS r1,cpsr     |
|          | ORR r1,r1,#0x80 | ORR r1,r1,#0x40 |
|          | MSR cpsr_c ,r1  | MSR cpsr_c,r1   |
| 之后     | nzcvqIft_SVC    | nzcvqiFt_SVC    |

中断请求是允许还是禁止，只有在MSR指令已经完成了流水线的执行阶段后才确定，理解这一点是很重要的。在MSR指令完成执行前，中断仍可发生或者仍被屏蔽。

为了同时允许和禁止IRQ和FIQ异常，对BIC或ORR改动即可。

#### 9.2.4基本的中断堆栈设计与实现

异常处理程序广泛使用堆栈，每一种模式都有一个专门的寄存器保存堆栈指针。异常堆栈的设计取决于以下因素：（中断栈在内核中提到过，后来专门分配4KB作为堆栈的空间）

- 操作系统要求，每个操作系统对堆栈设计都有自己的要求；
- 目标硬件，目标硬件限制堆栈的实际空间大小和在存储器中的位置。

在堆栈设计时，需确定2点：

- 位置，决定了在存储器映射中，堆栈从何处开始。大多数基于ARM系统设计的堆栈是采用向下递减式的。栈顶位于存储器的高端地址。
- 堆栈大小，依赖于处理程序的类型-嵌套的还是非嵌套的。一个嵌套中断处理程序需要更多的存储器空间，因为堆栈将随中断嵌套的深度而增加。这也是内核不允许多层嵌套的原因。

一个好的堆栈设计必须避免堆栈溢出-堆栈超出了分配给的存储空间，这会导致系统不稳定。有一些软件技术可以确认堆栈是否溢出，并在发生存储空间遭到无法恢复的破坏前，采取措施来修复堆栈。2种主要的方法是：

1. 使用存储保护；
2. 在每个例程开始处调用堆栈检查函数。

IRQ模式堆栈必须在中断允许前设置好，通常是在系统初始化代码中。在一个简单的嵌入式系统中，确认堆栈的大小是很重要的，因为堆栈大小在固件启动的初始阶段是被预留的。

下图显示了在线性 空间中的2种典型的存储安排方式。第一种方式A，说明了一个传统的堆栈安排，中断的堆栈位于代码段之下。第二种方式B，中断堆栈在用户堆栈 之上，位于存储器的顶端 。B优于A之处是，B在堆栈溢出时不会破坏向量表，因此系统在确认溢出后，还有机会纠正自己的错误。（堆栈溢出是通过异常处理程序实现纠正的，而异常处理程序地址在向量表中）

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1685667985345.png" alt="1685667985345" style="zoom:25%;" />

----

之前没有合计过堆栈的位置排放，或者说没有想过这个位置是可以修改的，堆栈是动态分配空间的，就存在堆栈溢出的可能，需要避免向量表受到影响。但是堆栈溢出在向量表中好像没有专门的异常来维护。可能是软件中断之中

----

例9.7**每一种处理器模式都要建立一个堆栈，这是在处理器每次复位时完成**的。下图说明了使用上述方法A的实现 ，为了有助于存储器安排，先声明一些存储区域名称的绝对地址映射定义。（这个操作uboot中也实现过，裸机应该是bootloader实现）

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1685668473604.png" alt="1685668473604" style="zoom:25%;" />

 例如，用户模式堆栈 用标号USR_Stack表示，对应地址0x20000；管理模式堆栈对应的地址是IRQ堆栈下面128字节处。（这里显示了三种模式的堆栈）

```assembly
USER_Stack EQU 0x20000
IRQ_Stack EQU 0x8000
SVC_Stack EQU IRQ_Stack-128
```

裸机中是由启动文件记录了堆栈的地址以及向量表。为了方便进行不同处理器模式的切换，另外声明了一组标号定义，使得每一种模式对应于一个特定的位格式。这些标号可以用来设置cpsr的新模式。

```assembly
Usr32md EQU 0x10;EQU是等价替换，这里是复制给cpsr的内容
FIQ32md EQU 0x11
IRQ32md EQU 0x12
SVC32md EQU 0x13
Abt32md EQU 0x17
Und32md EQU 0x1b
Sys32md EQU 0x1f
```

出于安全，需要声明一个定义来禁止cpsr中的IRQ和FIQ异常；

```assembly
NoInt EQU 0xc0;禁止中断就是设置cpsr中的[8:7]两位
```

NoInt通过设置2个屏蔽位为1来禁止这两种中断。

初始化代码一开始就设置各个处理器模式的堆栈寄存器。当发生模式改变时，堆栈寄存器r13是受备份保护的寄存器之一。（r13在不同的处理器模式下指向不同的模式堆栈）代码首先初始化IRQ堆栈。出于安全考虑，最好在NoInt与新模式之间，使用逻辑位或OR来确保中断是关闭的。

必须为每种模式设置堆栈。这里有一个例子，说明了处理器内核复位后是如何设置三种不同的堆栈的。

注意：这是一个基本范例，没有实现中止、FIQ以及未定义指令异常模式的堆栈。如果需要，可以使用与之类似的代码来实现。

- 管理模式堆栈，处理器内核从管理模式开始运行，因此SVC堆栈的建立包括把指向SVC_NewStack的地址装载到寄存器r13_svc。对于本例，这个值为SVC_Stack。

  ```assembly
  LDR r13,SVC_NewStack ;将SVC堆栈地址送入r13_svc堆栈指针中
  ...
  SVC_NewStack
  	DCD SVC_Stack;分配存储单元并用给定数据初始化，这是分配一个32位空间，用堆栈地址初始化，实际上就是把SVC_Stack送入r13中
  ```

- IRQ模式堆栈，为了建立IRQ堆栈，处理器内核必须切换到IRQ模式。在寄存器r2存放cpsr的位格式，然后将其复制到cpsr，就可以使得处理器进入IRQ模式。这个操作使得寄存器r13_irq立即可用，并被赋值为IRQ_Stack

  ```assembly
  MOV r2,#NoInt|IRQ32md
  MSR cpsr_c,r2
  LDR r13,IRQ_NewStack
  ...
  IRQ_NewStack
  	DCD IRQ_Stack
  ```

- 用户模式堆栈，通常是最后设置的，因为当处理器处于用户模式时，没有直接修改cpsr的方法，由于系统模式与用户模式共享寄存器，所以可以强制处理器进入系统模式来设置用户模式堆栈。（很合理）

  ```assembly
  MOV r2,#Sys32md
  MSR cpsr_c,r2
  LDR r13,USR_NewStack;因为系统模式和用户模式共享寄存器，所以也共享堆栈
  ...
  USR_NewStack
  	DCD USR_Stack
  ```

每种模式使用独立的堆栈而不是使用统一的堆栈处理，这样做的一个主要优点是：可以调试一个有错误的任务，并且与系统的其他部分隔离。

### 9.3中断处理方法

最后这一节将介绍几种不同的中断处理方法，包括从简单的非嵌套中断处理，到较复杂的分组优先级中断处理。每种方法都是以综述结合实例的形式给出的。

这里讨论的中断处理方法包括：

- 非嵌套中断处理，顺序地处理和服务各个中断，这是最简单的中断处理程序；
- 嵌套中断处理，处理多个没有分配优先级的中断；
- 可重入中断处理，处理多个可以有优先级的中断；
- 优先级简单中断处理，处理有优先级的中断；
- 优先级标准中断处理，相对于低优先级中断，能在更短时间内处理高优先级中断；
- 优先级直接中断处理，能在更短时间内处理高优先级中断，并直接跳转到一个专用的服务例程；
- 优先级分组中断处理，一种中断处理方法，把中断划分到不同的优先级组中；（这个类似于NVIC）
- 基于VICPL190的中断服务例程，说明了向量中断控制器VIC是如何改变中断服务例程设计的。

#### 9.3.1非嵌套中断处理

最简单的中断处理是非嵌套的：只有当控制权回到被中断的任务或过程时，才允许再次响应中断。由于一个非嵌套的中断处理程序在一个时段内只能为一个中断服务，所以这种形式的中断处理程序不适合需要为多个不同优先级中断服务的复杂嵌入式系统。

下图显示了在一个实现了简单的非嵌套中断处理系统中，发生一次中断的各种阶段：

1. 禁止中断
2. 保护上下文
3. 中断处理程序
4. 中断服务程序
5. 恢复上下文
6. 允许中断：最后，为了从中断处理程序返回，使用spsr_irq的值恢复到cpsr。接着pc指向响应中断时的下一条指令。

例9.8，这个IRQ处理程序的例子假定初始化代码已经正确建立了IRQ堆栈。

```assembly
interrupt_handler
	SUB r14,r14,#4
	STMFD r13!,{r0-r3,r12,r14}
	<中断服务程序>
	LDMFD r13!,{r0-r3,r12,pc}^
```

第一条指令设置链接寄存器r14_irq的值为返回到被中断任务或过程的正确地址。由于流水线的特性，在每一个IRQ处理程序的入口，链接寄存器指向的地址比返回地址多4字节，因此处理程序必须从链接寄存器中减去4。链接寄存器的值保存在堆栈里，为了返回被中断的任务，从堆栈恢复链接寄存器的内容，并将其复制到pc。

注意：由于ATPCS调用规则，寄存器r0~r3及寄存器r12也被保存。这就允许一个遵循ATPCS的子程序在处理程序中被调用。

STMFD指令通过把寄存器组的一个子集放置到堆栈 ，来保护上下文。由于执行一句STMFD或LDMFD指令的时间与参与的寄存器数目成正比，为了缩短中断延迟，只保存了尽可能少的寄存器。被保存到堆栈的寄存器由寄存器r13_irq来指向。

如果在系统中使用的是高级语言，则理解编译器的过程调用规则是很重要的，因为这不仅会影响到被保存的寄存器，也会影响到被保存到堆栈的顺序。例如，在一个子程序调用中，ARM编译器保存了寄存器r4~r11，因此没有必要再次保存，除非在中断处理程序中会用到他们。如果没有调用C例程，则没有必要保存全部的寄存器。只有当寄存器已被保存 到中断堆栈后，调用一个C函数才是安全的。

在一个非嵌套的中断处理程序中，没必要保存spsr，因为他不会被任何顺序的中断所破坏。

在中断处理程序的最后，指令LDMFD将恢复上下文，并从中断处理程序返回。LDMFD指令末尾的^意思是cpsr的值将从spsr中得到恢复，这**只有在pc同时也装载的情况下才有效**。如果pc没有被装载，那么^只恢复用户模式的备份寄存器组。

在这里，中断处理程序完成了所有的事务，并且直接返回到应用程序。

一旦进入中断处理程序，保护上下文以后，处理程序就必须确定中断源。下面给出一个简单的例子，说明如何确定中断源。IRQStatus是中断状态寄存器的地址。如果没有确定中断源，则控制权可以移交给另一个处理程序。本例中，将控制权交给了debug monitor。当然也可以忽略掉这个中断。

```assembly
Interrupt_handler
	SUB r14,r14,#4
	STMFD sp!,{r0-r3,r12,r14}
	LDR r0, =IRQStatus
	LDR r0,[r0]
	TST r0,#0x0080;如果中断源是定时器
	BNE timer_isr;跳转到定时器定时器的ISR
	TST r0,#0x0001;如果按下按钮
	BNE button_isr;调用按钮ISR
	LDMFD sp!,{r0-r3,r12,r14}
	LDR pc,=debug_monitor;否则跳转到debug monitor
```

在代码中有两个ISR:timer_isr和button_isr。他们与IRQStatus指向的中断状态寄存器中的特定位相对应，分别为0x0080和0x0001。

小结 简单的非嵌套中断处理

- 依次处理各个中断；
- 中断延迟较大，不能在位一个中断服务的同时，处理新的中断；
- 优点：相对来说易于实现和调试；
- 缺点：不能用于处理有多个优先级中断的复杂嵌入式系统。

#### 9.3.2嵌套中断处理

嵌套中断处理考虑了在当前被调用的中断处理程序执行过程中，发生另一个中断的情形。在处理程序完成当前中断的服务前重新允许中断，可以实现中断嵌套。

对一个实时系统，这一特性增加了系统的复杂性，但也改进了系统的性能。复杂性的增加会引入一些非常细微的时序问题，这可能会导致系统失败，而且这些细微的问题非常难以解决。在设计一个嵌套中断方法时，应当非常仔细，以免出现这些问题。通过保护从中断中恢复的上下文，可以实现这一点，这些下一个中断就不会填满堆栈（导致堆栈溢出）或破坏任何寄存器的值。

任何一个**中断处理程序**的首要目标，是**对中断的及时响应**，所以中断处理程序不会等待任何异步的事件，也不会迫使其等待中断处理；第二个目标，是在为各中断提供服务时，**不会延误常规同步代码的执行**。

复杂性的增加，意味着设计者需要在效率和安全方面做出折中。可以采用防御性的编程风格-假定会发生问题并采取相应的措施。处理程序必须检查堆栈，并保护可能会被破坏的寄存器。

下面显示了一个嵌套的中断处理过程。可以看出这个处理过程比9.3.1小节介绍的简单非嵌套中断处理过程要复杂的多。

嵌套的中断处理程序入口处代码与简单的非嵌套中断处理程序类似，不同之处在于，在退出时，处理程序要测试被ISR更新过的一个标志。这个标志表明，是否需要做进一步的处理，如果不要求更多的处理，那么这个中断服务例程就完成了，处理程序也可以退出；如果需要进一步处理，处理程序可能要采取若干措施：重新允许中断，并/或执行一次上下文切换。

重新允许中断包括把IRQ模式切换成SVC或系统模式。在IRQ模式下，不能简单的重新允许中断，因为这可能会**导致链接寄存器r14_irq遭到破坏**（本来保存的是被中断的指令地址，现在嵌套中断返回后是上一个中断地址），特别是在执行完指令BL后即发生一个中断。这个问题将在9.3.3小节中详细讨论。

执行上下文切换包括复位IRQ堆栈，因为当IRQ堆栈中还有数据时，处理程序不会执行上下文切换。所有**保存在IRQ堆栈的寄存器必须转移到任务堆栈**，典型地是放在管理模式堆栈上。然后其余的寄存器也必须被保存到任务堆栈。在那里，他们会被转移到堆栈中一个称为**堆栈帧**的**保留存储块**上。（这里提到的是不是栈帧结构，应该不是，这是指定在管理模式堆栈中的一个保留存储块）

例9.9一个嵌套中断的处理程序范例，基于流程图。本小节的其余部分将详细介绍该处理程序及其各阶段的细节。

```assembly
Maskmd EQU 0x1f
SVC32md EQU 0x13
I_Bit EQU 0x80
FRAME_R0 EQU 0x00
FRAME_R1 EQU FRAME_R0+4
IRQ_Entry 
	SUB r14,r14,#4
	STMDB r13!,{r0-r3,r12,r14};保存上下文
	<服务中断>
	BL read_RescheduleFlag;去读取被ISR更新过的标志，更新条件标志域，然后返回
	CMP r0,#0;判断是否要进一步处理，这里就是识别到了高优先级中断的请求，不过这也不算打断中断服务的工作主体，只是没有恢复上下文而已
	LDMNEIA r13!,{r0-r3,r12,pc}^;如果不需要进一步处理，就恢复上下文
	MRS r2,spsr;复制spsr_irq，
	MOV r0,r13;复制r13_irq，这两行是为了保存中断处理程序的上下文，方便嵌套中断
	ADD r13,r13,#6 * 4;复位堆栈，这里不理解
	MRS r1,cpsr
	BIC r1,r1,#Maskmd，清除[5:0]处理器模式
	ORR r1,r1,#SVC32md，切换到SVC模式
	MSR cpsr_c,r1;赋值cpsr的控制域
	SUB r13,r13,#FRAME_SIZE - FRAME_R4;保留一部分空间，让sp向下移动，为什么保留这部分空间，难道这就是堆栈帧么
	STMIA r13,{r4-r11};此时上一个中断还没有恢复上下文就切换到SVC模式，然后保存上下文
	STR r2,[r13,#FRAME_PSR]
	STR r8,[r13,#FRAME_R12]
	STR r9,[r13,#FRAME_PC]
	STR r14,[r13,#FRAME_LR];保存lr，我看出来了，这里就是堆栈帧了，将寄存器保存到事先空出来的存储空间，如果只中断一次，lr寄存器不需要保存，但是现在第二次中断需要覆盖lr，所以要保存了
	<完成中断服务程序>
	LDMIA r13!,{r0-r12,r14};恢复上下文，这里恢复的是中断被中断的上下文
	MSR spsr_cxsf,r14;恢复spsr
	LDMIA r13!,{r14,pc}^;这里恢复的就是被中断的上下文
```

这个例子使用了一个堆栈帧结构。所有的寄存器，除了堆栈寄存器r13外，都被保存到这个帧里，这里，寄存器的顺序不是重要的；但FRAME_LR和FRAME_PC是例外，他们必须是这个帧里的最后的2个寄存器，因为程序要使用单一的指令来返回（这里的堆栈帧就是使用存储空间中的一部分来存放被中断的中断的上下文，因为此时IRQ模式的IRQ堆栈已经被使用了，所以只能存放到SVC模式下的堆栈中）：

```assembly
LDMIA r13!,{r14,pc}^
```

可能还有其他寄存器需要存放到堆栈帧里，这取决于使用的操作系统或应用程序：

- 当操作系统支持2种模式，用户模式和管理模式时，必须保存寄存器r13_usr和r14_usr；
- 当系统使用硬件浮点时，必须保存浮点寄存器。

在本例中声明了一些定义，这些定义使得不同的cpsr/spsr改变映射到一个特定的标号。

另外还声明了一组定义，定义了**各个帧寄存器的帧指针偏移量**。当重新允许中断，寄存器必须被保存到堆栈帧中时，这些定义是很有用的。在本例中，堆栈帧是保存在SVC堆栈中。

本例的处理程序入口也使用了与简单非嵌套中断处理程序相同的代码。首先修改链接寄存器r14，使其指向正确的返回地址；然后把上下文和链接寄存器r14保存到IRQ堆栈。

接下来中断服务程序就为中断提供服务。当服务完成或部分完成时，控制权又交还给处理程序。然后，处理程序调用一个称为read_RescheduleFlag的函数，该函数决定是否需要做进一步的处理。如果不需要更多的处理，就在寄存器r0中返回一个非零的值；否则返回零。

注意：这里没有给出read_RescheduleFlag函数的源代码，因为他的实现要看具体情况而定。（为啥我学内核的时候没有提到这部分，没有提到中断嵌套的具体实现）

接着测试寄存器r0的返回值，如果该寄存器不为0，则处理程序恢复上下文，并把控制权交还给被挂起的任务。

如果寄存器r0被设置为0，则表明需要做进一步的处理。第一步操作是保存spsr，即把spsr_irq的副本送到寄存器r2；然后，处理程序可以把spsr保存到堆栈帧。（spsr和lr寄存器是一样的，本身都是备份寄存器，现在需要保存两次，所以只能放到堆栈中了）

由寄存器r13_irq指向的IRQ堆栈地址被复制到寄存器r0，以备后用。下一步是复位IRQ堆栈，因为第二个中断依旧要使用IRQ堆栈。这里通过在栈顶加6 * 4字节实现的，**不理解为什么可以实现**

处理程序无须担心保存在IRQ堆栈里的数据会被另一个嵌套的中断所破坏，直到IRQ堆栈的数据被恢复后，才重新允许中断。

然后处理器切换到SVC模式，中断仍被禁止。cpsr被复制到寄存器r1，并被修改，使处理器模式为SVC。寄存器r1再被写回到cpsr，于是当前模式就变成了SVC模式。新cpsr的副本保留在寄存器r1中，以便后面使用。

再下一步，是以堆栈帧的尺寸，通过扩展堆栈来构建一个堆栈帧。寄存器r4~r11可以保存在堆栈帧中，这样可以释放足够的寄存器，以恢复仍由寄存器r0指向的IRQ堆栈中的其余寄存器。仅有未被保存到堆栈帧中的寄存器，是在IRQ处理程序入口处已被保存的寄存器。现在处理程序可以从IRQ堆栈中重新得到所有的数据，重新允许中断是安全的。

处理程序保存好重要的寄存器后，重新允许IRQ异常，并可以完成堆栈帧。接下来这个阶段可以处理中断服务的其余部分。把当前任务控制块的寄存器r13的当前值保存，并从新的任务控制块装载一个新的值到寄存器r13，就可以实现上下文切换。

最后，处理器可能返回到被中断的任务或处理程序；如果发生了上下文切换，则切换到另一个任务。（我好像明白了，因为cpu每次只能执行一个进程，所以每次进程上下文切换就是切换这些堆栈在内的现场。）

最后，处理器可能返回到被中断的任务或处理程序；如果发生了上下文切换，则切换到另一个任务。

小结 嵌套中断处理

- 处理没有分配优先级的多个中断；
- 中等或较高的中断延迟；
- 优点：在为一个中断服务完成前允许其他中断，以缩短中断延迟；
- 缺点：不处理中断的优先级，因此低优先级的中断会阻塞高优先级的中断。

#### 9.3.3可重入中断处理

可重入中断处理是处理多个中断的一种方法，这里，多个中断按优先级被排序、过滤筛选，这对于满足高优先级中断要求低延迟的需求是很重要的。这种类型的筛选是使用一般的嵌套中断处理无法做到的。

可重入中断处理程序与嵌套中断处理程序的基本区别是，在可重入中断处理程序中，更早地重新允许了中断，从而缩短了中断延迟。更早地重新允许中断会带来一些问题。

在可重入中断处理中的所有中断，必须是在ARM处理器的SVC、系统、未定义指令或中止模式中被服务。（这里是什么意思，剩下的usr/irq/fiq为啥不用）

如果在一个中断模式中重新允许了中断，并且这个中断例程使用BL调用了一个子程序，那么这个子程序的返回地址将被设置在寄存器r14_irq。这个地址随后会被另一个中断所破坏，因为寄存器r14_irq的值将被覆盖。为了避免这种情况，中断例程应切换到SVC或系统模式，那样，BL指令可以使用寄存器r14_svc来保存子程序的返回地址。（虽然每个模式下有各自的寄存器，但实际上还是那些寄存器，这里依旧是要保存到堆栈的）在通过cpsr重新允许中断前，中断源必须被禁止，这一般是通过设置中断控制器的某个寄存器来实现的。

如果在中断源未被禁止，相应处理尚未完成前，重新允许中断，那么中断处理将会立即再次发生，导致无限的中断或紊乱情况。

由于中断是在SVC模式下得到服务的，中断堆栈未被使用，所以IRQ堆栈寄存器r13可以用来**指向一个12字节的结构体**。这个结构体可以用于在中断入口处临时保存一些寄存器。在一个可重入中断处理中，中断控制器对中断的优先级排序很重要。

没有被优先级排序，则系统延迟性能会下降到与嵌套中断处理相同的水平。因为那样的话，低优先级中断能够抢占正在被服务的高优先级中断；同时，这也和导致在低优先级中断服务期间，高优先级中断得不到响应。

例9.10假设寄存器r13_irq已被设置为指向一个12字节的数据结构体，而不是指向标准的IRQ堆栈。IRQ_spsr等偏移量用来指向这个结构的数据项。像所有的中断处理程序一样，需要做一些标准的定义来修改寄存器cpsr和spsr。

```assembly
IRQ_Entry
	SUB r14,r14,#4;
	STR r14,[r13,#IRQ_R14];就是这里的偏移实际上是让r13指向不同的结构体成员，保存lr
	MRS r14,spsr
	STR r14,[r13,#IRQ_spsr];保存spsr
	STR r0,[r13,#IRQ_R0];保存r0
	MOV r0,r13;将数据结构体指针送给r0，因为r0属于未分组寄存器，可以在irq模式下使用
	MRS r14,cpsr
	BIC r14,r14,#Maskmd
	ORR r14,r14,#SVC32md;切换状态位SVC
	MSR cpsr_c,r14;进入SVC模式
	STR r14,[r13,#-8]!;保存spsr_svc
	LDR r14,[r0,#IRQ_R14];从结构体中拿出数据
	STR r14,[r13,#4];保存r14_irq
	LDR r14,[r0,#IRQ_spsr];
	LDR r14,[r0,#IRQ_R0]
	STMDB r13!,{r0-r3,r8,r12,r14};保存上下文
	LDR r14, =ic_Base;伪指令将中断控制器地址送入r14
	LDR r8,[r14,#IRQStatus];加载中断控制器中的中断状态
	STR r8,[r14,#IRQEnableClear];清除中断
	MRS r14,cpsr
	BIC r14,r14,#I_Bit;重新设置IRQ位
	MSR cpsr_c,r14;允许IRQ中断
	BL process_interrupt;调用ISR，执行中断服务程序
	LDR r14,=ic_base
	STR r8,[r14,#IRQEnableSet];中断状态变成可以中断
	BL read_RescheduleFlag;这个就是之前判断是否需要嵌套
	CMP r0,#0
	LDMNEIA r13!,{r0-r3,r8,r12,r14};装载上下文
	MSRNE spsr_cxsf,r14
	LDMNEIA r13!,{r14,pc}^
	LDMIA r13!,{r0-r3,r8};否则装载寄存器
	STMDB r13!,{r0-r11}
	BL continue_servicing
	LDMIA r13!,{r0-r12,r14}
	MSR spsr_cxsf,r14
	LDMIA r13!,{r14,pc}^
```

处理程序的开头部分包括一个普通的中断入口，计算返回地址。重要的是向由寄存器r13_irq指向的数据结构的各个域赋值。被记录下来的寄存器有r14_irq，spsr_irq和r0。

在切换到SVC模式时，寄存器r0用来为数据结构体传递指针，因为寄存器r0是不会被自动分组保护的。寄存器r13_irq不能用作此目的的原因是，它在SVC模式下不可见。

通过赋值寄存器r13_irq的值到r0来保存指向数据结构体的指针。

小结 可重入中断处理

- 处理多个优先级被排序的中断；
- 较低的中断延迟；
- 优点：根据优先级处理中断
- 缺点：变得更复杂

我并没有看到在哪里进行的中断优先级。下一节讲解

#### 9.3.4优先级简单中断处理

非嵌套与嵌套中断处理都以先来先服务的原则为终端提供服务。与之相比，有优先级的中断处理程序，将一个特定的中断源与优先级联系起来，优先级用来指示中断得到服务的次序。因此，一个高优先级的中断将比一个低优先级的中断优先得到服务，这在许多嵌入式系统中是必需的。（计组中提到过中断优先级是取决于中断控制器，由中断控制器决定）

进行优先级排序可以由硬件或软件来完成。对于硬件优先级处理，程序设计比较容易，因为中断控制器会提供当前需要服务的最高优先级的中断。这些系统在启动时要求更多的初始化代码，因为在系统正常运行前，必须构造中断和与之相联系的**优先级表**。对于软件优先级处理，也需要外部中断控制器的协助，这种中断控制器只提供一些最基本的功能，包括设置和清除屏蔽码，读中断状态和中断源。

本小节将介绍一种精选的软件优先级处理技术，因为它是一种通用的方法，不依赖某个特定的中断控制器。为了有助于描述这个优先级中断处理程序，而不涉及具体的处理器芯片，这里引入一个基于ARM标准中断控制器的虚构的中断控制器。这个控制器连接多个中断源，并根据中断源是否被允许来产生一个IRQ或FIQ虚拟信号。（中断优先级分为响应和处理，前者是硬件决定，后者是软件决定，这里的标准中断控制器是硬件）

例9.11，这个中断控制器有一个寄存器来保存原始的中断状态，被中断控制器屏蔽之前的中断信号状态。IRQEnable寄存器确定哪个中断是被处理器屏蔽的，这个寄存器只能用IRQEnableSet和IRQEnableClear来设置或清除。

```assembly
IRQ_Handler
	SUB r14,r14,#4;计算出返回地址
	STMFD r13!,{r14};将lr保存到堆栈
	MRS r14,spsr;复制spsr到r14
	STMFD r13!,{r10,r11,r12,r14};保护上下文
	LDR r14,=ic_Base
	MOV r11,#PRIORITY_3
	LDR r10,[r14,#IRQStatus];装载IRQ状态给r10
	TST r10,#BINARY_3
	MOVNE r11,#PRIORITY_3
	TST r10,#BINARY_2
	MOVNE r11,#PRIORITY_2
	TST r10,#BINARY_1
	MOVNE r11,#PRIORITY_1
	TST r10,#BINARY_0
	MOVNE r11,#PRIORITY_0
	LDR r12,[r14,#IRQEnable]
	ADR r10,priority_masks;屏蔽码地址
	LDR r10,[r10,r11,LSL #2]
	AND r12,r12,r10
	...
```

对于FIQ异常，大多数中断控制器还有一组相应的寄存器，甚至允许单独的中断源使用特定的信号来申请内核中断。因此，通过编程中断控制器，一个特定的中断源就可以产生一个IRQ或FIQ异常。

在存储空间中，寄存器位于从某个基地址开始的特定偏移量处。其中IRQEnable与IRQEnableSet都使用偏移量0x08。

在中断控制器中，每一位都与一个特定的中断源关联起来。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1685881976451.png" alt="1685881976451" style="zoom:25%;" />

PRIORITY_x定义了在本例中用到的4个中断源，并使其分别对应于不同的中断优先级。PRIORITY_0是优先级最高的中断，PRIORITY_3是优先级最低的中断。

BINARY_x为每种优先级提供了位格式。例如，对于一个PRIORITY_0的中断，其二进制位格式是0x00000004。对每个优先级来说，都有一个相应的屏蔽码，用来屏蔽优先级相同或者更低的中断。（这个就是计组中学的中断响应优先级的原理）

中断控制器的地址定义也列出来了。ic_Base是基地址，其余的定义都是以这个基地址开始的偏移量。

优先级中断处理程序从标准的入口开始，但起初只有IRQ链接寄存器被保存到IRQ堆栈里。

接下来处理程序得到spsr，并将其内容保存在寄存器r14_irq，释放一组寄存器，用来进行优先级排序使用。

处理程序需要获得中断控制器的状态，这是通过装载中断控制器的基地址到寄存器r14，并用ic_Base加偏移量IRQStatus把状态信息装载到寄存器r10来实现。

然后，处理程序需要通过测试状态信息来确定优先级最高的中断。如果一个特定的中断源与某个优先级匹配，那么在寄存器r11中设置这一优先级。这种方法把中断源与所有设置的优先级进行比较，从最低优先级开始，一直到最高优先级。

经历这一段代码后，寄存器r14_irq将保存中断控制器的基地址，寄存器r11将保存优先级最高的中断的位号。现在重要的是禁止低优先级和同级的中断，而仍然允许更高优先级的中断打断这一处理程序。

注意：这种处理放啊具有更好的时间确定性，因为花在查找最高优先级中断的时间总是一样的。

为了设置控制器中的中断屏蔽码，处理程序必须确定当前IRQ使能寄存器的内容，并且获得优先级屏蔽码表的起始地址。priority_masks定义在处理程序的最后。

寄存器r12现在保存的是IRQ使能寄存器的值，寄存器r10保存的是优先级表的起始地址。为了得到正确的屏蔽码，寄存器r11左移2位（使用桶形移位器LSL #2）。这使得地址乘以4并加到优先级表的起始地址上去。

寄存器r10包含了新的屏蔽码。下一步是使用这个屏蔽码来清除低优先级中断：先把这一屏蔽码和寄存器r12(IRQEnable寄存器的内容)进行二进制逻辑与，再把结果写到寄存器IRQEnableClear。现在通过清除cpsr中的i位来使能IRQ异常就安全了。

最后处理程序跳转到正常的服务例程，这是通过修改寄存器r11和pc来实现的。直接把服务例程的地址装载到pc，就使得处理程序跳转到正确的例程

跳转表紧挨着装载pc的指令。在操作pc的指令与跳转表之间有一个NOP指令。（这里的NOP指令指的是啥都不干，只占用一个指令周期）因为pc指向超前了2条指令。优先级屏蔽码表是按中断源对应的位排序的。

每个ISR使用相同的入口处理方法，例子给出的是timer1中服务程序。在上述中断入口处理之后，是具体的ISR，一旦ISR完成，中断源必须被复位，并且把控制权交还给被中断的任务。

在中断可以重新打开后，处理程序必须禁止IRQ。现在外部中断可以恢复成原值，这一点是可以做到的，因为服务例程没有修改寄存器r12。为了返回到被中断的任务，需要恢复上下文，并把最初的spsr复制到spsr_irq。

小结，优先级简单中断处理

- 处理有优先级的中断；
- 较低的中断延迟；
- 优点：确定的中断延迟时间，首先要确定优先级，然后屏蔽较低优先级的中断，再调用服务；
- 缺点：获得一个低优先级的服务例程所用的时间，与一个高优先级的例程一样长。

#### 9.3.5优先级标准中断处理

从优先级简单中断处理继续发展下去，处理程序的复杂度进一步提高。优先级简单处理程序采用测试所有的中断来确定最高优先级，这是一种效率较低的方法；但也有其优点，即响应时间的确定性，因为每个中断优先级都会花费相同的时间来确定。

一种较好的替换办法就是，在高优先级中断被确认后，程序尽早地跳转，一旦确定优先级，就设置PC立即跳转。这意味着对于优先级标准中断处理程序来说，代码对中断优先级的确认部分更为复杂，确认部分将决定优先级，并立即跳转到一个屏蔽低优先级中断的例程，然后再通过一个跳转表跳转到合适的ISR。

例9.12一个优先级标准中断处理程序的开头部分与一个优先级简单中断处理程序类似，只是更早地拦截了高优先级的中断，寄存器r14用来指向中断控制器的基地址，寄存器r10用来保存中断控制器的基地址，寄存器r10用来保存中断控制器的状态寄存器内容。为了允许处理程序重定位，pc指向的当前地址被保存到寄存器r11。

现在可以通过比较最高到最低优先级来测试中断源。第一个与中断源匹配的优先级决定了引入中断的优先级，因为每一个中断都预先设定了优先级。一旦匹配成功，就可以跳转到屏蔽低优先级中断的程序中。 

这里跳过汇编部分

小结，优先级标准中断处理

- 进入高优先级的中断服务时间比进入低优先级的中断服务时间更短；
- 较低的中断延迟；
- 优点：高优先级中断得到优先处理，并不要复制代码来设置外部中断屏蔽；
- 缺点：时间上有些损失，因为这种处理程序需要2次跳转，导致流水线在每次跳转发生时被刷新。

#### 9.3.6优先级直接中断处理

优先级直接中断处理与优先级标准中断处理的区别之一是：一些操作被移出中断入口处理程序，而放到各自的ISR中。被移出的包括屏蔽低优先级中断的代码。每个ISR都将屏蔽掉相对于自身的低优先级中断，由于预先设定了每个中断的优先级，所以优先级是一个固定的值。

第二点是：优先级直接中断处理程序直接跳转到合适的ISR。每个ISR在修改cpsr重新允许中断前，要禁止低优先级的中断。这种类型的处理程序头部相对简单，因为**屏蔽工作是由各自的ISR**完成的。但这样会带来少量的重复代码，因为每一个中断服务例程都必须完成这一任务。

例9.13bit_x定义把一个中断源与中断控制器中的某一位对应起来，用以一个ISR内屏蔽低优先级的中断。

保存好上下文后，**ISR表的基地址被装载到寄存器r12**.一旦中断源的优先级被确定，使用寄存器r12就可以跳转到正确的ISR。

```assembly
IRQ_Handler
	SUB r14,r14,#4
	STMFD r13!,{r14};保存lr_irq
	MRS r14,spsr;让r14暂时存储spsr_irq
	STMFD r13!,{r10,r11,r12,r14};保存上下文
	LDR r14,=ic_Base;将中断控制器地址送入r14
	LDR r10,[r14,#IRQStatus];通过r14偏移找到数据结构体中的IRQ状态送入r10中
	ADR r12,isr_table;地址装载伪指令，将isr表送入r12
	TST r10,#BINARY_0;将IRQ状态拿来比较得出中断源是啥
	LDRNE pc,[r12,#PRIORITY_0<<2];跳转到对应的ISR，这里是直接通过ISR表跳转到各自的ISR地址
	...
	B service_none;无服务
	service_timer1
		MOV r11,#bit_timer1
		LDR r14,=ic_Base
		LDR r12,[r14,#IRQEnable]
		ADR r10,priority_masks
		LDR r10,[r10,r11,LSL #2]
		AND r12,r12,r10
		STR r12,[r14,#IRQEnableClear]
		MRS r14,cpsr
		BIC r14,r14,#I_Bit
		MSR cpsr_c,r14
```

优先级中断的确定是通过从最高优先级中断开始，向下直到最低优先级中断的检查来实现。优先级中断一旦确定，就把合适的ISR地址装载到pc，即isr_table中保存的间接地址加上优先级左移2位。

ISR跳转表isr_table是以最高优先级的中断为开始排序的。

service_timer1入口部分说明了优先级直接中断处理使用的ISR例子。每个ISR都是唯一的，依赖于特定的中断源。

中断控制器的基地址复制到寄存器r14_irq。这个地址加上 一个偏移量用来复制IRQEnable寄存器的内容到寄存器r12。

处理程序可以继续位当前的中断服务，除非有更高优先级的中断发生，那样的话，高优先级的中断将打断当前的中断服务。

小结，优先级直接中断处理

- 在更短的时间内处理高优先级的中断，直接跳转到特定的ISR
- 低的中断延迟；
- 优点：使用 简单的跳转，为进入ISR节省了宝贵的时间；
- 缺点：每个ISR都需要设置外部中断屏蔽码，以阻止低优先级中断打断当前的ISR，这使得每个ISR增加了额外的代码。

#### 9.3.7优先级分组中断处理

优先级分组中断处理与其他优先级中断处理不同。他是针对大量的中断集而设计的，（stm32的cortex-M3采用的就是优先级分组中断处理）通过把中断分组并形成具有同一优先级的子集来实现的。

一个嵌入式系统的设计者必须明确每个子集的中断源，并为该子集赋予一个组优先级。由于各组决定了系统的特性，在为中断源进行选择分组时需谨慎，这一点很重要。把中断源集中管理，相对降低了处理程序的复杂度，因为没有必要依次检查每个中断来确定优先级。如果一个优先级分组中断处理程序设计的好，则可大大改善系统整体的响应时间。

例9.14针对两个优先级组设计的处理程序。

定时器中断源被划分到组0，通信中断源被划分到组1.组0的中断优先级比组1的高。

```assembly
I_Bit EQU 0x80
PRIORITY_0 EQU 2
PRIORITY_1 EQU 1
PRIORITY_2 EQU 0
PRIORITY_3 EQU 3

BINARY_0 EQU 1 << PRIORITY_0
BINARY_1 EQU 1 << PRIORITY_1
BINARY_2 EQU 1 << ...


GROUP_0 EQU BINARY_2|BINARY_3
GROUP_1 EQU BINARY_0|BINARY_1

GMASK_1 EQU GROUP_1
GMASK_0 EQU GMASK_1 + GROUP_0

MASK_TIMER1 EQU GMASK_0
MAKS_COMMTX EQU GAMSK_1
MASK_COMMRX EQU GMASK_1
MASK_TIMER2 EQU GMASK_0

ic_Base EQU 0x8000 0000
IRQStatus EQU 0x0
IRQRawStatus EQU 0x4
IRQEnable EQU 0x8
IRQEnableSet EQU 0x8
IRQEnableClear EQU 0xc

Interrupt_handler
	SUB r14,r14,#4
	STMFD r13!,{r14}
	MRS r14,cpsr
	STMFD r13!,{r10,r11,r12,r14}
	;计算返回地址+保存上下文
	LDR r14,=ic_Base
	LDR r10,[r14,#IRQStatus];装载IRQ状态
	ANDS r11,r10,#GROUP_0
	ANDEQS r11,r10,#GROUP_1
	AND r10,r11,#0xf;屏蔽高24位
	ADR r11,lowest_significant_bit;装载LSB地址
	LDRB r11,[r11,r10];装载字节，这里是r11 = *(r11+r11的低八位)这里没有看懂。
	B disable_lower_pririty
lowest_significant_bit
	; 0 1 2 3 4 5 6 7 8 9 a b c d e f
	DCB 0xff,0,1,0,2,0,1,0,3,0,1,0,2,1,0
disable_lower_priority;这个函数用来找到具体的ISR
	CMP r11,#0xff
	BEQ unknown_condition
	LDR r12,[r14,#IRQEnable]
	ADR r10,priority_mask;装载优先级地址
	LDR r10,[r10,r11,LSL #2];
	AND r12,r12,r10
	STR r12,[r14,#IRQEnableClear]
	MRS r14,cpsr ;复制cpsr
	BIC r14,r14,#I_Bit;清零I位
	MSR cpsr_c,r14;允许IRQ中断
	LDR pc,[pc,r11,LSL #2];跳转到一个ISR
	NOP
	DCD service_timer1
	...
priority_mask
	DCD MASK_TIMER1
	DCD MASK_COMMTX
	DCD MASK_COMMRX
	DCD MASK_TIMER2
```

通过使用二进制或操作，GROUP_x定义为各中断源赋予了他们特定的优先级。GMASK_x定义为分组的中断指定了屏蔽码。MASK_x定义使每一个GMASK_x对应于一个特定的中断源，后面他们将被用在优先级屏蔽码表中。

保护好上下文后，处理程序就读取IRQ状态寄存器，其地址是中断控制器的基地址加上一个偏移量。

然后，处理程序使用逻辑与来确认中断源属于哪一组。指令的后缀字母S表明要更新cpsr中的条件标志位。

寄存器r11现在保存的是优先级最高的分组0或1。处理程序把r11和0xf进行逻辑与来屏蔽其他中断。

接着，最低有效位表的地址被装载到寄存器r11.使用寄存器r10的值从表格其实装载1字节。一旦最低有效位的位置装载到寄存器r11，处理程序就跳转到一个例程。

disable_lower_priority中断例程首先检查是否有无效的中断。如果这个中断已经失效，则调用unknown_condition例程。处理程序装载IRQEnable寄存器，并把结果放在寄存器r12里。

以装载优先级屏蔽码表的地址得到优先级屏蔽码，然后左移2位寄存器r11里的数据。结果0,4,8或12加到优先级屏蔽码的地址。寄存器r10保存的就是禁止低优先级组中断发生的屏蔽码。

下一步是清除低优先级的中断，使用这个屏蔽码与寄存器r12(IRQEnable寄存器)进行与运算，清零对应的位；然后把结果保存到IRQEnableCLear寄存器。现在清除cpsr里的i位来允许IRQ异常就安全了。

最后处理程序通过修改寄存器r11(他仍然保存有最高优先级中断)和pc跳转到正确的中断服务例程。寄存器r11左移2位，并把结果加到pc,ISR的地址就确定了。这一地址直接装载到pc。

注意：跳转表必须跟在LDR指令后。因为ARM的流水线机制需要插入一个NOP。

小结，优先级分组中断处理

- 这是一种处理不同优先级组别中断的方法；
- 低的中断延迟；
- 优点：当系统要处理大量中断时很有用，同样缩短了响应时间，因为确定优先级的时间较短；
- 缺点：须决定中断如何分组。

#### 9.3.8基于VICPL190的中断服务例程

为了利用向量中断控制器的优点，IRQ中断向量入口作了修改。

```assembly
LDR pc,[pc,#-0xff0];IRQ pc = mem32[0xfffff030]
```

该指令从内存映射地址0xfffff030中获得数据装载到pc，这就**跳过了任何软件中断处理**，（向量表中存放的就是中断服务程序地址）因为可以直接从硬件获得中断源。由于只使用了一句简单的跳转指令，这样做也减少了中断延迟。

以下是一个VIC服务程序的例子：

```assembly
INTON EQU 0x0000
SYS32md EQU 0x1f
IRQ32md EQU 0x12
I_Bit EQU 0x80
VICBaseAddr EQU 0xfffff000;VIC控制器基地址
VICVectorAddr EQU VICBaseAddr+0x30;中断的ISR地址
vector_service_routine
	SUB r14,r14,#4
	STMFD r13!,{r0-r3,r12,r14}
	MRS r12,spsr
	STMFD r13!,{r12}
	;<清除中断源>
	MSR cpsr_c,#INTON|SYS32md
	;<中断服务代码>
	MSR cpsr_c,#I_Bit|IRQ32md
	LDMFD r13!,{r12}
	MSR spsr_cxsf,r12
	LDR r1,=VICVectorAddr;装载向量中断控制器地址
	STR r0,[r1];写入证明中断被服务过
	LDMFD r13!,{r0-r3,r12,pc}^
```

该例程在清除中断源之前保存了上下文及spsr_irq。一旦完成该操作，就可以通过清除i位，使得IRQ异常重新是能够，并将处理器模式设置为系统该模式。于是服务程序在系统模式下处理中断。一旦完成处理，设置i位禁止IRQ异常，并将处理器的模式切换回IRQ模式。

spsr_irq也从IRQ堆栈中被恢复，为返回做准备。

然后，中断服务程序要对控制器中的VICVectorAddr寄存器进行写。写这个寄存器的目的是，向优先级处理硬件表明，该中断已经被服务过。

注意：VIC基本上是一种硬件中断控制器，因此必须在VIC被激活之前，编程和设置好中断服务程序的地址列表。

### 9.4总结

（本章学的我有点迷糊，对于多种中断方式的汇编代码没咋记住）

异常会改变指令执行的正常顺序。ARM有七种异常：数据中止、快速中断请求、中断请求、预取指中止、软件中断、复位和未定义指令中止。每一种异常与ARM处理器的一种模式相对应。一旦异常发生，处理器便进入一种特定的模式，并跳转到向量表中的某个入口。每种异常也有一个优先级。

中断是由ARM外设引起的一种特殊的异常。IRQ异常用于通常的操作系统事务处理。FIQ异常一般是为单独的中断源保留的。中断延迟是指从外部中断请求信号出现，到特定的中断服务程序ISR的第一条指令被取指之间的时间间隔。

本章讨论了八种中断处理方法，从依次服务单个中断、非常简单的无嵌套中断处理，到把中断划分到不同优先级组别的高级优先级分组中断处理，还有基于向量中断控制器VIC的中断服务例程。

----

在stm32的cortex-M3上 就是采用的嵌套中断向量控制器，中断处理程序的部分就是配置NVIC寄存器的函数，因为具体调用了API，所以当时没注意到如何跳转到向量表的。中断服务程序就是自己编写的，函数名称是固定的，启动文件中的向量表存放的并不是中断处理程序，而是具体的中断服务程序名称，所以此时名称不可修改。

---

## 第十章，固件

- 固件和引导装载程序
- 例子：Sandstone
- 总结

本章讨论基于ARM的嵌入式系统的固件（Fireware）。

----

我一直认为的固件就是烧录到芯片后不再修改的程序部分。比如uboot以及需要通信协议的芯片。之前震哥讲过外部flash芯片就是烧录了固件，通过spi通信发送的控制指令实际上就是由烧录的固件来完成具体的实现。

-----

对于任何嵌入式系统，固件都是一个重要的部分，因为在一个新的平台上，固件通常被移植并执行的第一段代码。对不同的系统，固件有很大的差异：可以是一个完整的嵌入式软件系统，也可以只是一段简单的初始化和引导装载在bootloader程序。本章分为两节：

10.1节介绍固件，这一节将给固件一个定义，并介绍2个可以在ARM处理器上使用的流行的工业标准固件包-ARMFireware Suite和RedHad公式的RedBoot。这两个固件包是通用的，可以较容易和快速地移植到不同的ARM平台上。

10.2节重点讨论初始化和引导装载过程。为了讨论方便，本节介绍了一个简单的例子-Sandstone。Sandstone首先初始化硬件，然后装载一个映像文件到存储器，最后将pc指针的控制权交给该映像文件。

接下来讨论固件并介绍两个通用的ARM固件包。

### 10.1固件和引导装载程序

有些术语，不同的人往往会有不同的认识，本章使用如下定义。

- 固件，是底层的嵌入式软件，他**提供硬件和应用程序/操作系统层软件之间的接口**。固件存储在ROM里，嵌入式硬件系统一上电就立即执行。在完成系统初始化以后，固件可以继续保持活动状态，以提供某些基本的系统操作。对于一个基于RAM的系统，选择什么固件取决于特定的应用：可以是装载并执行一个复杂的操作系统，也可以只是简单地将控制权交给一个小的微内核。因此，固件实现的需求会有很大的不同。例如一个小的系统可能只需要一个最小的固件支持，用来引导一个小的操作系统。固件的一个主要目的是，**提供一个可靠的机制来装载和引导一个操作系统**。
- 引导装载程序bootloader，是一个用来引导操作系统或应用程序到硬件目标平台上的小应用程序，他在操作系统或应用程序执行以后便立即退出。引导装载程序通常包含在固件里。（固件包含引导装载程序）

为了有助于理解不同固件的实现要素，这里列出一个通常的固件执行流程。下面将详细讨论每一个执行阶段。

第一阶段是设置目标平台，准备一个操作系统引导时所需的环境，因为操作系统在运行前都需要一个特定的环境。这一阶段包括正确地初始化平台。（例如，要保证某个特定微控制器的控制寄存器已经被赋予恰当的地址；或者通过改变存储器映射，得到一个期望的存储器结构。）

| 执行阶段             | 特征                                                         |
| -------------------- | ------------------------------------------------------------ |
| 设置目标平台         | 编程硬件系统寄存器、平台识别（是哪种体系结构）、诊断（检查硬件是否正常）、调试接口、命令行解释器（这就是uboot中命令行的具体实现函数） |
| 抽象硬件             | 硬件抽象层（在uboot阶段不可避免的使用外设）、设备驱动        |
| 装载可引导的映像文件 | 基本的文件系统（正常来说是装载内核映像，至于说根文件系统，确实和uboot有点关系，需要提供一些关于根文件系统的参数给内核） |
| 交出控制权           | 改变pc指针，使它指向新的映像文件。                           |

同一段可执行代码经常需要在不同的内核和平台上运行，这种情况下，固件必须能够识别他正运行在哪种内核和平台上。内核的识别通常只须读取协处理器cp15的寄存器r0。其中保存有处理器的型号和生产商名字。有多种方法可以用来识别平台，例如检查一组特定的外设是否存在，或简单地读取一个可预编程的芯片内容。

诊断软件提供一种有效的方法来快速检测出一些基本的硬件故障。由于他是用来检测硬件的，因此诊断软件都与特定的硬件相关。

调试功能是以模块（module）或监视器（monitor）的形式提供的，它为调试运行在硬件目标平台上的代码提供软件支持，这些支持包括：

- 在RAM中建立断点，断点允许中断程序和查看处理器内核的状态；
- 列出、修改存储器的值（使用peek和poke操作）；
- 显示当前处理器寄存器的内容；
- 将存储器内容反汇编成ARM和Thumb指令。

交互功能：可以通过命令行解释器CL1(Command Line Interperter)或者与目标平台相连的专用主机调试器来发送命令。除非固件可以访问**内部硬件调试电路**（这个应该是ic设计人员使用的），否则只有在RAM中的映像文件可以通过软件调试机制来进行调试。

命令行解释器CL1通常在较高级的固件实现中才有。（比如cortex-M3就没有，而A7就有）可以通过在命令行提示符后面键入命令来更改默认配置，从而改变将要引导的操作系统。对于嵌入式系统，CL1通常需要通过一个主机终端应用程序来控制。主机和目标平台之间的通信一般通过串口或网络接口。（串口和tftp或nfs）

第二阶段是抽象硬件。硬件抽象层HAL(Hardware Abstraction Layer)是一个软件层，它向上通过提供一组已定义的编程接口来隐藏下层的硬件。当移植到一个新的目标平台时，这些编程接口保持不变，但下层的实现却改变了。例如，2个目标平台可能使用不同的时钟外设，每个外设的初始化和配置都需要新的代码，即使硬件和软件在实现上有很大不同，HAL编程接口都将保持不变。

HAL中与特定硬件外设通信的软件称为设备驱动。（device driver）每个设备驱动提供一个标准的应用程序编程接口API来对特定外设进行读/写。

第三阶段是装载一个可引导的映像文件。是否要实现这个功能，取决于用来存储映像文件的存储媒介。

注意：并不是所有的操作系统映像文件或应用程序映像文件都需要拷贝到RAM中，也可以简单地直接在ROM中执行。（如果是从ROM启动就是了）

ARM处理器通常都在一个包含FlashROM的小设备上，一般都带有一个简单的FlashROM文件系统(FFS)，允许存储多个可执行的映像文件。（外部Flash首先有着自己的文件系统，然后固件中包含设备驱动）

其他的存储媒介，比如硬件，**需要固件中包含能够访问该存储媒介的设备驱动**。访问该硬件时，固件需要知道底层文件系统的格式，这样**固件才能访问文件系统**，找到包含映像的文件，然后将其复制到内存。类似的，如果映像文件是在网络上的，固件就需要知道网络协议和以太网硬件。（使用tftp下载内核的时候就需要uboot提供类似的功能，并且uboot中应该包含协议栈）

装载过程中必须考虑映像文件的格式。最基本的映像文件格式是普通的二进制格式，这种格式的映像文件**不包含任何头部或调试信息**。在基于ARM的系统中，一种常用的映像文件格式是可执行和链接格式ELF。（之前也好奇过二进制和elf之间的区别，Executable and Linking Format）这种格式最初是为UNIX系统开发的，用来代替早期的普通对象文件格式COFF（Common Object File Format）。ELF文件有三种形式：可重定位、可执行和共享对象。

大多数固件系统都必须处理可执行的格式。装载一个ELF映像文件包括要解释标准的ELF头部信息（执行地址、类型、文件的大小）。映像文件也可能经过加密或压缩，这样的话，装载过程还包括执行解密或解压工作。（vmlinux就是elf格式，删减后变成Image，压缩后变成zImage，此时头部信息就是解压代码）

第四阶段是转交控制权。这个阶段，固件将平台的控制权交给操作系统或应用程序。

注意：并不是所有的固件在这个阶段都交出控制权，固件也可以在平台上保留控制软件。

如果固件将控制权交给操作系统，则在操作系统取得控制权后，固件一般处于非活动状态。（确实，启动之后uboot看不到了）固件的机器无关层MIL(Machine Independent Layer)或者硬件抽象层HAL部分固件也可以继续保持活动状态，这一层通过SWI软中断机制为特定的硬件设备提供一个标准的应用程序接口。（这里指的是通过系统调用来控制uboot的部分功能）

在ARM系统中，交出控制权就是更新向量表和修改pc指针。更新向量表包括修改特定的异常和中断向量，使其**指向操作系统中用来处理该异常或中断的处理程序**。（本身使用的是固件的异常处理程序，现在换成了操作系统的处理程序必然需要更新向量表的中每个中断服务程序的地址）pc指针必须被修改，使其指向操作系统的入口地址。

在一些比较成熟的操作系统中，比如Linux，转交控制权需要传递给操作系统内核kernel一个标准的数据结构，这个数据结构说明了操作系统内核将运行的环境。比如数据结构中可能有一个域包含目标平台的可用RAM的大小，另一个域包含所用MMU的类型。（uboot传递给kernel的三个参数中r2寄存器保存的就是一个数据结构）

接下来应用以上的定义来描述两个通用的固件套件。

#### 10.1.1ARMFirmware Suite

ARM Firmware Suite(AFS)是ARM公司专门为基于ARM的嵌入式系统开发的固件包，它支持包括Intel公司的XScale和StrongARM处理器在内的很多ARM处理器和平台。该固件包主要包括2项技术：硬件抽象层micro-HAL和调试监控Angel。

uHAL提供了一个可以在不同通信设备（例如USB、以太网、串口等）上操作的底层设备驱动框架，同时他也提供标准的应用程序编程接口API。这样在移植代码时，只要实现与uHAL的API函数相对应的、与具体硬件无关的部分即可。

使用标准的函数编程接口 ，可以使移植过程变得相对容易。一旦在新的目标平台移植好了固件，接着就是移植一个操作系统到这个平台。移植过程的复杂性取决于该OS是否使用了uHAL的API调用来访问硬件。

uHAL主要支持如下特征：

- 系统初始化，设置目标平台和处理器内核，这可以是一个简单、也可以是一个复杂的任务，取决于目标平台的复杂性；
- 简单的串口驱动，提供一种基本的与主机进行通信的方法；
- LED支持，控制LED以实现简单的用户反馈（feedback），使应用程序可以显示一些操作状态。
- 定时器支持，产生周期性的定时中断，这是抢占式调度操作系统实现其调度机制所必需的；
- 中断控制器，支持不同的中断控制器

在uHAL的启动监控中，包含一个命令行解释器CL1.

Angel允许调试的主机和目标平台之间的通信，使程序员可以查看和修改存储器内容，下载和执行映像文件，设置断点，查看处理器寄存器的内容。所有这些控制都通过主机调试器。Angel调试监控必须可以访问SWI和IRQ或FIQ中断向量。

Angel使用SWI指令来提供一组API函数，允许一个程序打开、读/写主机的文件系统。（系统调用）IRQ/FIQ中断用于与主机的通信。

#### 10.1.2RedHatRedboot

RedBoot是由RedHat公司开发的固件工具，遵循开放源码许可，没有版税或前期费用。RedBoot可以在不同的CPU上执行。它提供给了GNU的GDB（这是一种Linux下的调试方法）和bootloader两种调试方法。RedBoot的软件核心基于一个HAL。

RedBoot主要支持的特征如下：

- 通信，通过串口或以太网进行配置。对于串口，使用X-Modem协议与GNU调试器GDB进行过通讯；对于以太网，使用TCP协议与GDB进行通信，支持很多网络标准，比如tftp
- Flash存储器管理，提供一组文件系统函数，用它可以下载、升级、擦除Flash存储器里的映像文件。另外，映像可以被压缩和解压。
- 完全的操作系统支持，支持嵌入式Linux、Red Hat的eCos和其他许多常见操作系统的装载和引导。对于嵌入式Linux支持定义一些参数，这些参数在引导时直接传给操作系统内核。（太熟悉了）

### 10.2例子：Sandstone

本节设计的Sandstone是一个最小的uboot，只执行如下任务：设置目标平台环境，装载一个可引导的映像到存储器，将控制权交给操作系统。但他说一个真实运行的例子。

这个实现针对ARM Evaluator-7T评估板，它包含一个ARM7TDMI的处理器。这个例子清楚地说明了如何设置一个简单的平台，以及软件是如何被装载到存储器中并被引导的。被装载的软件既可以是一个应用程序（这是不是就是单片机开发烧录的文件）也可以是一个操作系统映像。Sandstone是一个静态的设计，在变异以后不能在配置。下表列出了Sandstone的基本特征。

| 属性                 | 配置                        |
| -------------------- | --------------------------- |
| 代码                 | 只使用ARM指令               |
| 工具链（就是编译器） | ADS1.2                      |
| 映像大小             | 700B                        |
| 源代码               | 17KB                        |
| 存储器               | 重映射过（uboot也重映射过） |

下面再来看一下目录和代码结构。目录结构显示了源代码放在那里，以及不同的编译文件放在哪里。代码结构着重介绍实际的初始化和引导过程。

请注意Sandstone是完全用ARM汇编写的，他是可以初始化目标硬件和引导任何软件的一段正常工作代码。当然是指在ARM Evaluator-7T评估板上。

#### 10.2.1Sandstone的目录结构

Sandstone源文件sand.s位于sand/build/src目录中。汇编器生成的目标文件放在build/obj目录下。目标文件被连接后，最后的Sandstone映像文件放在sand/build/image目录下，这个**映像文件包括Sandstone代码和有效载荷部分**。将被Sandstone装载并引导的映像文件（内核实际上就是有效载荷）放在sand/payload目录下。

关于Sandstone的build过程的详细介绍，可以参考sand目录下的readme.txt文件。readme.txt包含如何生成一个在ARM Evaluator-7T上运行的二进制映像文件的介绍。

#### 10.2.2Sandstone的代码结构

Sandstone只包含一个汇编文件。文件结构被分成几步，每一步对应Sandstone的执行流程的一个阶段。见下表

| 步   | 描述                                       |
| ---- | ------------------------------------------ |
| 1    | 执行复位异常                               |
| 2    | 开始初始化硬件                             |
| 3    | 存储器重映射（为了给kernel腾出空间）       |
| 4    | 初始化通信硬件（此时完成了启动前所有步骤） |
| 5    | 引导装载-复制映像文件和转交控制权          |

下面将详细介绍这些步骤，这里尽量避免与平台相关的部分，但是有些与硬件相关的部分是不可避免的（比如配置系统的寄存器和存储器重映射）。

Sandstone初始化工作的目标是设置目标平台环境，这样它就可以提供某些形式的反馈来指示固件正在执行和控制着平台。

##### 10.2.2.1第一步：执行复位异常

指令执行从复位异常开始。默认的相关量表中只要有一个复位向量入口，他就是真正被执行的第一条指令。除了复位向量外的其他向量都调换到一个哑处理过程--一条分支指令跳转到一个无限循环。这里假设在Sandstone的执行过程中没有异常或中断发生，复位向量使执行流程进入第二步。

```assembly
AREA start,CODE,READONLY;这块存储空间为只读的代码区
sandstone_start
	B sandstone_init1
	B ex_und
	B ex_swi
	B ex_pabt
	B ex_dabt
	NOP
	B int_irq
	B int_fiq
ex_und
	B ex_und;死循环，其他同理
	...
```

Sandstone_start被放在0x0

第一步的执行结果：

- 哑处理过程被设置；
- 控制权被转交给初始化硬件的代码。

##### 10.2.2.2第二步：开始初始化硬件

初始化硬件的主要工作是设置系统寄存器。访问硬件设备之前，必须先初始化这些寄存器。例如，ARM Evaluator-7T评估板有一个7段数码管显示器，可以把它作为反馈工具，用来指示固件正被执行。在显示段码之前，必须将**系统寄存器的基地址放在一个已知的位置**（这里其实很简单，就是通过伪指令将地存储单元的地址送入寄存器中）。这里选取默认地址0x03ff0000，这样可以使所有的硬件系统寄存器远离ROM和RAM，区分了外设和存储器地址空间。

这样，所有微控制器的**存储器映射寄存器**将被放在从地址0x03ff0000开始的特定偏移处。该操作可用下面的代码来实现：

```assembly
sandstone_init1
	LDR r3,=SYSCFG;SYSCFG默认地址=0x03ff0000
	LDR r4,=0x03ffffa0
	STR r4,[r3];SYSCFG = 0x03ffffa0，这里是进行属性配置
```

-----

弄明白了，全弄明白了！

存储器映射：由厂家决定，将空白的存储器变成每个存储单元都有对应地址并将这些存储单元分成不同的区域。比如代码段和RAM段

寄存器映射：首先需要介绍下cpu内的寄存器和寄存器映射得到的寄存器的区别，之前疑惑过用c来对寄存器进行操作，但是对cpu内的寄存器具体操作是由编译器实现的。这两种寄存器是不同的，r0这样的寄存器是cpu内部自带的寄存器是没有地址的，而外设寄存器是通过对4字节的特定功能的存储单元取别名得到的。

----

寄存器r3包含默认的系统寄存器基地址，并可被用来设置新的默认的地址，也可以用来设置其他类似于cache的特定属性。寄存器r4包含新的配置值，其**高16位包含新的系统寄存器基地址**，**低16位包含新的属性配置值0xffa0**

设置完系统寄存器的基地址后，就可以开始配置数码管显示了。用数码管来指示Sandstone的执行过程。这里没有描述数码管显示的代码，因为他是与具体硬件相关的。

第二步的执行结果：

- 系统寄存器被设置在一个已知的基地址0x03ff0000；
- 数码管显示器被配置，这样就可以用它来显示执行过程。

##### 10.2.2.3第三步：存储器重映射

硬件初始化的一个主要任务是设置存储器环境。Sandstone初始化SRAM，然后进行存储器**重映射**。这个过程应在系统初始化时尽早完成。在一个已知的存储器状态下，平台开始运行。如下表所列。

| 存储器类型  | 起始地址   | 结束地址   | 大小/KB |
| ----------- | ---------- | ---------- | ------- |
| Flash ROM   | 0x00000000 | 0x00080000 | 512     |
| SRAM bank 0 | 不可用     | 不可用     | 256     |
| SRAM bank 1 | 不可用     | 不可用     | 256     |

可以看到，硬件平台上电时，只有Flash ROM被分配在存储器重映射的一个位置，2个SRAM段没有初始化，所以还不能使用。下一步就是将两个SRAM段可用，并将Flash ROM重映射到一个新的地址。（存储器映射是厂家实现的，和uboot无关，这里是对存储器进行重映射来重新分配区域）

```assembly
LDR r14,=sandstone_init2;将重映射前中断服务程序地址送入r14
LDR r4,=0x01800000;新的Flash ROM位置
ADD r14,r14,r4;r14 = 中断服务地址+Flash地址得到的是重映射后的例程地址
ADRL r0,memorymaptable_str;首先是ADR伪指令，将地址送入r0中，L是带链接返回，memory这个地址是存储了新的存储器映射数据的结构体地址。uboot中就是初始化一个global结构体
LDMIA r0,{r1-r12};执行后增量将r0地址的内容送入r1-r12中，获得各个成员地址
LDR r0,=EXTDBWTH;=(SYSCFG+0x3010)，这里的SYSCFG是系统寄存器基地址+偏移量0x3010是存储器控制器的地址
STMIA r0,{r1-r12};其实就是更新存储器控制器寄存器
MOV pc,r14;跳转到重映射后的存储空间
sandstone_init2
	;sandstone_init2之后 的代码执行在@+0x01800000
```

这里的存储器重映射我熟悉了，就是重定位，将c语言的各个区重新定位。

| 类型        | 起始地址   | 结束地址   | 大小/KB |
| ----------- | ---------- | ---------- | ------- |
| Flash ROM   | 0x01800000 | 0x01880000 | 512     |
| SRAM bank 0 | 0x0        | 0x00040000 | 256     |
| SRAM bank 1 | 0x00040000 | 0x00080000 | 256     |

可以看到，SRAM现在可使用了，Flash ROM被放置在一个更高的地址上。最后的部分是跳转到固件的下一个例程或阶段。（uboot分为多个阶段，就是通过把例程地址送入pc实现的）

这个跳转是利用ARM流水线实现的。尽管新的存储器环境激活了，但下一条指令已经装载到流水线里了。下一个例程可以通过将寄存器r14的值复制到pc而被调用。这里在重映射代码的后面紧跟一条简单的MOV指令来实现这一功能。

第三步的执行结果：

- 存储器被重映射
- pc指向下一步，这个地址在重映射后的Flash ROM内。

##### 10.2.2.4第四步：初始化通信硬件

通信初始化包括配置串口和输出一个标准的提示符。显示出提示符，表示固件已经全部正常工作且存储器已成功重映射。同样，由于在ARM评估板Evaluator-7T上初始化串口的代码是与硬件相关的。

串口被设置成9600波特，无校验，1位停止位，无数据流控制。如果串口电缆接到评估板上，则主机终端就必须用上面相同的配置。

第四步的执行结果：

- 串口被初始化；
- 串口输出标准的提示符。

##### 10.2.2.5第五步：引导装载-复制映像文件和转交控制权

最后一步包括复制一个有效载荷，并将pc的控制权转交给该程序。这项工作通过下面的代码来实现。代码的第一部分初始化作为块复制工作寄存器的r12/r12/r14。引导装载代码假设该有效载荷是一个纯二进制的映像文件，无须解密或解压。

```assembly
sandstonee_load_and_boot
	MOV r13,#0;指向SRAM起始地址
	LDR r12,payload_start_address;指向内核的起始地址
	LDR r14,payload_end_address;指向内核的结束地址
_copy
	LDMIA r12!,{r0-r11};将内核起始地址的内容开始拷贝到SRAM起始地址
	STMIA r13!,{r0-r11}
	CMP r12,r14
	BLE _copy;如果小于等于就循环，是这么粗暴循环拷贝到SRAM中么
	MOV pc,#0;此时的0x0是SRAM的起始地址，同时也是kernel的起始地址，从而实现控制权交给kernel
payload_start_address
	DCD startAddress
payload_end_address
	DCD endAddress
```

通过强制把pc指向被复制的有效载荷的入口地址，就把pc的控制权交给了该程序。

第五步的执行结果：

- 有效载荷被复制到SRAM，地址为0x00000000。
- pc指针的控制权转交给了被装载程序,pc=0x0
- 系统完全被引导。

### 10.3总结

本章首先讨论了基于ARM的固件。固件是提供硬件和应用程序或操作系统接口的底层代码。引导程序bootloader装载操作系统或应用程序到存储器，然后将pc控制权交给被装载的软件。

其次，介绍了ARM Firmware Suite和RedBoot。ARM Firmware Suite是专门为基于ARM的系统设计的。RedBoot更通用，可以用在其他的非ARM的处理器上。

最后介绍了一个固件例子Sandstone。Sandstone初始化硬件，然后以下列步骤装载引导一个映像文件：

1. 执行复位异常操作；
2. 开始初始化硬件，设置系统寄存器的基地址，初始化数码显示管；
3. 存储器重映射
4. 初始化通信硬件，使输出指向到串口；
5. 引导装载-装载一个可执行的映像文件（有效载荷）到SRAM，将pc指针的控制权交给他。

这样就实现了ARM7TDMI嵌入式系统的全部初始化。

## 第十一章嵌入式操作系统

- 基本模块
- 实例：简单小型操作系统SLOS
- 总结

本章讨论嵌入式操作系统OS的实现。由于嵌入式操作系统是为某一特殊目的而设计的，因此他历来具有简单，实时性强，在有限的存储空间中运行等特点。随着嵌入式硬件的不断成熟，这些特点也不断发展、变化，传统上只能在桌面机S上找到的一些特征，比如虚拟存储器，现在也已经移植进嵌入式系统。

操作系统涉及的范围很广，本章只论述组成嵌入式操作系统的基本模块。该操作系统建立在第十章介绍的固件例子的基础上。

本章分为两节：11.1节简要介绍组成嵌入式操作系统的基本模块，同时指出一些针对ARm处理器的OS会涉及到的特定问题；11.2节介绍一个操作系统的实例，称为简单小型操作系统SLOS，SLOS说明了操作系统基本模块的一个具体实现。

### 11.1基本模块

一个操作系统由一些常见的底层模块组成，每个模块实现一个预定的功能。这些模块的相互作用和功能决定了这个特定操作系统的特征。

- **初始化代码**initialization是操作系统执行的第一段代码，包括建立内部数据结构、全局变量和硬件环境。在固件把控制权交给操作系统时，初始化代码开始执行。操作系统的硬件初始化包括设置各种控制寄存器（这里应该不是寄存器映射了，而是初始化），初始化设备驱动程序。若操作系统为抢占式的，还须建立一个周期性的定时器中断。
- **存储器处理**包括建立系统堆栈和任务堆栈。这些堆栈的位置决定了任务或系统可用的存储空间大小。系统堆栈的位置通常在操作系统初始化时设置。任务堆栈在何时建立，取决于该任务是静态的还是动态的。（之前提到的中断堆栈又是何时建立的，那六种模式对应的堆栈属于系统堆栈么，那操作系统初始化之前uboot就使用的堆栈又是啥时候建立的，即使上操作系统后也不影响ARM工作模式的切换，uboot也会分配堆栈的。就好像uboot和kernel都有自己的向量表，异常处理程序一样，也是拥有各自的堆栈）静态任务在编译时被定义，并包含于操作系统映像中。这些任务的堆栈可在操作系统初始化时建立。作为例子，后面的SLOS就是一个基于静态任务的操作系统。动态任务在装载并运行啊哦做系统以后被装载和执行，（这里说的动态任务指的是动态加载驱动模块）他不是操作系统映像的一部分。这种任务的堆栈在创建任务时才建立。不同操作系统的存储器处理的复杂程度也不同，取决于很多因素，比如所选择的ARM处理器核、微控制器的性能以及最终目标硬件的物理存储器布局等。11.2节中将介绍的实例操作系统SLOS采用静态存储器。他简单配置微控制器内的寄存器，并设置各堆栈的位置。因为没有实现动态存储管理（这里指的是没有堆这个概念，只有栈的概念），所以找不到malloc和free函数的实现，这些函数一般可在标准C库中找到。
- **中断和异常处理**的方法是操作系统结设计的一部分。设计时必须考虑如何处理各种不同的异常：数据中止、快速中断请求、中断请求、预取中止、复位和软中断SWI等。（不管是uboot的向量表还是kernel的实现方式都是之前学习的汇编的方式）并非所有的异常都需要异常处理程序。比如，若目标板不使用FIQ中断，则无需FIQ中断处理程序。通常比较安全的做法是：为未使用的异常提供一个死循环，作为默认的异常处理程序，调试容易：当系统不响应时，说明是在某一异常处理程序中死循环。像SLOS这种抢占式的操作系统，需要一个周期性的中断。一般情况下，，这由目标硬件上的计数器或定时器产生。操作系统在初始化阶段设置该周期性中断频率，通常只须给计数器或定时器的存储器映射寄存器赋予值即可。当被激活时，计数器或定时器开始递减该值，当值递减到零时，就产生一个中断，相应的ISR将处理这个中断。ISR首先用一个新的起始值重新初始化该计数器或定时器，然后调用调度程序或其他专用例程。相反，非抢占式的操作系统不需要周期性的中断，它使用不同的技术，例如轮询--不断检查设备状态的变化，如果状态改变，则执行相应的特定操作。
- **调度程序**是决定下一个该执行哪个任务的算法。有很多可选的调度算法，Linux采用的是CFS完全公平分配算法。最简单的一个称为循环算法，它以固定的次序循环激活任务。调度算法的选择必须在效率、代码大小与复杂性之间折衷。执行完调度程序后，新、老任务用上下文切换来实现交换。上下文切换将老人物的处理器寄存器数据保存到一个数据结构中，然后将新任务的数据装载到处理器寄存器中。（进程上下文属于用户模式下的多个进程切换，中断则是模式切换时的保存上下文）
- 最后一个模块是**驱动程序框架**--操作系统用于在不同硬件外设之间提供统一接口的机制。这个框架提供一种标准且简单的方法，把对特定外设的新支持集成到操作系统中。应用程序要访问特定外设时，必须有对应的可用驱动程序。框架必须为访问外设提供安全的方法。

### 11.2实例：简单小型操作系统SLOS

开发一个小型操作系统，说明之前讨论的基本模块是如何组成一个完整的操作系统的。这里选用ARM家族中最简单的核ARM7TDMI，以ADS1.2为开发环境 ，以ARM公司的Evaluator-7T为目标板。移植SLOS到其他开发环境中也相对简单。这里使用第十章介绍的Sandstone固件来装载和执行SLOS。

SLOS是抢占式操作系统，周期性的中断唤醒睡眠态的任务。为了简单起见，所有的任务和设备驱动程序都是静态的，即他们都在编译时创建而非系统运行时创建。

同时SLOS提供了一个设备驱动程序框架。

SLOS设计运行在无存储器管理单元或保护单元的ARM7TDMI核上。假设已在初始化代码中配置好了存储器映射。要求将SRAM放在0x0~0x00080000的地址内，将配置借此运气基地址放在0x03ff0000。

SLOS被装载到地址0x0，这个地址也是SLOS的入口地址。当固件将控制权交出时，ARM处理器工作在SVC模式。由于SVC模式是特权模式，所以允许初始化代码通过访问cpsr改变工作模式。可以利用这一点设置IRQ模式和系统模式下的堆栈。（初始化代码是内核的一部分，并不是固件，内核上来就设置IRQ和系统模式下的堆栈，这个是没错的，内核在编译的时候确实可以决定中断栈的大小）

在当前配置下，SLOS包含三个任务和两个服务例程。任务1和任务2演示了使用一个二元信号量实现互斥的例子；实现的2个服务例程是周期性定时器和按钮式中断；任务三通过ARM评估板Evaluator-7T的串口提供一个简单的命令行接口。

SLOS的每个任务都需要自己的堆栈。所有的任务都在用户模式下运行，因此任务只能读cpsr而不能写cpsr。任务切换到特权模式的唯一途径是，使用一个SWI指令调用。这个机制也被用来调用设备驱动程序，因为设备驱动程序也可能写cpsr。

在任务中可以修改cpsr，但这种修改只能通过使用可更新cpsr条件标志的指令来间接进行。

#### 11.2.1SLOS目录结构

SLOS可以从原作者的网站下载，在第11章目录下，SLOS的目录结构与Sandstone固件的目录结构相似。

在包含操作系统所有源文件的目录slos/build/src下，有6个子目录。目录slos/build/src/core包含了各种工具的源文件，例如命令行解释器CL1的源代码。（这个解释器是uboot命令行的解释器，怎么会出现在kernel目录下）

特定平台的代码放在以此平台命名的目录下，例如Evaluator-7T的特定代码就放在目录e7t下。

目录slos/build/src/devices存放所有的设备驱动程序源文件，目录slos/build/src/events存放处理服务、异常和中断的源文件。

最后，目录slos/build/src/apps存放特定 配置下的应用程序，例如在Evaluator-7T的实现上，有3个应用程序。

#### 11.2.2初始化

初始化SLOS有3个主要阶段--启动，简历进程控制块PCB和执行C初始化代码。启动阶段设置FIQ寄存器和系统模式、SVC模式、IRQ模式下的堆栈。（这个就是kernel建立的，内核启动前也是由堆栈的，只不过是由uboot建立）建立进程控制块阶段建立包含每个任务状态的PCB，PCB包含所有的ARM寄存器。在上下文切换时，PCB用来保存和恢复任务状态（这里的PCB就是进程描述符task_struct结构体，内部包含进程地址空间4GB，这里包含进程栈，实现保存上下文），启动时PCB被设置成一个初始状态。最后的C初始化阶段调用设备驱动程序、事件处理程序和周期性定时器初始化例程。初始化一结束，就可以调用第一个任务了。

控制权通过复位向量转交给SLOS。vectorReset存放初始化代码的起始地址。假设固件将处理器置于SVC模式，就允许操作系统的初始化代码可完全访问cpsr。第一条操作系统指令将初始化代码的起始地址装载到pc。可以从下面列出的向量表中看到使用load指令装载一个字。汇编器使用pc与vectorReset地址的差来计算偏移量。（之前学kernel启动流程的时候并没有分成初始化代码和C初始化两个部分，所以很混沌）

```assembly
AREA ENTRYSLOS,CODE,READONLY
ENTRY
	LDR pc,vectorReset;这就是kernel启动阶段的第一条指令，将复位向量送入pc，执行复位处理例程
	...
vectorReset
 	DCD coreInitialize
 	...
```

作为初始化过程的一部分，这里通过**使用备份FIQ模式寄存器，实现了一个底层调试系统**。这些寄存器用来保存状态信息。也并不总是使用FIQ寄存器，因为这些寄存器可能已用于其他目的了。

```assembly
bringupInitFIQRegisters
	MOV r2,r14
	BL switchToFIQMode;跳转到FIQ模式再返回
	MOV r8,#0;r8_irq = 0
	MOV r9,#0
	MOV r10,#0
	BL switchToSVCMode;切换回SVC模式
 	MOV pc,r2;返回原程序
 coreInitialize
 	BL bringupInitFIQRegisters;很显然跳转到上面例程
```

下一阶段是设置SVC/IRQ和系统堆栈基址寄存器。由于处理器已处于SVC模式，所以可直接设置SVC堆栈基址寄存器。代码如下（这里的模式堆栈都是物理地址，那进程堆栈又是在哪里设置的，应该是虚拟地址吧）：

```assembly
MOV sp,#0s80000;上来直接设置了SVC堆栈指针地址
MSR CPSR_c,#NoInt|SYS32md;切换成SYS模式
MOV sp,#0x40000
MSR CPSR_c,#NoInt|IRQ32md;设置IRQ模式
MOV sp,#0x9000
MSR CPSR_c,#NoInt|SVC32md;切换回SVC模式
```

如代码所列，建立堆栈后，处理器将切换回SVC模式，以便初始化过程继续下去。在特权模式下，初始化的最后阶段就可通过清除cpsr的I位，并将处理器切换回用户模式，并允许IRQ中断。

执行完初始化启动代码后的结果如下：

- 底层调试机制被初始化；
- SVC/IRQ和系统堆栈基址寄存器被设置。

要运行SLOS，还必须初始化每个任务的PCB。PCB是一个保留的数据结构，用于保存所有ARM寄存器的一个副本。通过将相应任务的PCB数据复制到处理器寄存器。可激活某个任务。

下面介绍下进程控制块结构的各个成员，这就是保存进程寄存器上下文的结构，里面存的数据就是task_struct的成员，**PCB和task_struct是一个东西**！

| Offset | 寄存器 | Offset | 寄存器 |
| ------ | ------ | ------ | ------ |
| 0      | --     | -36    | r6     |
| -4     | r14    | -40    | r5     |
| -8     | r13    | -44    | r4     |
| -12    | r12    | -48    | r3     |
| -16    | r11    | -52    | r2     |
| -20    | r10    | -56    | r1     |
| -24    | r9     | -60    | r0     |
| -28    | r8     | -64    | pc+4   |
| -32    | r7     | -68    | spsr   |

真的是把常用的寄存器都保存全了。

每个任务的PCB必须在上下文切换发生前被初始化，因为上下文切换要将PCB数据复制寄存器r0-r15和cpsr。如果PCB未被初始化，则上下文切换将会复制一些不确定的数据到这些寄存器。

PCB主要有4部分需要初始化：程序计数器、链接寄存器、用户模式堆栈（这里保存的堆栈就是进程栈了么，要是这么说的话进程栈是物理地址了）和每个任务保存的处理器状态寄存器（寄存器r13、r14、r15和spsr）。

```assembly
;void pcbSetUp(void *entryAddr,void *PCB,UINT offset);
pcbSetUp
	STR r0,[r1,#-4];之前学过的r0是第一个参数，并且是返回值保存的寄存器，r1是PCB，所以这里是PCB[-4] = entryAddr
	STR r0,[r1,#-64];PCB[-64] = C_TaskEntry
	SUB r0,sp,r2;r0 = sp-offset
	STR r0,[r1,#-8];PCB[-8] = sp-offset
	MOV r0,#0x50;这是r0 = cpsr[7:0] 0101 0000
	STR r0,[r1,#-68];PCB[-68] = iFt_User
	MOV pc,lr
```

上面这段代码就是初始化PCB中的成员。

为便于说明PCB的初始化过程，这里摘取了初始化PCB例程的部分代码。例程pcbSetUp用于创建任务2和任务3。其中寄存器r0是任务的入口地址，也就是任务的执行地址（指的是进程的开始地址或者说函数的栈帧结构的起始地址？不太懂）；寄存器r1是PCB数据结构的地址-pcbAddr标号，这个地址指向存放某个任务PCB的存储块（就是PCB所在的堆栈地址）；寄存器r2存放堆栈偏移值，用来定位堆栈在存储器映射中的位置。（每个进程栈的地址不同，当前sp+offset找到我们想要的堆栈地址）

注意：因为任务1是第一个执行的任务，所以他不需要初始化。（没看到任务在哪里体现的）

建立PCB的最后一步是设置当前任务的标识符，调度算法根据该标识符来决定当前应该运行哪个任务。()

```assembly
LDR r0,=PCB_CurrentTask;当前进程的PCB地址
MOV r1,#0
STR r1,[r0];PCB[0] = 0，设置当前进程标识符,可能这里第一个元素就是进程标识符
LDR lr,=C_Entry
MOV pc,lr
```

在程序段的最后调用第一个C例程--C_Entry，这通过将此例程的起始地址赋给pc来实现。因为前面涉及到设置堆栈位置等操作寄存器，只能使用汇编。接下来的就是由C编译的部分。

PCB初始化过程执行完毕的结果如下：

- 初始化了所有3个任务的PCB；()
- 设置当前要执行的PCB为任务1（所谓的任务1就是进程标识符0，指的就是进程标识值--PID）

现在初始化过程交给例程C_Entry，该例程在build/src/core/cinit.c源文件中。C_Entry例程调用另一个例程cinit_init()，cinit_init()例程初始化设备驱动程序、事件服务和周期性中断。这个C程序设计成不需要标准C库的支持，因为它没调用任何标准C库中的函数。（内核中存在函数库，但那是GNU C库而不是标准C库，因为kernel要考虑本身占用空间）

```c
void cinit_init(void)
{
    eventIODeviceInit();
    eventServicesInit();
    eventTickInit(2);
}
```

这三个函数分别用来初始化操作系统的各个不同部分。最后一个只有一个参数，用来设置周期性中断的时间间隔以ms为单位。

cinit_init()例程的初始化完成以后，周期性定时器就被启动了。这就意味着任务1应该在定能够使其第一次中断之前被调用。为使周期性时间可以中断处理器，必须使能IRQ，且处理器必须处于用户模式下。将这些设置完成后，就可以**调用任务1的入口地址**C_EntryTask1。

```c
int C_Entry(void)
{
    cinit_init();
    eventTickStart();//启动定时器
    __asm
        {
            MSR CPSR_c,#0x50;//设置iFt_USER
        }  
    C_EntryTask1();//执行任务1
    return 0;
}
```

如果程序正常运行，那么C_Entry例程最后的return语句将用惯不会执行到。至此，完成了所有初始化工作，操作系统就可正常工作。

所有C初始化代码执行完毕的结果如下：

- 设备驱动程序被初始化；
- 事件服务被初始化；
- 周期性定时器被初始化并启动；
- 在cpsr中使能IRQ中断
- 处理器工作在用户模式
- 调用了任务1的入口地址。

---

为什么固件退出时要保证是SVC模式？

我理解是因为kernel要设置多种工作模式下的堆栈，需要操作cpsr实现切换模式，所以不可以是用户模式。

-------

#### 11.2.3存储模型

SLOS采用一个简单的存储模型，如下图所示，SLOS的代码部分分配在存储器低端，IRQ和每个任务的堆栈分配在存储器高端，SVC堆栈分配在存储器顶端。（我就是对任务、模式的堆栈分布很感兴趣）下图中的箭头表示堆栈的增长方向。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686211945879.png" alt="1686211945879" style="zoom:25%;" />

这行图真的是帮了我大忙了，可以看得出来不同模式下的堆栈果然是不同的地址，之前提到过要把kernel起始地址从0开始，最底部的是kernel的向量表。也能看出来寄存器映射部分距离堆栈很远。系统/用户模式的堆栈和进程1的堆栈是同一个基地址，进程2开始是偏移基地址的堆栈了。

#### 11.2.4中断和异常处理

SLOS操作系统的实现实际上只用到3个异常，其他异常都被忽略。（其他模式下的堆栈也忽略了）。当遇到其他未使用的异常时，便进入相应的哑处理程序。为安全起见，这里将这些哑处理程序设计成死循环。为完善这个操作系统，这些哑处理程序需要用完整的处理程序来代替。3个异常及其在操作系统中的使用方法如下表所示：

| 异常 | 目的                 |
| ---- | -------------------- |
| 复位 | 初始化操作系统       |
| SWI  | 设备驱动程序访问机制 |
| IRQ  | 事件服务机制         |

##### 11.2.4.1复位异常

复位向量只在初始化阶段被调用一次。理论上，可以再次调用它来重新初始化系统--例如，由看门狗定时器溢出引发的处理器复位。当系统长时间没反应时，看门狗定时器可以用来复位系统。

##### 11.2.4.2SWI异常

应用程序通过SWI处理机制来调用设备驱动程序。（这里指的是open打开设备节点）SWI指令迫使处理器从用户模式切换到SVC模式。内核的SWI处理程序在下面列出，处理程序的第一步是将 寄存器r1~r12保存到SVC堆栈中。（中断上下文）

下一步是计算SWI指令的地址，并将指令装载到寄存器r10。将SWI指令的高8位屏蔽后，便得到了SWI号（这就是系统调用号）；然后将SVC堆栈的地址复制到寄存器r1，并将 其作为调用SWI C处理程序的第二个参数。（方便服务例程调取数据）

然后将spsr复制到寄存器r2，并保存到堆栈中。这一步只有当发生SWI嵌套调用时才需要。（这是因为发生嵌套的时候cpsr会再次更新spsr，并且SWI堆栈也会被覆盖，这需要帧堆栈来保存SWI堆栈内容）接下来处理程序将跳转到调用C处理例程的代码处。

```assembly
coreSWIHandler
	STMFD sp!,{r0-r12,r14}
	LDR r10,[r14,#-4];装载SWI指令到r10
	BIC r10,r10,#0xff000000;屏蔽高8位
	MOV r1,r13;保存sp_svc
	MRS r2,spsr
	STMFD r13!,{r2};将r2保存到堆栈
	BL swi_jumptable;跳转到swi_jumptable
	LDMFD r13!,{r2};恢复spsr
	MSR spsr_cxsf,r2;复制到spsr
	LDMFD r13!,{r0-r12,pc}^;恢复上下文
swi_jumptable
	MOV r0,r10;将swi号复制到r0
	B eventsSWIHandler;在这个函数中利用swi号找到对应的swi服务例程
```

C处理程序eventsSWIHandler被调用，并且寄存器r0包含SWI号，寄存器r1指向保存在SVC堆栈中的寄存器。这里就是简单判断了一次SWI号，我觉得r[0]是swi号

```c
void eventsSWIHandler(int swi_number,SwiRegs *r)//r是r13_svc堆栈指针
{
    if(swi_number = SLOS)
    {
        if(r->r[0]==Event_IODeviceInit)//这里取出了堆栈头部的东西，进行了比较。
        {
            ioInitializeDrivers();
        }else{
            //若非初始化，则切换到系统模式，并使能IRQ
            if(STATE!=1){//这里的state是啥，在SLOS中可能意味着PID
                modifyControlCPSR(SYSTEM|IRQoN);
            }
            switch(r->r[0])
            {
            	case:
                    r->r[0] = (unsigned int)io_open_driver(
                    (UID*)r->r[1],
                    r->r[2],
                    r->r[3]
                    );
                    break;
                    ...
                    
            }/*若非初始化，切换回管理模式并禁用IRQ*/
            if(STATE!=1){modifyControlCPSR(SVC|IRQoFF);}
            }
        }
    }
}
```

##### 11.2.4.3IRQ异常

IRQ处理程序比SWI处理程序简单得多，将它设计为不支持嵌套的基本中断处理程序。处理程序首先保存上下文；然后将中断控制器的中断请求寄存器INTPND复制到寄存器r0;接下来每个中断服务例程将自身所代表的的中断源与寄存器r0进行比较，（这就是软件实现中断处理优先级）如果匹配，则该例程被调用，否则将寄存器INTPND所表示的中断看作**虚中断**并忽略它。

```assembly
eventsIRQHandler
	SUB r14,r14,#4;中断异常的lr需要-4
	STMFD r13!,{r0-r3,r12,r14};保存上下文
	LDR r0,INTPND;r0 = 中断请求寄存器
	LDR r0,[r0];r0 = *r0
	TST r0,#TICKINT;如果是定时器中断
	BNE eventTickVeneer;跳转到定时器中断服务程序，这里应该是eq的，但是一直都是这么写的
	LDMFD r13!,{r0-r3,r12,pc}^;返回到任务并更新cpsr
```

对于系统认可的中断源，将调用各自的中断服务例程来处理这个中断事件。下面的代码是一个定时器中断服务例程，从例子中可看出该中断服务例程包含2个调用：第一个是复位定时器例程；第二个是称为调度程序的kernelScheduler例程，该例程进行上下文切换。

```assembly
eventTickVeneer
	BL eventTickService;复位定时器硬件
	B kernelScheduler;跳转到调度程序
```

不需要将寄存器r4-r12放到IRQ堆栈中（不理解，都是未分组寄存器为啥还差别对待，这些是被调用函数存放参数的寄存器，所以哪怕保存寄存器也不会在当前函数中保存），因为调度算法和上下文切换将会仔细处理这些寄存器。

#### 11.2.5调度程序

SLOS的底层调度程序采用简单的静态循环算法，如下面的伪代码所示，这里的静态是指任务只能在操作系统初始化时创建。SLOS中的任务在操作系统处于活动状态时，既不能创建，也不能删除。（那这里就是单纯的排个优先级，cfs采用的是虚拟运行时间越小的放在前面）

```c
scheduler()
{
    T = t+1;
    if T = MAX_NUMBER_OF_TASKS
        T = 0;
    end;
    ContextSwitch(t,T);
}
```

在初始化阶段，将当前活动任务t的PCB地址PCB_CurrentTask置为任务0，当定时器中断产生时，新任务T灯光与当前任务号t+1.如果任务号等于任务最大值MAX_NUMBER_OF_TASKS，则将任务T重新设置为任务0。（这里是因为超出了系统的PID_max，Linux中会事先检查是否查过max，没超过才会提供pid）

1. 从PCB_CurrentTask中获得当前任务ID；
2. 在PCB_Table中使用PCB_CurrentTask作为索引找到当前任务对应的PCB地址；（现在都不使用PCB表，而是任务链表）
3. 使用步骤2所获得的地址来更新PCB_PtrCurrentTask的值；
4. 使用循环算法计算新任务T的ID；
5. 将新任务T的ID保存到PCB_CurrentTask；
6. 在PCB_Table中使用更新后的PCB_CurrentTask作为索引找到下一个任务的PCB地址
7. 将下一个任务的PCB地址保存到PCB_PtrNextTask。

剩下不学了

#### 11.2.6上下文切换

上下文切换使用调度程序产生的更新信息，交换活动任务t和下一个任务T。为达到这一目的，上下文切换将这个过程分成2个阶段，第一阶段将处理器寄存器保存到由PCB_PtrCurrentTask指向的当前任务t的PCB中；第二阶段将由PCB_PtrNextTask指向的下一任务T的PCB数据恢复到寄存器中。（因为是静态创建任务，所以事先就知道下一个任务是啥，所以在PCB中设置了指向下一个任务的指针域）

下面简单介绍上下文切换2个阶段的过程和代码，先是保存当前任务的上下文，然后恢复新任务的上下文。

##### 11.2.6.1保存当前任务上下文

第一阶段是保存当前活动任务t的寄存器。所有的任务都在用户模式下运行，所以必须保存用户模式下的寄存器。步骤如下：

1. 必须从堆栈中恢复寄存器r0-r3和r14，这些寄存器属于当前任务；（这里是不是认为有的寄存器没用上，而是保存在堆栈了，所以需要拿出来统一放到寄存器中，然后再保存寄存器）
2. 寄存器r13用于指向当前任务PCB_CurrentTask的PCB，偏移量为-60，这个偏移量允许2条指令来更新整个PCB；
3. 保存所有用户模式下的寄存器r0-r14，这只要用一条指令来完成。符号^表示对用户模式下寄存器的多次存储操作。（之前搜过这里是强制cpsr从spsr中恢复）第二条存储指令保存spsr和用于返回的链接寄存器。

将寄存器保存到PCB中的代码为

```assembly
handler_contextswitch
	LDMFD r13!,{r0-r3,r12,r14};不理解上来先恢复寄存器
	LDR r13,=PCB_PtrCurrentTask
	LDR r13,[r13]
	SUB r13,r13,#offset15Regs
	STMIA r13,{r0-r14}^
	MRS r0,spsr
	STMDB r13,{r0,r14}
```

保存当前任务上下文以后的结果如下：

- 复位IRQ堆栈并将它保存到PCB_IRQTask;（这里没涉及到IRQ）
- 任务t的用户模式下的寄存器被保存到当前PCB中。

##### 11.2.6.2恢复新任务上下文

上下文切换的第二阶段是将T的PCB恢复到用户模式下的寄存器中。完成这一过程，例程接着就必须将控制权交给新任务T。步骤如下：

1. 恢复并将r13设置到与新任务PCB的起始地址偏移为-60的位置；
2. 首先恢复寄存器spsr（只有当发生中断和软中断才会cpsr拷贝到spsr）和链接寄存器，然后恢复下一个任务的寄存器r0-r14，寄存器r14是用户模式下的寄存器r14，而不是指令中带有符号^的IRQ寄存器r14；
3. 从PCB_IRQStack恢复IRQ堆栈
4. 复制保存在寄存器r14中的地址到pc，并更新cpsr，以继续运行新任务。

从PCB中恢复寄存器的代码如下：

```assembly
LDR r13,=PCB_PtrNextTask;转到下一个任务的PCB地址
LDR r13,[r13];难道上面这个是PCB指针的地址么
SUB r13,r13,#offset15Regs;
LDMDB r13,{r0,r14}
MSR spsr_cxsf,r0
LDMIA r13,{r0-r14}^
LDR r13,[r13]
MOVS pc,r14
```

恢复新任务上下文以后的结果如下：

- 上下文切换完成；
- 新任务的寄存器恢复到用户模式下的寄存器中；
- IRQ堆栈恢复到进入IRQ中断处理程序之前的设置。

所以说进程上下文怎么会涉及到中断呢。

#### 11.2.7设备驱动程序框架

使用SWI指令实现设备驱动程序框架DDF（Device Drier Framework）。DDF保护操作系统，使应用程序不能直接访问硬件，并提供一个统一的标准接口给所有任务。如果任务想访问一个特定设备，则它必须先获得一个唯一的标识号UID。（这是文件的fd吧）通过调用打开宏(eventsIODeviceOpen)来完成。这个宏被直接转换成一条设备驱动程序SWI指令。UID用来保证没有其他任务正在访问相同的设备。

打开一个设备驱动程序的任务代码如下：

```c
device_treestr * host;
UID serial;
host = eventIODeviceOpen(&serial,DEVICE_SERIAL_E7T,COM1);//这里是返回文件指针
if(host == 0)
{
    //返回0表示文件打开错误，看看errno怎么记录
}
switch(serial)//这是fd吧
{
    case DEVICE_IN_USE:
    case DEVICE_UNKNOWN:
}
```

这个例子说明了如何使用设备驱动程序框架来打开一个串行设备。

可以使用一些宏将参数传送到寄存器r1~r3，然后这些寄存器通过SWI机制传给设备驱动函数。在这个例子中，实际上只有寄存器r1指向的值(&serial)是被更新的，这个值用来返回UID，如果返回0表示出错。

下面的代码显示了宏eventIODeviceOpen如何转化成一个SWi指令调用：

```c
PRE r0 = Event_IODeviceOpen(unsigned int)
	r1 = &serial(UID * u)
    r2 = DEVICE_SERIAL_E7T(unsigned int major)
    r3 = COM1(unsigned int minor)
    SWI 5075
POST r1 = UID指针指向的数据改变了
```

当任务运行在非特权模式下时，可使用SWI切换到特权模式，这样就允许设备驱动程序完全访问cpsr。下图说明了当调用一个设备驱动程序函数时实际的模式变化。从图中可看出设备驱动程序自己在系统模式下执行。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686279413613.png" alt="1686279413613" style="zoom:25%;" />

这幅图写的很好，侧重于工作模式切换上，阴影部分是内核态了。

一旦执行SWI指令，处理器就进入SVC模式，并且IRQ中断自动关闭。只有当处理器切换到系统模式时，中断才能继续使用。只有一个例外，那就是在初始化阶段 调用设备驱动程序。这种情况下，中断仍然是禁止的。

### 11.3总结

一个运行在ARM处理器上的嵌入式操作系统的基本模块如下：

- 初始化模块initialization建立所有的内部变量、数据结构和操作系统使用调度硬件设备。
- 存储器处理模块memory handling组织存储器，以容纳内核和要执行的各种应用程序。
- 所有的中断喝异常都需要一个处理程序，对于未使用的中断和异常必须提供一个哑处理程序。
- 抢占式操作系统需要一个周期性定时器，该定时器产生周期性的中断，以调用调度程序。
- 调度程序是用来决定下一个要执行哪个任务的算法
- 上下文切换保存当前任务的状态并恢复下一个任务的状态。

以下接模块在一个被称为简单小型操作系统SLOS的操作系统里都有相应的例子：

- 初始化模块-建立SLOS的所有功能模块，包括模式堆栈、每个应用程序的进程控制块PCB和设备驱动程序等。
- 存储模型--SLOS内核位域存储器低地址，每个应用程序都有自己的存储空间和堆栈，微控制器系统寄存器独立于ROM和SRAM。（ROM和SRAM应该不在一个芯片上）
- 中断和异常-SLOS只使用三个时间：复位、SWI和IRQ所有的未使用的中断和异常都提供一个亚处理程序。
- 调度程序--SLOS实现一个简单的循环调度程序。
- 上下文切换--首先将当前上下文保存到一个PCB中，然后从另一个PCB中恢复下一个任务的上下文。
- 设备驱动程序框架--保护操作系统，以使应用程序不能直接访问硬件。

这一章很好，模式堆栈和进程堆栈的存储器模型让我直观的看到了。

## 第十二章、高速缓冲存储器cache

- 存储层次和cache
- cache结构
- cache策略
- 协处理器15与cache
- 清除和清理cache
- cache锁定
- cache与软件性能
- 总结

---

之前以学cache的存储策略为主，并没有学习协处理器的指令，具体编程。cache对我来说仍然是一片未知的谜团

---

cache是一种容量小，速度快的存储器阵列。它位于主存和处理器内核之间，保存着最近一段时间处理器涉及到的主存块内容。在需要进行数据读取操作时，为了改善系统性能，处理器尽可能从cache中读取数据，而不是从主存中获取数据。cache的主要目标就是减少慢速存储器给处理器内核造成的存储器访问瓶颈问题的影响。

cache经常与写缓冲区一起使用。写缓冲器是一个非常小的先进先出FIFO存储器，位于处理器核与主存之间。使用写缓冲器的目的是，将处理器核和cache从较慢的主存写操作中解脱出来。

cache是一个法语单词，意思是隐蔽的存储场所。将cache使用到ARM嵌入式系统中，这个定义就显得更加贴切了。cache存储器和写缓冲区（这个写缓冲器没见过）加到处理器内核上之后，**对软件代码的执行是透明的**。（由协处理器实现对cache的访问，协处理器有自己的指令，所以和汇编指令无关）这样在一个拥有cache的处理器内核上运行以前写的软件时，代码就不需要重新编写。虽然cache和写缓冲器都有附加的控制硬件，可以**自动处理**主存和处理器之间的代码和数据的传送，但是了解处理器cache的设计细节，可以**帮助编程人员在特定的ARM核上编写出执行更快的程序**。

本章主要描述cache能做的许多有效的工作，以使程序执行得更快。但是在系统中使用cache是否会带来其他弊端呢？答案是肯定的，其中最主要的弊端就是，很难判断一个程序的执行时间。下面将对此做出解释。

因为cache存储器只提供了主存中非常少的一部分数据，在程序执行过程中，cache会很快被填满。一旦被填满，cache控制器就会频繁地从cache存储器中移出原来的代码和数据，以给新的代码和数据留出存储空间。这种移出操作一般是随机发生的，它会留下一部分数据而将其他部分移出。这样，在任何一个给定的时刻，某个数值可能在cache中，也可能不在。

既然数据在任何一个给定的时刻可能在cache中，也可能在主存中，由于直接使用cache中的数据和从主存中装载cache的一行数据所需时间不一样，因此一个程序每次执行所需时间就会有轻微的差别。

本章将介绍cache在标准的存储层次中所处的位置，以及存储器访问的局部性原理，以此来解释cache是如何改善系统性能的；然后简单介绍一下cache的体系结构，并定义一系列ARM常用术语；最后，提示一些示例代码，实例如何清理和清除cache，以及如何将代码段和数据段锁定在cache中。

写缓冲器和cache在存储层次上处于同一层次，只是在进行**主存写操作时才使用写缓冲器**。

### 12.1存储层次和cache

第一章介绍了计算机系统中的存储器分层结构，下图更好地显示了cache和写缓冲器在存储器层次结构中所处的位置。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686448632263.png" alt="1686448632263" style="zoom:25%;" />

存储层次的最顶层在处理器内核中。该存储器与处理器的结合非常紧密，以致在很多情况下，很难将二者分开。该存储器被称为寄存器文件。这些寄存器被**集成在处理器内核中**，在系统中提供最快的存储访问。

接下来是一级存储器，**存储部件与处理器内核通过专用的片上接口**连接起来。紧耦合存储器TCM和一级cache就在这一层。后面会介绍更多关于cache的内容。

主存也在第一级里，包含一些易失性存储器（掉电后数据会丢失）存储器，比如SRAM、DRAM以及一些非易失性存储器比如Flash存储器。主存的主要任务就是承载在系统运行着的程序。（就是内部ROM和内部RAM）

在下一层是二级存储器（辅助存储器），即低速的相对较便宜的大容量存储设备，比如硬盘存储器和可移动存储器。在这一层里，还有从外设得到的数据，访问时间特别长。二级存储器用来存储正在运行的较大程序的未被使用的部分（由于程序过大，不适合将全部程序都放在主存中），或者存放当前没有运行的程序。

需要指出的是，存储层次结构不但依赖于体系结构的设计，也依赖于相关的工艺和技术。例如TCM和SRAM在技术上相同（其实TCM就是一种SRAM），但在结构排列上不同：TCM在片上，SRAM在板上。（TCM集成到SOC上了，这个SRAM我以为是内部的存储器，确实，如果是MCU就是内部存储器了，SOC这边不一定）

在存储层次中，cache可以被放置于存在明显访问速度差异的任何层次上，并且可以改善系统性能。cache存储器系统把存储层次中较低层次的信息取出，并把他们临时存放到较高的层次中。

上图中包含了一个L1cache和一个写缓冲器。L1cache是一个高速片上存储阵列，用来临时承载底层存储器中的程序和代码。cache所装载的信息可以缩短访问指令和数据所需的时间。写缓冲器则是一个容量很小的FIFO缓冲器，其主要作用就是**对由cache中写到主存的数据提供缓冲**。（也就是说cache和主存中还隔着一层写缓冲器）上图中没有把L2cache标记出来，他应该位于**L1cache和更底层的存储器之间**。通常也把L1cache和L2cache分别称作一级cache和二级cache。

下图可以看出cache与主存储器系统和处理器内核之间的关系。图的上半部分是一个没有cache的系统，处理器内核以自己支持的数据类型方式直接访问主存。图的下半部分是一个带有cache的系统，cache的存取速度比主存快得多，这样处理器内核对数据的访问请求可有快速的响应。cache与主存的关系主要体现在高速cache和低速主存间传送小块数据上。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686450785711.png" alt="1686450785711" style="zoom:50%;" />

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686450800953.png" alt="1686450800953" style="zoom:50%;" />

这样的小块数据被称作cache行（cache和主存之间是块传输cache行，和写缓冲器也是传输cache行）。写缓冲器作为临时缓冲器帮助cache释放存储空间，即从cache中搬出的数据暂存在写缓冲器中。cache控制器将cache行以较高的速度放到写缓冲器中，之后写缓冲器以较低速度将该cache行写入主存中。

###### cache和存储器管理单元

如果带cache的处理器内核支持虚拟存储，那么cache就可以被放在处理器内核与存储器管理单元MMU之间，或者在MMU与物理存储器之间。cache放置在MMU之前或之后，决定了cache的寻址范围和编程结构（程序员看到的cache总线结构以及存储的是虚拟地址还是物理地址）。下图显示了cache在系统中的不同位置带来的差异。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686451413308.png" alt="1686451413308" style="zoom:50%;" />

下图是物理cache的存放位置

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686451446352.png" alt="1686451446352" style="zoom:50%;" />

逻辑cache在虚拟地址空间存储数据，它位于处理器和MMU之间。处理器可以直接通过逻辑cache访问数据，而无须通过MMU。逻辑cache又称为虚拟cache。

物理cache使用物理地址存储数据，它位于MMU和主存之间。当处理器访问存储器时，MMU必须先**把虚拟地址转换成物理地址**，cache存储器才可以向内核提供数据。

带有cache和MMU的ARM处理器中，从ARM7到ARM10，包括Intel StrongARM和Intel XScale处理器，都使用逻辑cache。ARM11处理器系列使用物理cache。

使用cache来改进性能是可行的，因为计算机程序的执行并不是随机的。程序执行的可预测性是cache系统成功的关键。如果程序对存储器的访问是随机的，那么cache对整个系统的综合性能几乎不会有什么改进。（无非就是多了一点内存而已）存储器访问的局部性原理可以很好地解释为什么在系统中加入cache可以改善性能。这个原理表明：程序在执行过程中会频繁地运行小范围的循环代码，而这些循环又会对数据存储器中的局部区域反复访问。

对存储器中相同或邻近的数据和代码反复使用，是cache改善性能的主要原因。处理器在第一次访问存储器时，将相关数据和程序加载到cache中，使随后的访问速度大大提高。对高速cache的重复访问改善了系统的性能。

cache同时使用了时间和空间的局部性原理。如果对存储器的访问受时间影响，在时间上有连续性，则这种时间上密集的访问被称为时间局部性访问；如果多次对存储器访问的地址相近，则这种空间上邻近的访问被称为空间局部性访问。

### 12.2cache结构

带有cache的ARM内核采用了两种总线结构：冯·诺依曼结构和哈佛结构。这两种总线结构的区别在于，是否在内核与主存之间将指令和数据通道分离。分别有不同的cache设计来支持这两种结构。

在使用冯·诺依曼结构的处理器内核中，只有一个数据和指令公用的cache。这种类型的cache被称作统一cache，他可以存储指令和数据。

哈佛结构将指令总线和数据总线分离，以改善系统的综合性能，但是支持两种总线需要两种cache。所以在使用哈佛结构的处理器核中，存在两种cache：指令cache(I-cache)和数据cache(D-cache)。这种类型的cache被称为分离cache。在分离cache中 ，指令被存储在指令cache中，而数值被存储在数据cache中。

可以通过图12.4中的统一cache来了解cache的基本结构。cache的两个主要组成部分是cache控制器和cache存储器。cache存储器是一个专用的存储器阵列，其访问单元称为cache行。cache控制器**使用处理器在访问存储器时所提供的地址的不同段**，以选择cache存储器的不同部分。（同样是32位地址访问cache，只不过将这个32位地址划分不同段来找到对应的cache不同的部分）

下面将介绍cache存储器的结构，接下来介绍cache控制器的一些细节。

简单地说就是32位的地址其中[32:12]作为标签检查cache是否命中，[11:4]作为组索引号查找是哪个cache行，[3:0]是数据索引，因为cache行是由4个32位字组成，也就是128位，而处理器内核查找单位是一个存储单元也就是8位，所以128/16=8，需要4位指向每个存储单元。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686453634268.png" alt="1686453634268" style="zoom:50%;" />

#### 12.2.1cache存储器的基本结构

上图的右侧是一个简单的cache存储器，她有3个主要部分：目录存储段、状态信息段和数据项段。每一个cache行都由这3部分来表示。

cache必须知道cache存储器中的**每个cache行所对应于主存内的位置**，cache使用目录存储段来记录每个cache行是由主存的什么地方拷贝而来的。该目录项被称作cache标签。

同样，cache存储器必须存储来自主存的信息，这些信息被放在数据项段里。cache的大小是**由cache可以存储的主存中实际数据和代码的大小决定的**。在计算cache容量时，**用来存储cache标签和状态信息位不计算在内**。

在cache存储器中，还有用来记录状态信息的状态位。2个常见的状态位是有效位(valid bit)和脏位(dirty bit)。有效位用来标记当前的cache行是活动的，即该cache行中包含最初从主存中取得的数据，并可以为处理器内核所用。脏位则用来标记该cache行中所含的内容与主存中相应的内容是否一致。（Linux内核采用双向循环链表来维护页面，同样也有脏位和有效位）

#### 12.2.2cache控制器的基本操作

cache控制器是一种硬件，它将主存中的数据或者代码自动拷贝到cache存储器中，cache控制器在不为应用软件所知的情况下，**自动完成搬移工作**。（不受软件 约束）所以，同一个应用软件不做修改，就可以在有cache和没有cache的系统中运行。

读写存储器的请求在被传送到存储器控制器之前，会被cache控制器截获，cache控制器将该请求的地址信息分成3部分，标签域、组索引域、数据索引域。3个位域如上图所示。

首先，控制器通过组索引域在cache存储器中确定可能包含所要求的代码和数据段cache行的位置，也就是确定某一cache行。cache行中还包含cache标签和状态位，控制器就是通过他们来确定数据的实际存储位置的。（也就是说先确定行、然后在看是否命中）

接下来，控制器检查有效位，以确定该cache行当前是否处于活动状态，并且将请求地址的标签域的值与cache标签比较。如果cache行当前是活动的，并且标签域与cache标签的值也相同，则cache命中，否则失效。

在cache失效的情况下，控制器从主存中拷贝整个cache行到cache存储器中，为处理器核提供相应的代码或数据。这种拷贝整个cache行的操作被称为cache行填充。（类似于缺页处理）

在cache命中的情况下，控制器直接从cache存储器中为处理器核提供数据和代码。控制器使用数据索引域，在cache行中选择实际的代码或数据，并将其提供给处理器内核。

#### 12.2.3cache和主存的关系

对cache存储器的基本结构和cache控制器的工作原理有了一定的了解后，就可以讨论cache与主存的关系了。

下图显示了主存中的部分内容和如何被临时存放在cache存储器中。此图所示为最简单的cache形式-直接映射cache。（计组中提到过多种映射方式，会导致抖动）在一个直接映射cache中，主存中的每个地址都对应cache存储器中唯一的一行。由于主存的容量要远远大于cache存储器，所以在主存中有很多地址被映射到同一个cache行。下图可以看出这种关系，所有以0x824结尾的内存地址都映射在同一cache行。

之前介绍的地址信息的3个域：标签域、组索引域和数据索引域，在下图仍然可以体现出来。组索引域可以确切地指出所有以0x824结尾的内存地址在cache中所唯一对应的存储地址；数据索引域可以确定字、半字或者字节在该cache行中的位置，在本例中是cache行中的第二个字；标签域则用来与cache行中的cache-tag相比较。

![1686464400547](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686464400547.png)

在本例中，cache中的每一行对应着100w个内存地址。在任一给定适可而止，这些地址中只有一个地址的内容可以出现在cache存储器中。将主存地址的标签域与cache行中的cache标签相比较，可以确定该cache行中是存储了处理器所要访问的主存单元数据，还是存储了另外一个地址以0x824结尾的主存单元数据。

在cache行被填充时，cache控制器可以在向cache中搬运数据的同时，将数据传送到处理器内核中，**这被称为数据流注**。数据流注允许处理器一边执行程序，cache控制器一边向相应cache行中搬运剩余的数据和代码。

如果在某一cache行中的数据虽然是有效的，但是与之对应的是主存中其他的地址块，而非处理器所要求的地址，那么整个cache行中内容将被删除，并被替换为与处理器内核所要求的地址相对应的cache行。这种移动一个有效cache行的过程，是cache失效处理的一部分，被称作替换，即将cache行中的内容返回到所对应存储单元中，留出空间给需要加载到cache的新的数据。

直接映射cache是一种简单的解决方法，但是这种设计使得每个主存块在cache中只有一个特定的行可以存放，如果程序同时用到对应于cache同一行的2个主存块，那么就会发生冲突，冲突的结果就是导致cache行的频繁置换。这就是关于直接映射cache的颠簸问题，cache存储器中同一位置的软件冲突。

下图所示为一个简单的软件循环在cache中频繁置换的过程。该程序在一个do-while循环中反复调用两个子程序，每个子程序都拥有相同的组索引域地址，所以这两个子程序在主存中的物理地址会映射到cache中相同的行。当第一次执行该循环并执行到子程序A时，A被调入到cache行中，接下来当执行到子程序B时，A所在的cache行被替换，同时B被放入该行，并开始执行。当第二次循环执行到A时，A又把B从cache中替换出来，接着B再把A置换出去。重复的cache失效导致cache控制器连续不断地将当前不用的程序置换出cache，这就是cache颠簸。

#### 12.2.4组相联

某些cache使用其他的设计方式，可以减少cache的颠簸频率。这种设计改变了cache的构造：将cache存储器分成了一些相同容量的小单元，称作路。下图仍然是一个4KB的cache，但是与前面所讲的cache不同的是，一个组索引域对应于多个cache行，即在每一路中都有一个cache行与之对应。前面所讲的4KB容量的cache分为256行，现在把cache分成4路，每路有64个cache行。组索引域相同的四个cache行被称作处于同一个组里，这也是组索引的命名的由来。

拥有相同组索引的cache行称为组相联的。主存中的数据或者代码块可以在不影响程序执行的情况下被分配到组相联的任意一路中。换句话说，将数据或者代码存入cache行中的操作不会影响程序的执行。当主存中两个顺序的块被置换到cache中时，可以被放在同一路的连续cache行中，也可以被放在不同路中。需要注意的是，主存中特定位置的代码或者数据被读入到cache时，可以被存放在同一个组的任意cache行中。在cache的同一个组当中，**数据放置的位置具有排他性**，（因为你们已经同一组了，组索引号相同，如果此时数据也相同，那该如何分辨呢）可以防止同样的数据被重复放在一个组的不通过的cache行。

在4个way的组相联cache中，主存到cache的映射与以前不同。主存中的一个地址现在可以映射到cache中的4个不同地址。（因为组索引号现在是6位，只能对应64个cache行，所以一个256行现在只能分成4份，才能完整对应64行，）

下图中tag域比以前多了2位，而同时组索引域比以前少了两位。这意味着主存中的400w地址映射到cache一个组中的四个cache行中，而不是100w主存地址映射到一个cache位置。（毕竟现在4个cache行随便选）

现在，主存映射到cache中的大小是1KB而不是4KB。这意味着将数据块映射到同一组的cache行的可能性比以前增加了4倍，同时一个cache行被替换的概率也减小为原来的1/4。（之前相当于同一组中只有一个）

如果之前的实例程序代码在4个way的组相联cache中运行，那么cache失效的可能性会大大降低。子程序A、子程序B和数据组会分别被存储在一个组的4个可能位置中的一个。当然，这是假设每个子程序和数据组的大小要小于从主存中映射过来的1KB空间。（毕竟现在地址对应了四个cache行中的字节）

###### 提高相连度

随着cache控制器的相联度提高，冲突的可能性减小了。理想的目标是，尽量提高组相联程度，使主存地址能够映射到任意cache行。这样的cache被称为全相联cache。然而，随着相联度的提高，与之相匹配的硬件的复杂程度也在提高。硬件设计者提高cache相联度的一种方法就是**使用内容寻址存储器CAM**。

CAM使用一组比较器，以比较输入的**标签地址**和存储在每一个有效cache行中的**cache-tag**。CAM采用了与RAM相反的工作方式：RAM是得到一个地址后再给出数据；而CAM则是在检测到给定的数据值在存储器中后，再给出该数据的地址。使用CAM允许同时比较更多的cache-tag，从而增加 了可以包含在一个组中的cache行数。（因为同一组中的排他性必须保证每个cache行内容不同）

在ARM920T和ARM940T中的cache是64路组相联的。下图为ARM940T的cache结构图。cache控制器把地址标签作为CAM的输入，他的输出选择了**包含有效cache行的路**。这里就是根据地址标签作为内容找到对应不同组但相同标签的cache行，然后根据2位的组索引号找到对应的组。

访问地址的tag部分被作为**4个CAM**（每个CAM负责一组中cache行的比较）的输入，输入标签同时与存储在64路中的所有cache标签相比较。如果有一个匹配，那么数据就由cache存储器提供；如果没有匹配，存储器控制器就会产生一个失效信号。

控制器使用组索引位来选择4个CAM中的一个。被选中的CAM会在cache存储器中国选择一个cache行，该地址的数据索引部分在该cache行中选择出需要的数据。（因为路数，代表一个地址指向的cache行的行数，保证了地址的被选中的概率更大，同一个组索引号为一组，此时组内的cache行多了起来，就需要辨别，使用CAM找出一组中的对应标签。然后确定是哪个CAM也就是哪组的）

#### 12.2.5写缓冲器

写缓冲器是一个容量非常小的高速FIFO存储缓冲器，用来临时存放处理器将要写入到主存中的数据。在没有写缓冲器的系统中，处理器直接写数据到主存中。在带有写缓冲器的系统中，数据先高速写入FIFO，然后再写入低速的主存中。写缓冲器缩短了写小块序列数据到主存时的处理器时间。写缓冲器中的FIFO存储器在存储层次中与L1 cache处于相同的层次。(除非写缓冲器不需要CPU帮助就可以低速写入主存中)

写缓冲器同时还改善了cache的性能，这体现在cache行被替换时。当cache控制器要置换出一个脏的cache行时，它只将该cache行放入写缓冲器中，而不写入主存中。这样，可以更快速填充新的cache行数据（对于cache而言高速交给FIFO即完成任务，可以进行填充了），处理器可以继续从cache存储器中读/写数据。

写缓冲器中的数据在没有被写入主存之前，是**不能被读取**的。同样，被替换的cache行在写缓冲器中时也不能进行读操作。这也是为什么写缓冲器的FIFO深度通常比较小的原因之一。一般只有几个cache行的深度。（对于这种黑箱操作肯定是越少越好）

有些写缓冲器并不是严格的FIFO缓冲器。例如ARM10系列支持接合--把写操作合并到一个单一的cache行。也就是说，写缓冲器会把新的数值合并到一个在写缓冲器中已存在的cache行。接合又被称为写合并。

#### 12.2.6cache效率的衡量

有2个性能指标可以衡量一个程序的cache效率：cache命中率和cache失效率。在给定的时间间隔内，cache命中的次数与总的存储器请求次数的比值称为命中率。命中率可以用下面的百分数来表示：

失效率和命中率形式相似：在给定的时间内，cache失效的总次数除以总的存储器请求次数所得的百分数。失效率与命中率之和为100%。

命中率和失效率可以衡量数据的读/写，或者同时衡量读写两者的效率。也就是说这两个指标可以从几个方面来描述系统的性能情况。例如：可以计算读数据的命中率、写数据的命中率，或者其他方面操作的命中率和失效率等。另外两个衡量cache性能够的指标是命中时间和失效开销。命中时间是指处理器访问cache中数据时所需的时间。失效开销是指处理器从主存中装载一个cache行到cache所需的时间。

### 12.3cache策略

有3种可以决定cache操作的策略：写策略、替换策略以及分配策略。cache的写策略决定了处理器执行写操作时数据存放的位置。替换策略在cache失效的情况下，决定选择被替换出主存的cache行。分配策略决定cache控制器在何时将要分配cache行。

#### 12.3.1写策略-直写法或回写法

处理器核向存储器写数据时，cache控制器可以有2种可选择的写策略。他可以同时向cache行和相应的主存位置中写入数据，将存储在2个位置上的数据一起更新，这种做法被称为直写法。另外它也可以只把数据写入相应的cache行，而不写入内存，只有当相应cache行被替换或者清理cache行时，才被写入主存，这种做法被称为回写法。

##### 12.3.1.1直写法

如果cache控制器使用直写策略，那么处理器核写cache命中时，将同时修改cache和主存中的内容，以确保cache和主存数据的一致性。在这种策略下，处理器核在每次写cache时也要写相应的主存单元。由于要访问主存，直写法的速度比回写法慢。

##### 12.3.1.2回写法

如果cache控制器使用回写策略，那么处理器核写cache命中时，只向cache存储器写数据，而不立即写入主存。这样，主存块与相应的cache行数据有可能不一致。cache中的数据是最新的，而主存中的数据可能是较早的、没有被更新过的。

配置成回写法的cache要使用到cache行的状态信息块中的一个或多个脏位。当回写cache控制器向cache存储器中某一行写入数据时，他将脏位设置为1。如果控制器内核此后访问该cache行，那么通过脏位的状态就可以知道该cache行中含有主存中没有的数据。如果cache控制器要将一个脏位被置位的cache行替换出cache存储器，那么该cache行数据会自动被写到主存单元中去。控制器通过这种方式来防止只存在于cache中而主存中没有的重要信息的丢失。

当一个程序频繁使用某些临时的局部变量时，由于这些变量是临时的，所以根本用不着被写入主存中。此时回写法cache优于直写法。例如，当寄存器文件没有足够的寄存器来存放临时局部变量时，就会导致部分变量溢出到一个cache堆栈中（cache堆栈，这里就是说存放到cache中），这些临时变量就不需要写入主存。

#### 12.3.2cache行替换策略

当一个cache访问失效时，cache控制器必须从当前**有效的组**中选择一个cache行来存储从主存中取得的新信息。被选中替换的cache行被称为丢弃者。如果丢弃者中包含**有效的脏数据**（如果是无效直接清除了），那么在该cache行被写入新数据之前，控制器必须把该行中的数据写到主存。选择和替换丢弃cache行的过程被称为淘汰。

cache控制器选择下一个丢弃cache行的策略被称为淘汰。

cache控制器选择下一个丢弃cache行的策略被称为替换策略。cache替换策略从当前**有效的相联组**中选择一个cache行。也就是说他选择一路用于下一次cache行替换。总的来说，组索引域在各个way中选择可用的一组cache行；而替换策略决定在该组中的哪一个cache行被新的数据所替换。

带cache的ARM核支持两种替换策略：伪随机替换法和轮转法。

- 轮转法又叫循环替换，这种方法只是简单地将当前分配cache行的下一行作为被替换的行。它所采用的选择算法使用了连续加1的丢弃计数器，该计数器在每一次cache控制器分配新的cache行时都会自动加1。当丢弃计数器计数达到最大值时，就被复位成预先定义好的一个基值。
- 伪随机替换法从特定的位置上随机地选出一行替换出去。该算法使用了**非连续增加的丢弃计数器**，控制器随机产生一个增加值，并将该增加值加到丢弃计数器上。同样，当丢弃计数器计数达到最大值时，会被复位成预先定义好的一个基值。（可能cache未完全满时开始丢弃）

大多数ARM核都支持这两种替换策略。相比之下，轮转法替换策略有更好的可预测性，容易预测最坏情况下cache的性能，这在嵌入式系统中是很必要的；然而，轮转法替换策略在存储器访问发生很小的变化时，就对cache性能造成较大的变化。

例12.1说明分别使用轮转和伪随机替换策略运行一个程序所耗费的时间。测试程序cache_RRtest使用C库文件header.h中的时钟函数来计算时间。程序先用轮转策略进行时间测试，然后使用随机策略进行了相同的测试。

测试程序readSet是基于ARM940T的。该程序使用轮转替换策略，并故意显示了一种cache性能的最坏的突变。

```c
#include <stdio.h>
#include <time.h>
void cache_RRtest(int times,int numset)
{
    clock_t count;
    printf("Round Robin test size=%d\r\n",numset);
    enableRoundRobin();
    cleanFlushCache();
    count=clock();
    readSet(time,numset);
    count=clock() - count;
   	printf("Round Robin enabled = %.2f seconds\r\n",
          (float)count/CLOCKS_PER_SEC);
    enableRandom();
    cleanFlushCache();
    count = clock();
    readSet(times,numset);
    count = clock()- count;
    printf("Random enabled = %.2f seconds\r\n",
          (float)count/CLOCKS_PER_SEC);
}
int readSet(int times,int numset)
{
    int setcount,value;
    volatile int *newstart;
    volatile int * start = (int *)0x20000;
    __asm
    {
        timesloop:
        	MOV newstart,start;//开始地址
            MOV setcount,numset;//组内读取的数据个数
        setloop:
        	LDR value,[newstart,#0];//将地址中的内容送入value中
             ADD newstart,newstart,#0x40;//
                SUBS setcount,setcount,#1;//读取一个组内cache行的次数
                BNE setloop
                SUBS times,times,#1;//读取几个组
                BNE timesloop
    }
    return value;//最后一个读取的数
}
```

上面这个代码没看懂，但我好奇的是这个newstart读取的是主存里的数据么，访问cache控制器应该是由协处理器管理吧。虽然处理器核确实是发送和主存同样的地址信号给cache控制器。

还有一种替换策略是最近最少使用策略LRU。该策略记录cache行的使用情况，将近期内最长时间未被访问过的cache行替换出cache。（页面是采用了两个循环链表管理，一个是活跃，一个是不活跃链表LRU/2）

带cache的ARM核不支持最近最少使用策略，但是有些ARM的半导体合作伙伴在其制造的芯片中将自己的cache加到不带cache的ARM核中。所以有些基于ARM的产品支持最近最少使用策略。

#### 12.3.3cache失效时的分配策略

在cache失效发生时，ARM的cache可以采取两种策略来分配cache行：第一种叫做读操作分配策略；第二种叫做读/写操作分配策略。

如果cache未命中，那么对于读操作分配策略，**只有进行存储器读操作时，才分配cache行**。如果被替换的cache行包含有效数据，那么在该行被新的数据填充之前，要先把其原来的内容写入主存中去。

采用读操作分配策略时，存储器写操作并不会更新cache存储器中的内容，除非相关的cache行恰好是前一个主存读操作刚刚分配的。如果这个cache行中包含有效数据，那么在采用直写策略时，写操作更新cache的同时，还会更新主存中的相应内容。如果写操作的对象不在cache中，那么写操作只更新主存中的相应内容。

采用读/写操作分配策略时，不管是存储器读操作，还是存储器写操作，在cache**未命中时都会分配**cache行。对于主存的**任何写操作**，如果操作对象不在cache中，那么cache控制器也会**分配**一个新的cache行，并把主存中的相应内容填充到该cache行。对于存储器**读操作**，cache控制器运用**读操作分配策略**。

当内核进行数据写操作时，如果cache未命中，那么cache控制器将会分配一个cache行。如果被替换出的cache行中包含有效数据，那么在主存将新的内容放入该cache行之前，控制器将会改行的内容先写入主存。如果该行的数据无效，那么它将直接被主存中的新数据覆盖。分配的cache行被填充后，控制器才将内核数据写到该cache行的相关位置。对于直写cache，数据将会同时被写入到主存中。

这里学的策略感觉没啥用，写操作分配和读操作分配有啥区别。

### 12.4协处理器15与cache

协处理器15(CP15)的一些寄存器是专门用来配置和控制带cache的ARM内核的。下表列出了控制cache配置的协处理器15寄存器。CP15的主寄存器c7和c9控制着cache的设置和操作。辅寄存器CP15:c7是只写的，**控制清除或清理cache**；CP15:c9定义将被替换的**丢弃者指针的基地址**，该基地址决定了锁定在cache中的代码和数据的行数。

还有其他一些影响cache操作的CP15寄存器，这些寄存器的定义依赖于内核。这些寄存器的内容后续介绍。

在接下来的几节中，将使用下表中列出的CP15寄存器编写清理和清除cache的示例程序，并在cache中锁定代码和数据。控制系统通常调用这些子程序作为存储管理的一部分。

只要分配了cache行，即使是内核执行写操作，cache控制器也先要把主存的相关内容复制到所分配的cache行，内核数据才能写入该cache行中。

下表是配置和控制cache操作的协处理器15寄存器

| 功能            | 主寄存器 | 辅寄存器             | 操作码（Opcode）2 |
| --------------- | -------- | -------------------- | ----------------- |
| 清理和清除cache | c7       | c5,c6,c7,c10,c13,c14 | 0,1,2             |
| 排空写缓冲器    | c7       | c10                  | 4                 |
| cache锁定       | c9       | c0                   | 0,1               |
| 轮转法替换      | c15      | c0                   | 0                 |

### 12.5清除和清理cache

ARM使用术语清除flsuh和清理clean表示对cache的两种基本操作。

清除cache的意思是清除cache中存储的全部数据。对处理器而言，清除操作只要清零相应cache行的有效位即可。（这里的有效位就是活跃，变成不活跃就会被清除）然而，对于采用回写策略的D-cache，就需要使用清理操作。

清理cache的意思是把脏的cache行强行写到主存，并把cache行中脏位清零。清理cache可以**重建cache与主存之间的一致性**，他只用在使用回写策略的D-cache上。（指令存放在只读代码段，无法修改所以不需要考虑一致性问题，所以只考虑数据cache，指令应该不需要修改）

改变系统的存储器配置可能需要执行清除和清理cache的操作。访问权限、cache和缓冲策略的变化或者重新映射虚拟地址等（对于虚拟cache是这样的）

在**分离cache**中执行**自修改代码**之前，cache也需要执行清理和清除操作。自修改代码包括将**代码简单地从一个地方拷贝到另一个地方**。（这里指的是代码被复制到另一处，而不是数据，所以称为自修改代码，代码修改其他代码）

清理和清除操作是由两种可能的情况引起的：第一种，自修改代码可能被承载在D-cache中，因此，不可能作为一条指令从主存中进行加载；第二，I-cache中现存的指令可能会屏蔽写到主存中的新指令。（就是说代码放在D-cache当成数据了，就不能作为指令被执行，或者放在I-cache中指令会将在主存中的代码屏蔽掉，这种情况下就需要清除）

如果cache使用回写策略并且自修改代码被写入主存中，那么第一步就是将指令以数据块的形式写到主存中的某处；稍后，程序跳转到主存中，以指令流的形式从主存中的该处开始执行。（这里意思就是把主存中的该处作为指令地址送入pc中）其中，当代码作为数据写入到主存中时，如果cache存储器中代表自修改代码被写入的主存位置的cache行有效，那么代码有可能会被写入到cache中而不是写入到主存。这些cache行会被拷贝到D-cache，而不是拷贝到主存。如果发生了 这种情况，那么当程序跳转到自修改代码所在地方时，就会执行原来数据表示代码，因为自修改代码此时还在D-cache中。为了防止这种情况发生，可以进行D-cache的清理操作，把指令代码强制作为数据存到主存中，从而这些数据就可以作为指令流从主存中被读取出来。

D-cache被清理后，新的指令就被写入主存中。但是，I-cache中可能会有有效cache行存储新数据地址对应的指令。接下来，在新代码所在的地址读取指令时，仍然会得到I-cache中的老代码，而不是主存中的新代码。清除I-cache可以防止发生。

---

这一小节，我没看懂，好像是在说代码被存入D-cache中当成数据的解决方法，以及代码本身的自修改代码。

---

#### 12.5.1清除cache

清除cache，即使cache中的内容无效。如果cache使用回写策略，那么在清除前应该清理cache，防止由于清除操作使数据丢失。

有三个CP15:c7命令可以在cache中执行清除操作：第一个清除整个cache；第二个只清除I-cache；第三个只清除D-cache。这些命令以及支持他们的内核见下表，对于这3个MCR指令，处理器内核寄存器Rd的值应该为零。

| 命令          | MCR指令                                                      |
| ------------- | ------------------------------------------------------------ |
| 清除cache     | MCR p15,0,Rd,c7,c7,0;//对cp15协处理器进行操作，内核寄存器是Rd，主寄存器是c7，辅助寄存器是c7，一二号操作码0，将Rd内容写入协处理器CP15的主寄存器+辅寄存器中 |
| 清除数据cache | MCR p15,0,Rd,c7,c6,0                                         |
| 清除指令cache | MCR p15,0,Rd,c7,c5,0                                         |

例12.2显示了如何使用这3条指令清除cache。下面示例中包含一个产生3个例程的宏。

- flushICache
- flushDCache
- flushCache

这些 没有输入参数，使用以下的原型从C程序中调用：

```c
void flushCache(void);
void flushDCache(void);
void flushICache(void);
```

例12.2本例首先根据所支持的不同命令将内核分组。

这里使用一个名为CACHEFLUSH的宏来创建例程。这个宏先设置内核寄存器，将0写入CP15:c7:Cm。接下来根据需要的cache操作的类型和不同的内核，插入特定的MCR指令。

```c
IF {CPU}="ARM720T";
```

最后，多次使用宏创建例程。ARM720T具有指令-数据统一cache，所以只使用flushCache例程即可。对于其他内核，3次使用宏来创建3个例程。

也可以使用内嵌汇编实现

```c
__inline void flushICache926(void)
{
    unsigned int c7format = 0;//在汇编中c7format是RN 0也就是r0寄存器，这里无参数、无返回值，有一个局部变量，默认是使用r0来存储，倒也合理，并且函数执行完C编译器自动加上MOV pc,lr
    __asm{MCR p15,0,c7format,c7,c5,0};
}
```

#### 12.5.2清理cache

清理cache即执行指令，命令cache控制器将所有带有脏位的D-cache行写入到主存中去。在这个过程中，cache行中 脏位将被清除。清理cache操作可以重建cache和主存之间的数据一致性。此操作仅适用于使用回写策略的D-cache。

术语回写和回拷在一些地方也通常表示清理的意思。这些术语与描述cache写策略的用词相近，但在这种情况下，他们描述的是对cache存储器所做的操作。在非ARm系统中，术语刷新往往与ARM系统中清理意思相同。

#### 12.5.3清理D-cache

到本书截稿为止，有3种清理D-cache的方法。具体的处理方法与处理器有很大关系，因为不同的处理器内核有各自不同的指令来清理D-cache。

下表是清理D-cache的方法

| 方法                             | 示例 |
| -------------------------------- | ---- |
| 路和组索引寻址                   |      |
| 测试清理                         |      |
| 读某一特定存储器块的特殊分配策略 |      |

虽然清理cache的方法有很多种，但在下面的例子中，会提供相同的过程调用，为所有的内核提供一致性的接口。这里给出了3个程序来清理整个cache，cache会在每次清理之前做一次写操作：

- cleanDCache
- cleanFlushDCache;清理并清除D-cache
- cleanFlushCache清理并清除D-cache和I-cache

CleanDCache，cleanFlushDCache和cleanFlushCache三个过程不需要输入参数，并且可以在C程序中以下面的形式来调用。

在编写这些例子中的宏时，应使他们不需要做大量修改就可以支持尽可能多的ARM内核。为了达到这个目的，在本例中和本章的其他例子中，使用了一个通用的头文件，文件名位cache.h，见以下程序：

```assembly
IF{CPU} = "ARM920T"
CSIZE EQU 14
CLINE EQU 5
NWAY EQU 6
I7SET EQU 5
I7WAY EQU 26
I9WAY EQU 26
ENDIF
SWAY EQU (CSIZE - NWAY)
NSET EQU (CSIZE - NWAY - CLINE)
```

头文件中的值或者是用以2为底的对数表示的cache的大小，或者表示域位置指针。如果值表示的是一个位置指针，那么它代表CP15寄存器位域的最低位。如本例中的常量I7WAY指向CP15:c7:c5寄存器的way选择域最低位。有的是26；有的是30。数值以这种格式存储，可以支持使用MCR指令发出清理命令时，将内核寄存器R9数据向CP15:Cd:Cm寄存器搬移的位操作。

现将头文件中依赖于内核体系结构的6个常量分别列出：

下面这六个常量都是真正常量的左移值

- CSIZE，指**cache全部字节数**以2为基数取对数所得到的值。cache的容量就是1<<CSIZE个字节。这里进行左移后获得的是真实值
- CLINE，指**cache行中的字节数的左移量**以2为基数取对数所得到的值。cache行的长度为1<<CLINE个字节。
- NWAY，指**路way的左移量**，与组相联相同也就是同一个地址对应的cache行的数量。也就是同组内cache行的数量，这里的左移量指的是在32位中的第几位
- I7SET，**组索引在CP15:c7指令寄存器中左移的位数**。这个值也被用作顺序访问cache时，在CP15:c7寄存器中增大或者减小组索引部分的大小。
- I7WAY，路索引在CP15:c7指令寄存器中左移的位数。
- I9WAY，路索引在CP15:c9指令寄存器中左移的位数。

还有两个由内核特殊数据计算而来的常量：

- SWAY，一路中的字节数。
- NSET，指每路中的cache行数。实际上就是组索引的数量1<<NSET

#### 12.5.4使用路和组索引寻址清理D-cache

有些ARM内核支持用way和组索引寻址来确定某一cache行在cache中的位置，并清理和清除该单一的cache行。下表中以MCR指令实行列出了清理和清除一个cache行的命令个。有两个命令可以用来清除一个cache行：清除指令cache行和清除数据cache行。其余的2个命令用来清理D-cache：清理cache行和清除cache行。

| 命令                  | MCR指令               |
| --------------------- | --------------------- |
| 清除指令cache行       | MCR p15,0,Rd,c7,c5,2  |
| 清除数据cache行       | MCR p15,0,Rd,c7,c6,2  |
| 清理数据cache行       | MCR p15,0,Rd,c7,c10,2 |
| 清理并清除数据cache行 | MCR p15,0,Rd,c7,c14,2 |

列出的每个内核通过路和组索引寻址方式选定特定的某cache行。当使用这些指令时，在同样的ARM处理器内核上执行上这四条指令（之前说对于有cache和没有cache的ARM处理器上程序一样，但是这里却特意使用指令控制cache，是不是cache使用默认就不需要额外指令管理了），内核寄存器Rd中的值是相同的(都是32位地址)；但是不同的处理器的寄存器位域格式不同的。（就是cache结构不同，路和组索引号不同）下图为支持通过路寻址方式清理和清除一个cache行的ARM内核的CP15:c7:Cm寄存器格式。在内核寄存器Rd中以相应的CP15:c7寄存器格式创建一个数值，就可以执行这些命令。寄存器通常包含两个位域：选择路和该路中的组。一旦 寄存器被创建，执行相应的MCR指令就可以把内核寄存器Rd中的内容放到CP15:c7寄存器中。

在下面的例子中列出了在ARM920T、ARM922T、ARM940T、ARM946E-S和ARM1022E处理器上的cleanDCache,cleanFlushDCache和cleanFlushCache程序。

例12.3这里使用一个名为CACHECLEANBYWAY的宏创建使用路和组索引寻址方式清理、清除和清理清除cache的3个过程。

所定义的宏使用头文件cache.h中的常量以CP15:c7寄存器格式c7f为相应的处理器内核建立一个处理器寄存器。

- 第一步将c7f寄存器清零，在MCR指令中，这被作为Rd输入值来执行相应的操作；
- 接下来根据之前头文件的格式，每次写cache行都会增加一次c7f寄存器。组索引在内循环中增加，路索引在外循环中增加。使用嵌套的循环，就可以逐步清理所有路当中的所有cache行。

```assembly
AREA cleancachebyway,CODE,READONLY;Start of Area block
IF {CPU} = "ARM920T"
EXPORT cleanDCache
EXPORT cleanFlushDCache
EXPORT cleanFlushCache
INCLUDE cache.h
c7f RN 0
NACRO;伪操作标识宏定义的开始，下面作为宏定义体被调用
CACHECLEANBYWAY $op;这里的op将被替换成相应的标识
MOV c7f,#0;建立c7格式，对于清理和清除而言，设置0即可
IF "$op" = "Dclean"
MCR p15,0,c7,c10,2;清理D-cache
ENDIF
IF "$op" = "Dcleanflush"
MCR p15,0,c7f,c7,c14,2;清理并清除D-cache
ENDIF
ADD c7f,c7f,#1<<I7SET;组索引号+1，因为从第I7SET位开始才到组索引号范围
TST c7f,#1<<(NSET + I7SET);测试索引溢出，其实这里有点问题，1<<NSET=组索引大小，而I7SET是在32位中的左移值，这两者怎么能相加呢
BEQ %BT5;这里是跳转到%BT5是啥意思

BIC c7f,c7f,#1<<(NSET + I7SET);清除之前做测试的痕迹
ADDS c7f,c7f,#1<<I7WAY;丢弃者指针+1，这里I7WAY是标签范围的左移值。
BCC %BI5;如果小于，测试路溢出。
MEND;标识宏定义的结束
cleanDCache
	CACHECLEANBYWAY Dclean;Dclean替换op，调用宏定义体
	MOV pc,lr
cleanFlushDCache
	CACHECLEANBYWAY Dcleanflush
	MOV pc,lr
cleanFlushCache
	CACHECLEANBYWAY Dcleanflush
	MCR p15,0,r0,c7,c5,0;清除I-cache
	MOV pc,lr
ENDIF
```

这个代码说到底就是调用之前表中的指令，只不过是提供了清除还是清理D-cache的选择，并且会在清除清理之后测试下组索引和路索引是否溢出。

#### 12.5.5使用test-clean命令清理D-cache

两种较新的ARM内核可以使用test-clean测试清理CP15:c7寄存器清理cache行。test-clean命令是一条特殊的清理指令，他用在软件循环中可以非常有效地清理cache。这两种内核同样支持使用组索引和路索引来清理cache，但是使用test-clean命令清理cache可以更加高效。

在下面的程序中，使用下表的命令清理两个ARN内核。

| 命令                            | MCR指令                    | 支持的内核             |
| ------------------------------- | -------------------------- | ---------------------- |
| 通过循环测试清理D-cache行       | MCR p15,0,**r15**,c7,c10,3 | ARM926EJ-S,ARM1026EJ-S |
| 通过循环测试清理并清除D-cache行 | MCR p15,0,r15,c7,c14,3     |                        |

和之前非循环的方法相比MCR指令的二号操作码是2。

例12.4ARM926EJ-S和ARm1026EJ-S内核的cleanDCache,cleanFlushD-Cache和cleanFlushCache程序。

测试清理命令找到第一个带有脏位的cache行，将其中的内容传送到主存中，从而清理cache。如果在cache中还有其他的脏位，那么Z标志位就会被清零。

```assembly
IF {CPU} = "ARM926EJ-S"
	EXPORT cleanDCache
	EXPORT cleanFlushDCache
	EXPORT cleanFlushCache
cleanDCache
	MCR p15,0,pc,c7,c10,3;循环清理只能使用r15寄存器作为Rd
	BNE cleanDCache
	MOV pc,lr
ENDIF
```

清理cache可以通过创建一个使用test-clean命令的软件循环来实现。通过测试Z标志并跳转重复测试，处理器循环测试直到D-cache被清理。需要注意的是，test-clean命令使用程序计数器(r15)作为Rd寄存器到MCR指令的输入。

#### 12.5.6在Intel XScale SA-110和Intel StrongARM内核中清理D-cache

这两种处理器使用第三种方法来清理D-cache。前者有一种命令可以在D-cache中分配一行而不需要填充它。当处理器执行这条命令时，有效位被置1，并使用Rd寄存器提供的cache标签填充目录项。（相当于指定标签填充）并且，当这条命令被执行时，主存不会向cache传送数据。这样，cache中数据直到被处理器写操作时才会被初始化。下表中的分配命令有自动替换出脏cache行的优点。

Intel Xscale分配D-cache行的CP15:c7命令

| 命令                | MCR指令              | 支持的内核 |
| ------------------- | -------------------- | ---------- |
| 在数据cache中分配行 | MCR p15,0,Rd,c7,c2,5 | XScale     |

Intel StrongARM和Intel Xscale处理器需要附加的技术来清理cache。他们需要一块**专用的、未被使用的、且可cache的主存**（这里的意思是与cache交换内容的主存区域）**来清理cache**。通过相应的软件设计，可以使这个存储器块专门用作清理cache。

由于使用轮转替换策略，Intel StrongARM和Intel Xscale处理器可以通过读固定的主存块清理cache。如果一个程序的执行使处理器内核顺序读主存中与cache大小相同的一块，那么这一系列的读操作将会把所有当前cache行替换出cache，并把读取的数据块放到cache中。当顺序读操作结束时，**cache中不会包含任何重要的数据，因为专用的读块中没有有用的信息**。所以cache可以被清除而不用担心丢失有用信息。

可使用这种技术来清理Intel StrongARM的D-cache和Intel Xscale的迷你D-cache。这两个处理器的cleanDCache,cleanFlushDCache和cleanFlushCache过程的源程序在下面的例子中。其中的CleanMiniDCache是一个附加程序，用来清理Intel XScale处理器的D-cache。

例12.5本例使用了2个宏：CPWAIT和CACHECLEANXSCALE。CPWAIT是一个3指令序列，用以在XScale处理器上防止CP15操作的副作用。由于宏使用这些指令，所以有足够的处理器周期执行，从而确保CP15命令的完成并且流水线中已经没有指令。说的都是p话。

CPWAIT宏定义如下：

```assembly
MACRO
CPWAIT
MRC p15,0,r12,c2,c0,0;读取所有的CP15的寄存器
MOV r12,r12;
SUB pc,pc,#4;跳到下一条指令
MEND
```

这个CPWAIT宏不知道啥作用。

宏CACHECLEANXSCALE创建了cleanDCache,cleanFlushDCache和cleanFlushCache3个过程。宏的第一部分为程序设定了物理参数。第一个参数adr是用来清理cache的专用存储库的虚拟起始地址。（就是之前提到的可cache的存储空间，不过为啥是虚拟起始地址，这是虚拟cache吗）第二个参数nl是cache中cache行的总数。

```assembly
IF {CPU} = "XSCALE"
EXPORT cleanDCache
EXPORT cleanFlushDCache
EXPORT cleanFlushCache
INCLUDE cache.h

CleanAddressDcache EQU 0x8000;这个应该是主存中存储块的起始地址
CleanAddressMiniDcache EQU 0x10000;
adr RN 0;起始地址
nl RN 1;待处理的cache行数
tmp RN 12;临时寄存器
MACRO
CACHECLEANXSCALE $ op
IF "$ op" = "Dclean"
LDR adr,=CleanAddressDcache;将定义的地址送给adr
MOV nl,#(1 << (NWAY + NSET));这里括号打开了是乘法得到总的cache行数
ENDIF
IF "$ op" = "DcleanMini"
LDR adr,=CleanAddressMiniDcache;这是miniDcache对应的地址
MOV nl,#(1<<(NWAY + NSET))
ENDIF

IF {CPU} = "XSCALE":LAND:"$ op" = "Dclean";这里的意思就是and和or，前面的L可能是勿加的，网上搜不到
MCR p15,0,adr,c7,c2,5;分配D-cache行
ADD adr,adr,#32;这里地址+32就是偏移地址也就是0x20
ENDIF
IF {CPU} = "SA - 110":LOR:"$ op" = "DcleanMini"
LDR tmp,[adr],#32;装载数据，这里是先取址然后才偏移地址
ENDIF
SUBS nl,nl,#1;nl也就是cache行总数不断自减
BNE %BT5
IF {CPU} = "XSCALE"
CPWAIT
ENDIF
MEND
cleanDCache
	CACHECLEANXSCALE Dclean
	MOV pc,lr
cleanFlushDCache
	STMFD sp!,{lr}
	BL cleanDCache
	IF {CPU} = "XSCALE"
	BL cleanMiniDCache
	ENDIF
	MOV r0,#0
	MCR p15,0,r0,c7,c6,0;清除D-cache
	IF {CPU} = "XSCALE"
	CPWAIT
	ENDIF
	LDMFD sp!,{pc}
cleanFlushCache
	STMFD sp!,{lr}
	BL cleanDCache
	IF {CPU} = "XSCALE"
	BL cleanMiniDCache
	ENDIF
	MOV r0,#0
	MCR p15,0,r0,c7,c7,0;清除I-cache和D-cache
	IF {CPU} = "XSCALE"
	CPWAIT
	ENDIF
	LDMFD sp!,{pc}
	ENDIF
	IF {CPU} = "XSCALE"
	EXPORT cleanMiniDCache
	cleanMiniDCache
		CACHECLEANXSCALE DcleanMini
		MOV pc,lr
		ENDIF
```

上面就是不断的判定，最后执行什么指令。

接下来，宏会筛选所需要的命令来执行2个处理器内核的清理操作。Intel XScale使用CP15:c7行分配命令来清理D-cache，并通过读取专用的存储器块来清理miniD-cache。而Intel StrongARM读取存储器中特定的一块来清理其D-cache。

最后可多次使用宏来创建cleanDCache,cleanFlushDCache,cleanFlushCache和cleanMiniDCache等过程。

没有针对Icache清理清除的专用的指令。

#### 12.5.7清理和清除部分cache

ARM内核支持通过**访问主存中某一个cache行所对应的主存地址来清理和清除该cache行**。下表以MCR指令的形式列出了这些命令。这些命令中的2个可以用来清除单一的cache行：一个命令负责清除指令cache；另一个命令清除数据cache。另外2个命令用来清理数据cache；一个清理单一的cache行；另一个清理并清除一个cache行。

下表是通过主存中所对应的地址清理和清除一个cache行的命令

| 命令                  | MCR指令               |
| --------------------- | --------------------- |
| 清除指令cache行       | MCR p15,0,Rd,c7,c5,1  |
| 清除数据cache行       | MCR p15,,Rd,c7,c6,1   |
| 清理数据cache行       | MCR p15,0,Rd,c7,c10,1 |
| 清理并清除数据cache行 | MCR p15,0,Rd,c7,c14,1 |

当使用这些指令时，在同一个处理器上，内核寄存器Rd的值对于这4个命令是相同的，并且它的内容必须能够将CP15:c7寄存器置位（为啥必须要置位）；然而，对于不同的处理器，CP15:c7寄存器位值(bit value)的格式稍有不同。下图为支持清理和清除一个cache行的内核的寄存器格式。如果内核支持MMU，那么清理和清除一个cache行可以通过改变虚拟地址实现；如果内核支持MPU，那么可以通过改变物理地址实现。

这里使用这4个命令来创建6个例程，用来清理、清除或者既清理又清除cache中代表主存中某个区域的cache行。

- flushICacheRegion；清除I-cache中代表主存中一块区域的cache行
- flushDCacheRegion；清除D-cache中代表主存中一块区域的cache行
- cleanDCacheRegion；清理D-cache中代表主存中一块区域的cache行
- cleanFlushDCacheRegion；清理并清除D-cache中代表主存中一块区域的cache行；
- flushCacheRegion；清除D-cache和I-cache中代表主存中一块区域的cache行；
- cleanFlushCacheRegion；清理并清除D-cache，接下来清除I-cache。

对于所有的过程都有2个输入参数：主存中的起始地址adr和区域中的字节数b。C函数原型如下：

```c
void flushICacheRegion(int * adr,unsigned int b);//输入起始地址给MCR指令，从而找到用该地址作为标签的cache行，进行清除
void flushDCacheRegion(int * adr,unsigned int b);
void cleanDCacheRegion(int * adr,unsigned int b);
void cleanFlushDCacheRegion(int * adr,unsigend int b);
void flushCacheRegion(int * adr,unsigned int b);
void cleanFlushCacheRegion(int * adr,unsigned int b);
```

当使用以上指令清理cache区域过程时要小心，他们比较适合小存储区域。如果区域大小比cache大好几倍，那么使用之前介绍的清理cache方法。

只有少数ARM内核支持区域过程。同样这些内核也列在接下来的示例代码的开始部分中。

例12.6宏将输入的地址裁剪成一个cache行大小，这种裁剪通常将地址对应到内核的cache行的第一个双字。然后，宏会将输入参数字节数b转换成cache行数。宏将cache行的数目作为计数器变量在选中的清除和清理操作中作循环每一次循环结束后，将地址增加一个cache行的大小，直到计数器计数值为0。

```assembly
IF {CPU} = "ARM920T"
INCLUDE cache.h;汇编也可以包含头文件
adr RN 0
size RN 1
nl RN 1
MACRO
CACHEBYREGION $ op
BIC adr,adr,#(1 << CLINE) - 1;cache行的字节数-1清除起始地址，不理解
MOV nl,size,lsr #CLINE;这里的lsr也是第一次用
IF "$ op" = "IcacheFlush"
MCR p15,0,adr,c7,c5,1
ENDIF
...
```

我认为这种汇编没必要写了。

最后使用名为CACHEBYREGION的宏创建例程。对于命令集有限的Intel Strong-ARM内核，可以创建3个例程；对于其余的拥有分离cache（指的是将I和D分开）的处理器，可以创建所有的6个例程。

### 12.6cache锁定

cache锁定（lockdown）是cache的一项特性，使程序能够加载对时间要求很苛刻的代码和数据到cache中来，并把这些代码和数据**标记为非替换的**。被锁定的代码和数据有更快的系统反映能力（始终在cache中，随时等待），cache在正常操作时，经常涉及到cache行替换，这种替换会带来代码执行时间不确定的问题，而cache锁定可以避免这种不确定性。

将信息锁定在cache中的目的是，避免cache失效所造成的负面效果。然而，由于任何用作cache锁定的cache存储器单元不能够再存储主存的其他内容，所以，可用的cache空间被减少了。

ARM内核为cache锁定分配固定的cache单元。一般来讲，分配作cache锁定的cache单元是一个路way。例如：一个4路组相联cache允许将锁定的代码和数据放在容量为cache总容量的1/4的cache单元内，带cache的内核通常至少保留一个路作为cache的正常操作使用。

有些指令往往需要被锁定在cache中，比如**中断向量表**、**中断服务程序**以及为一些特殊算法编址的代码。这些算法被系统广泛使用且时间要求比较苛刻。对于数据来说，经常使用到的全局变量最好被锁定在cache中。

锁定在ARM cache中的数据和代码不会被替换。但是，如果cache被清除，被锁定的信息也会丢失，存放锁定信息的cache存储区也不能被用作一般的cache存储区。必须重新运行cache锁定程序，以保存新的锁定信息。

#### 12.6.1在cache中锁定代码和数据

本小节将介绍如何在cache中锁定代码和数据。锁定代码和数据的典型C程序如下：

```c
int interrupt_state;
int globalData[16];
unsigned int * vectortable = (unsigned int *)0x0;
int wayIndex;
int vectorCodeSize = 212;//向量表和FIQ句柄的字节数，为什么这里单独提FIQ句柄，这里的句柄是啥，是中断服务例程地址吧
interrupt_state = disable_interrupts();
enableCache();
flushCache();
//锁定全局数据块
wayIndex = lockDcache(globalData,sizeof globalData);
//锁定中断向量表和FIQ句柄
wayIndex = lockIcache(vectortable,vectorCodeSize);
enable_interrupts(interrput_state);
```

开始时，中断被禁止，而cache是使能的。禁止中断的程序在这里没有表述。其中flushCache程序详见本章前几节的例子。实际使用的调用取决于cache的配置，而且很可能也包括cache的清理。

函数lockDcache在D-cache中锁定一块数据；类似的，函数lockIcache在I-cache中锁定一个代码块。

- 执行cache锁定的软件本身必须被存放在不可cache的主存中。
- 锁定在cache中的代码和数据必须被存放在可cache的主存中。这句话的理解其实很容易，如果cache中的内容位置，那么在装载之前应先清除cache。只有根据主存地址才能找到被锁住的该内容。

一旦代码和数据被装载到cache，就可以重新使能中断了。

对于函数lockDcache和函数lockIcache这里提供了3种不同的实现代码，因为根据体系结构不同，在cache中锁定代码有3种不同的方法。第一种锁定代码和数据的方法使用了路way寻址技术；（因为锁定的空间是以路为单位）第二种使用了一组锁定位；第三种方法中国，结合使用了特殊分配命令和读取主存中特定块这两种方法锁定代码和数据。

下表列出了实现lockDcache和lockIcache的三个例子。

#### 12.6.2通过增加路索引来锁定cache

一部分ARM内核使用路和组索引寻址来实现锁定。2个CP15:c9:c0寄存器中**包含12.3.2小节中描述的丢弃者计数器的复位寄存器**。这两个寄存器中的一个控制着I-cache，另一个控制D-cache。这些寄存器被用作在一个路中选择用来锁定数据和代码的cache行。

写到CP15:c7寄存器中的值用来设置丢弃计数复位值，即当丢弃者计数器的值增加到超出内核中路的数目时，丢弃者计数器被复位的值。系统上电时，复位值为0，只有当cache中的某一部分被用作锁定时，复位值才由软件改变。当cache中的某一部分被用作锁定时，可用cache行的数量随被锁定的cache行数量的增加而减少。读此寄存器，将返回当前的丢弃计数复位值。读和写这两个寄存器的MRC和MCR指令见下表。

下表通过访问路，在cache中锁定数据的命令

| 命令                | MRC和MCR指令         |
| ------------------- | -------------------- |
| 读D-cache锁定寄存器 | MRC p15,0,Rd,c9,c0,0 |
| 写D-cache锁定寄存器 | MCR p15,0,Rd,c9,c0,0 |
| 读I-cache锁定寄存器 | MRC p15,0,Rd,c9,c0,1 |
| 写I-cache锁定寄存器 | MCR p15,0,Rd,c9,c0,1 |

当读/写锁定基地址时，对于不同的处理器来说，MRC和MCR指令使用的内核寄存器Rd的格式稍有不同。下图为使用这些指令的处理器内核Rd寄存器格式。为保证命令正确地执行，一定要使Rd寄存器的格式和下图一致。

将指令锁定在cache中还需要一条特殊的装载命令。该命令复制与cache行相同大小的主存块到I-cache的cache行 中。该命令以及Rd寄存器在该指令中使用的格式见下图。

在I-cache中锁定cache行

| 命令                  | MCR指令               |
| --------------------- | --------------------- |
| 通过地址预取I-cache行 | MCR p15,0,Rd,c7,c13,1 |

例12.7这个例程的第一部分定义了在宏CACHELOCKBYWAY中使用的寄存器。在宏的定义中也使用了头文件cache.h中的常量。

宏的第一行将地址adr调整成cache行地址。接下来的3行根据代码的字节数决定承载代码所需要的路数。然后由CP15:c9:c0中读取I-cache和D-cache的当前被丢弃者指针。

接下来的几行代码做错误检测，主要测试cache是否过载以及即将装载的代码长度是否为零。

在两种ARM内核中锁定代码和数据时，在将一块内存数据锁定在cache行中以前，必须把锁定位置位。本例程中的下一条指令就是将锁定位置位，并将数据写回到CP15:c9:c0寄存器。

在此，代码使用了嵌套的循环：外面的大循环选择路，里面的小循环在一个路中不断的增加cache行地址。

在这2个循环的中央，使用预取指令或装载数据命令在cache存储器中锁定一个cache行。

- 为了锁定指令，宏对一个特殊的CP15:c7:c13寄存器执行写入操作，从主存中预装载代码段。（锁定指令比锁定数据多一个步骤，就是写入CP15寄存器）
- 为了锁定数据，只须使用LDR指令读数据即可。（这个是读取主存的时候根据读操作策略，在这个时候会分配cache行到锁定部分）

如果内核是ARM940T或ARM946E-S，那么宏退出返回时须清除CP15:c9:c0寄存器中的锁定位。对于所有的ARM内核，宏在锁定的代码和数据之后将丢弃者指针指向下一个路。

```assembly
IF {CPU} = "ARM920T"
EXPORT lockDCache
EXPORT lockICache
INCLUDE cache.h
adr RN 0
size RN 1
nw RN 1
count RN 2
tmp RN 2
tmp1 RN 3
c9f RN 12
	MACRO
	CACHELOCKBYWAY $ op
	BIC adr,adr,#(1 << CLINE)-1;这里的cache行地址从来都没搞明白
	LDR tmp,=(1 << SWAY) - 1;得到一条路的字节数-1作为常量，不理解为啥要-1
	TST size,tmp;比较下cache存储器字节数和一条路字节数-1
	MOV nw,size,lsr #SWAY;将字节数转换成路数，这里size是总字节数/一条路的字节数，所以lsr应该是除法的意思，路数送入nw
	ADDNE nw,nw,#1;如果有碎片，则路数+1
	CMP nw,#0;比较下路数和0
	BEQ %FT2;如果路数等于零，说明无法执行锁定请求，退出并返回丢弃者寄存器，这里的%FT2不理解，之前是%BT5
	IF "$ op" = "Icache";如果锁定的是Icache，先获得其丢弃者寄存器复位值
	MRC p15,0,c9f,c9,c0,1;c9f = Icache的丢弃者复位值就是十进制数
	ENDIF
	AND c9f,c9f,tmp;此时的c9f是32位的，不需要这么多位，我们只关注
	ADD tmp,c9f,nw;temp=丢弃者 + 路的字节数
	CMP tmp,#(1<<NWAY)-1;判断是否大于总的路数
	MOVGT r0,#-1;如果路数过多返回-1
	BGT %FT1;错误，cache路溢出。
	IF {CPU} = "ARM940T"
	ORR c9f,c9f,#1<<31;将cache设定为锁定模式这里的锁定模式看不懂，丢弃者计数器复位值左移31位然后或上
	ENDIF
	IF "$ op" = "Icache"
	MCR p15,0,c9f,c9,c0,1;锁定数据
	ENDIF
	MOV count,#(1<<NSET)-1;组索引数量送入count
	IF "$ op" = "Icache"
	MCR p15,0,adr,c7,c13,1;对于Icache额外的步骤
	ADD adr,adr,#1<<CLINE;cache行地址+1
	ENDIF
	...
```

看不懂。。。

#### 12.6.3使用锁定位锁定cache

ARM926EJ-S和ARM1026EJ-S使用一组锁定位在cache中锁定代码和数据，如下图。这两种处理器的CP15:c9指令使用不同的Rd格式，0~3四个位分别代表了在两种处理器的4路组相联cache中的四个路。如果某位被置位，那么它所对应的路就被锁定。对于D-cache锁定了数据；对于I-cache则锁定了代码。被锁定的路中的cache行，直到被解锁之后才能被替换。将L位中的某一位清零，就可以解锁相应的路。这种锁定cache的方式使系统代码可以单独选择锁定和解锁的路。

| 命令                      | MRC和MCR指令          |
| ------------------------- | --------------------- |
| 读I-cache锁定页寄存器     | MRC p15,0,Rd,c9,c0,1  |
| 读D-cache锁定页寄存器     | MRC p15,0,Rd,c9,c0,0  |
| 写I-cache锁定页寄存器     | MCR p15,0,Rd,c9,c0,1  |
| 写D-cache锁定页寄存器     | MCR p15,0,Rd,c9,c0,1  |
| 装载某一地址的代码cache行 | MCR p15,0,Rd,c7,c13,1 |

这种单独选择锁定路的功能，使得系统中代码的锁定和解锁更加容易。本小节的程序使用了与其它带cache的内核相同的锁定数据的程序接口。

这两种ARM内核的lockDCache和lockICache示例程序有相同的输入参数。但是代码的大小受路的最大尺寸的限制，并且可以重复调用3次。在本小节的例子中，**锁定位3通常为cache专用的**。（锁定位有4位对应四个路，这里是啥意思）这不是处理器硬件的限制，而仅仅是为了适应程序接口的需要，对过程调用做出的限制。

如果size参数是1字节或者更大那么实例程序返回被锁定路的锁定位。如果size参数为0，那么程序返回下一个可用的路的锁定位。如果没有可锁定的路，那么将返回8。

例12.8通过名为CACHELOCKBYBIT的宏产生lockDCache和lockICache函数。宏CACHELOCKBYBIT也使用了cache.h头文件所定义的常数。

宏首先检查cache中将要被锁定的字节数是否为零；接下来它分析承载这些代码所需要的cache行数，并调整地址adr到cache行地址。

如果程序要在D-cache中锁定数据，那么它就会读锁定寄存器CP15:c9:c0:0的值；如果要在I-cache中锁定代码，那么就会读锁定寄存器CP15:c9:c0:1的值。结果被放在内核c9f寄存器中，锁定位也被存放在tmp寄存器中，以备以后使用。

```assembly
IF {CPU} = "ARM926EJ-S"
EXPORT lockDCache
EXPORT lockICache
EXPORT bittest
INCLUDE cache.h
adr RN 0
size RN 1
tmp RN 2
tmp1 RN 3
c9f RN 12
	MACRO
	CACHELOCKBYLBIT $ op
	ADD size,adr,size;当前地址+存储器字节数=末位地址
	BIC adr,adr,#(1<<CLINE)-1;与CLINE对齐，不理解，就是cache行内字节数
	MOV tmp,#(1<<CLINE)-1;临时CLINE屏蔽
	TST size,tmp
	SUB size,size,adr;补上对齐字节数。
	...
	IF "$ op"="Icache"
	MRC p15,0,c9f,c9,c0,1
	ENDIF
	IF "$ op"="Dcache"
	MRC p15,0,c9f,c9,c0,0
	ENDIF
	;此时已经获取了锁定位存在c9f中，但这是32位的
	AND tmp,c9f,#0xf;获得低四位，也就是锁定位。
	MOV tmp1,#1
	TST c9f,tmp1;测试锁定位0
	MOVNE tmp1,tmp1,LSL #1;如果不相等的话，左移一位
	TSTNE c9f,tmp1;既然锁定位0不相等，测试锁定位1
	MOVNE tmp1,tmp1,LSL #1
	TSTNE c9f,tmp1
	MOVNE tmp1,tmp1,LSL #1;因为锁定位3是cache专用，所以不测试
	BNE %FT1;错误就是没有可取的路
	CMP size,#0;无锁定请求
	BEQ %FT1;退出返回size=0
	;之前只是检查下锁定位以及锁定请求的情况
	MVN tmp1,tmp1;对tmp1取非，进行锁定
	AND tmp1,tmp,#0xf;清除寄存器中L位以外的其他位。
	BIC c9f c9f,#0xf;构造c9f寄存器
	ADD c9f,c9f,tmp1;将设定好的L位添加到c9f中
	IF "$ op"="Icache"
	MCR p15,0,c9f,c9,c0,1;设置锁定I位，要求锁定的路已经提供了你就锁就完了
	ENDIF
	IF "$ op"="Dcache"
	MCR p15,0,c9f,c0,c0;设置锁定D页
	ENDIF
	IF "$ op"="Icache"
	MCR p15,0,adr,c7,c13,1;装载指令cache行，锁定cache的路之后还没有添加数据，根据特定的装载指令添加。adr就是需要装载的指令cache行地址
	ADD adr,adr,#1<<CLINE;cache行地址加1
	ENDIF
	IF "$ op"="Dcache"
	LDR tmp1,[adr],#1<<CLINE;装载数据cache行，数据cache没那么多讲究，直接读操作，就会自动装载cache行
	ENDIF
	SUBS size,size,#1;cline=-1
	BNE %BT5;在各cache行进行循环
	lockDCache
		CACHELOCKBYLBIT Dcache
	lockICache
		CACHELOCKBYLBIT Icache
		ENDIF
```

将CP15的情况存入c9f中，检查c9f寄存器，看看是否有一个路可以用来存储数据和代码。如果没有，则退出该例程；如果有，则在接下来的4行中改变c9f寄存器的值，以选择用于锁定数据的路。接着c9f寄存器被用在MCR指令中来选择路。

这样，程序进入把锁定的代码和数据填满cache的循环。如果要在I-cache中锁定代码，则将执行预取I-cache行命令；如果锁定外部存储器中的数据，则程序将清理、清除并向D-cache中装载新的cache行。(就是说想把外存中的数据锁定)

宏在退出返回时将所保存的原来的cache锁定位与新锁定的页融合，根据结果创建新的c9f寄存器。宏在MCR指令中使用c9f寄存器来设置CP15:c9:c0 cache，锁定寄存器L位。

最后，2次使用宏CACHELOCKBYBIT创建lockDCache和lockICache函数。

#### 12.6.4在Intel XScale SA-110中锁定cache行

Intel XScale处理器也有在cache中锁定代码和数据的能力。这要求使用一组CP15:c9 cache锁定命令。见下表，CP15:c9:c2寄存器的格式。另外还需清理D-cache使用 CP15:c7，分配D-cache行命令。

| 命令                                     | MRC和MCR指令         |
| ---------------------------------------- | -------------------- |
| 取并锁定I-cache行                        | MCR p15,0,Rd,c9,c1,0 |
| 解锁指令cache                            | MCR p15,0,Rd,c9,c1,1 |
| 读数据cache锁定寄存器                    | MRC p15,0,Rd,c9,c2,0 |
| 写数据cache锁定寄存器并置位/清零锁定模式 | MCR p15,0,Rd,c9,c2,0 |
| 解锁D-cache                              | MCR p15,0,Rd,c9,c2,1 |

在Intel XScale处理器中，cache中的每个组都有一个轮转指针。（这就是轮转循环法替换法）每当有新的cache行在cache中被锁定时，该指针顺序增加。在一个组的32个cache行中，可以有最多28个cache行被锁定。若在一个组中试图锁定超过28个cache行，则会使该cache行被分配，但不能在cache中被锁定。

----

我品出来了，其实操作cache控制器的代码太多了，不同的内核版本也会导致不同的操作，这也是汇编的难度

---

Intel XScale处理器有2种方法在D-cache中锁定数据：第一种方法只是简单地将主存位置锁定在D-cache中；第二种方法使用分配cache行命令，将cache中的一部分配置成数据RAM（嗯？第一种锁定主存位置是之前的方法吧，第二种和第一种有啥区别。。），这样，这部分分配的cache没有被初始化，需要处理器内核对它执行写操作来包含有效数据。在这里的例子中将存储器初始化为零。

例12.9例程的第一部分定义了宏CACHELOCKREGION中使用的寄存器。宏中也使用了头文件cache.h中定义的常量。

宏首先调整地址adr到cache行地址，并决定承载代码所需要的cache行数。

如果要在D-cache中锁定数据，那么代码中接下来的几行代码需要排空写缓冲器，并把D-cache解锁。在D-cache中锁定数据，必须在锁定一个D-cache行之前使用解锁命令。（为什么之前不需要排空写缓冲区）宏通过向CP15:c9:c2:0寄存器中写入1来将该位置位。

这时，程序进入循环，向cache中填充锁定的数据和代码。如果程序要在I-cache中锁定代码，那么将会执行锁定I-cache行命令；如果要锁定来自外部存储器的数据，那么程序将清理cache，清除cache并向D-cache中装载新的cache行；如果要创建数据RAM，那么程序会分配一个D-cache行，并且排空写缓冲器，以防止试图锁定超过28组数据而引起的错误。（这句话解释明白了，因为在本ARM内核版本下，不允许超过28个cache行被锁定，所以需要排空写缓冲器，毕竟回写的时候会导致cache行通过写缓冲器写回主存）

接下来使用STRD指令将cache行初始化为0。

如果是锁定D-cache中的数据，那么宏在返回退出时，把cache装载CP15寄存器上的锁定位清零。

```assembly
IF {CPU}="XSCALE"
EXPORT lockICache
EXPORT lockDCache
EXPORT lockDCacheRAM
INCLUDE cache.h
adr RN 0
size RN 1
tmp RN 2
tmp1 RN 3
MACRO
CACHELOCKREGION $ op
ADD size,adr,size
BIC adr,adr,#(1<<CLINE)-1
MOV tmp,#(1<<CLINE)-1
TST size,tmp
SUB size,size,adr
MOV size,size,lsr #CLINE;size = size/CLINE
ADDNE size,size,#1
CMP size,#0;无锁定请求
BEQ %FT1;退出返回size=0
IF "$ op"="Dcache":LOR:"$ op"="DcacheRAM"
MCR p15,0,adr,c7,c10,4;排空写缓冲
MOV tmp,#1
MCR p15,0,tmp,c9,c2,0;解锁Dcache
CPWAIT
MOV tmp,#0;偶数字清零
ENDIF
IF "$ op"="DcacheRAM"
MOV tmp1,#0
ENDIF
IF "$ op"="Icache"
MCR p15,0,adr,c9,c1,0
ADD adr,adr,#1<<CLINE
ENDIF
IF "$ op"="Dcache"
MCR p15,0,adr,c7,c10,1;清理带脏位的cache行
MCR p15,0,adr,c7,c10,4;排空写缓冲器
STRD tmp,[adr],#8;
...
```

我现在都不敢写熟悉ARM汇编了。

### 12.7cache与软件性能

遵循一些简单的规则，将有助于利用cache的结构优势来编写代码。

存储器系统中的许多区域，通常都把cache和写缓冲器两者都使能，从而最大限度地利用cache体系结构的优点来缩短平均访存时间。有关存储系统的不同部分、cache配置和写缓冲器操作的更多细节，可参考后续章节。如果使用带有存储器保护单元(MPU)的ARM处理器内核，参考第十三章；如果使用带有存储器管理单元MMU的ARM处理器内核，可参考第十四章。

如果把存储器映射的外设配置成使用cache或写缓冲器，那么通常会产生问题。（这里的意思就是c语言前面加上volatile关键字，每次cpu直接访问主存中的寄存器映射，虽然速度慢了一些，但不需要考虑一致性问题了，cache直写策略无法避免一致性问题，因为现在不是cpu想要改变，而是外设端口自己修改了，cache都不知道）

最好将他们配置成不使用cache，并且不使用写缓冲器，这就强制处理器在每次访问时都去读外设端口，而不是从cache中读取陈旧的信息。

应尽可能将经常访问的数据**顺序存放**在主存中，因为从主存中获取一个新的数据的代价等同于填充整个cache行。（毕竟每次填充cache都需要访问主存一个cache行）如果一个cache行中的数据在被替换出cache之前只使用过一次，那么系统的性能就比较低。应尽可能地把**例程中的数据放在同一个cache行**中，以提高cache命中率，因为这样可以充分利用局部性原理，从而形成更多的cache命中。最重要的一点是，要在主存中把一个共用例程所访问的数据尽量紧靠在一起。

尽可能**组织数据，使读、处理和写都在cache行尺寸的块中完成**，并使主存块地址的低位与cache行的起始地址匹配。（也就是说以四个32位为单位）

最通用的做法是使代码尽量小，并将相关的数据分组放在一起。代码尺寸越小，cache效率越高。

 在cache系统中，使用链表会降低程序性能，因为查表会导致很高的cache失效率。与从顺序数组中访问数据相比，从链表访问数据，程序将以更加随机的形式取数据。这一点在查找任何无序表时都须考虑。选用何种数据查找方法，可能需要对系统性能进行分析。（链表会导致地址不连续，此时如果按顺序将数据依次存入cache行中无法保证空间局部性）

然而，除了编写高效使用cache的代码之外，不要忘记还有许多其他的因素在改善系统性能上有更大的作用。

### 12.8总结

cache是一个放置在处理器和主存之间的小容量高速存储器阵列。他是一个存储部分最近访问的主存内容的缓冲。相比于系统存储器，处理器在可能的情况下更高优先使用cache存储器，以改善系统的平均性能。

写缓冲器是一个位于处理器内核与主存之间的非常小的先进先出存储器，只写不可读，它可以把处理器内核与cache存储器从低速的主存写操作中解脱出来。

局部性原理说明，程序在执行过程中会频繁运行小范围的循环代码，而这些代码会对数据存储器中的局部数据反复访问。它解释了为什么使用带cache的内核后，系统的平均性能会显著改善。

ARM组织使用了许多条目来描述cache体系结构的特性。为了方便，这里列出当前所有带cache的ARM内核的特性。

| 内核    | cache类型 | cache大小/KB | cache行大小/word | 相联  | 位置             | 是否支持cache锁定 | 写缓冲器大小/word |
| ------- | --------- | ------------ | ---------------- | ----- | ---------------- | ----------------- | ----------------- |
| ARM720T | 统一      | 8            | 4                | 4-way | 逻辑（虚拟地址） | 否                | 8                 |

这八条属性把cache和写缓冲器的特性说明白了。

cache行是cache的基本组成单位，包含3部分：目录存储段、数据项段和状态信息段。cache标签是一个目录记录项，指示一个cache行是从主存中的什么地方被装载的。在cache中通常有2个状态位：有效位和脏位。当相关的cache行包含有效的存储器内容时，有效位被置位；当cache使用回写策略并且有新的数据写入到cache行时，脏位被置位。

cache的位置可以在MMU之前或之后，有物理cache和逻辑cache之分。逻辑cache被放置在处理器内核与MMU之间，在虚拟地址空间访问代码和数据。物理cache被放置在MMU和主存之间，使用物理地址访问代码和数据。

直接映射cache是一种非常简单的cache结构，每一个主存地址都对应唯一的cache地址。直接映射cache经常会导致颠簸。为了减少颠簸，将cache分成容量相等的较小单元，这种小单元被称作路。（同一个主存单元对应多个路）这种cache被称为组相联cache。

内核总线的体系结构决定了cache系统的设计。冯*诺依曼结构使用统一cache存储代码和数据。哈佛结构使用分离cache：一个cache用于指令，另一个cache用于数据。

cache替换策略决定了在访问cache失效时，哪一个cache行将被替换出cache。配置策略决定cache控制器使用什么算法在当前cache存储器的组中选择一个cache行。被选中作替换的cache行被称为丢弃者。带cache的ARM内核使用两种替换策略：伪随机法和轮转法。

向cache中写数据有两种策略：如果控制器只更新cache存储器，称为回写策略；如果cache控制器既写cache，又写主存，则称为直写策略。

当cache失效时，cache控制器使用两种策略分配一个新的cache行：读分配策略，在数据由主存中读出时分配cache行；写分配策略在向主存中写数据时分配cache行。

ARM使用术语清理表示将D-cache中的数据写回到主存中。ARM使用术语清除表示使cache中的内容无效。

有些ARM内核提供cache锁定功能，锁定允许代码和数据被装载到cache，并被标记为非替换的。

----

昨天晚上突然困惑了，对于采用组相联在cache中的寻址实际上是组索引号是cache中的地址信号、数据索引是找到cache行内的四个字的数据信号。如何区分同组内的不同路，通过比较tag实现，当组内cache行过多时，采用CAM比较tag找到对应的路，每个CAM对应一个路。从而在组索引号也就是cache的地址总线信号相同时，找到的对应的路。

-----

本章还提供了一些实例代码，显示了如何清理、清除cache，以及在cache中锁定代码和数据。

## 第十三章，存储器保护单元MPU

- 受保护的区域
- 初始化MPU，cache和写缓冲器
- MPU系统示例
- 总结

一些嵌入式系统使用多任务的操作或控制系统。在这种系统里，必须保证正在运行的任务不破坏其他任务的操作。防止系统资源和其他任务受非法访问的工作称为保护，这也是本章将要讨论的主要内容。

系统资源的访问控制有两种方法：无硬件保护和有硬件保护。无保护的系统紧靠软件来保护系统资源；受保护的系统靠硬件和软件两者来保护系统资源。在具体的控制系统中使用哪一种方法，取决于处理器的性能和该控制系统的需求。

在无保护的嵌入式系统中，没有专门用于存储器和外围设备访问控制的硬件。在这种系统中，任何一个任务都可能破坏其他任务的状态，因此每个任务在访问系统资源时都必须与其他所有的任务进行协调。当一个任务忽略其他任务环境的访问限制时，这种协调机制可能会导致任务失败。

这里是无保护系统中可能出现的一个任务失败的例子：当读写一个通信用的串口寄存器时，如果一个任务正在使用串口，则它没办法防止其他任务使用同一个串口。因此，若要成功使用该串口，则必须通过一个**访问该串口的系统调用**来协调。但使用这些调用任务的非授权访问，很容易破坏经过该串口的通信。因此资源的不合理使用也许是不可避免的、或者说它本质上就存在。

相反，受保护系统有专门的硬件来检测和限制系统资源的访问。它能保证资源的所有权，任务需要遵守一组由操作环境定义的、由硬件维护的规则，在硬件级上授予监视和控制资源程序的特殊权限。受保护的系统会主动防止一个任务使用其他任务的资源。因此使用硬件主动监视系统比协调加强的软件例程，提供了更好的保护。

ARM的很多处理器配备了有效保护系统资源的硬件，比如通过存储器保护单元MPU或者通过存储器管理单元MMU。带有MPU的处理器核是本章讨论的重点，他对一些由软件定义的区域提供硬件保护。带有MMU的处理器和是下一章讨论的重点，他提供硬件保护并增加了虚拟存储器功能。

在受保护的系统中，主要有两类资源需要监视：存储器系统和外围设备。ARM的外围设备通常都映射到存储器中。（果然就是我想的寄存器映射）因此MPU就使用同样的方法来保护这两类资源。

ARMD MPU使用区域来管理系统保护。区域是与一个存储空间相关联的一组属性，处理器核将**这些属性保存在协处理器CP15的一些寄存器**里，并用0~7的号码标识每个区域。

区域的存储器边界通过两个属性进行配置：起始地址和大小。大小可以是4KB~4GB的任何2的乘幂。另外，操作系统可以为这些区域分配更多的属性：访问权限、cache和写缓冲器策略。存储器中对区域的访问可以是读/写、只读或不可访问，并基于当时的处理器模式比如管理模式或用户模式，还有一些附加的权限。区域还有控制cache和写缓冲器属性的cache写策略。

比如可以设置一个区域使用直写策略访问存储器，而另一个区域则以无cache和无写缓冲方式操作。（因为cache行的标志区域是根据主存地址决定的）

当处理器访问主存的一个区域时，MPU比较该区域的访问权限属性和当时的处理器模式。如果请求符合区域访问标准，则MPU允许内核读/写主存；如果存储器请求导致存储器访问违例，则MPU产生一个异常信号。

异常信号被传送到处理器核。处理器核执行 一个异常向量，然后跳转到异常处理程序，以响应该异常信号。异常处理程序可以判断异常类型为预取指或者数据中止，跳转到相应的服务例程。

要实现一个受保护系统，控制系统对主存中的不同块定义若干区域。一个区域可以被创建一次，然后一直作用到嵌入式系统结束；也可以被临时创建来满足一个特殊操作的需要，随后就被删除。下一节的主题就是如何来分配和创建区域。

### 13.1受保护的区域

目前有四种ARM核包含MPU，这四种ARM核包含8个受保护区域；有的包含16个受保护区域。

有的ARM处理器内核使用统一的指令和数据区域，指令区域和数据区域使用相同的寄存器进行定义，这些寄存器设置区域的起始地址和大小。为指令和数据访问分别配置存储器访问权限和cache策略；区域的设置问题和内核结构无关。每个区域通过0~7的号码来标识和引用。

因为ARM940T采用独立的区域来控制指令和数据存储器，所以可以**为指令和数据区域定义不同的区域起始地址和大小**。指令和数据区域的分离导致在这种核中增加了8个区域。虽然在ARM940T中标识区域的号码仍然是0~7，但是每个号码对应有两个区域：一个数据区域和一个指令区域。

有关区域的一些属性如下：

- 区域可以相互重叠；
- 每个区域都分配一个优先级，该优先级与分配给区域的权限无关；
- 当区域重叠时，具有**最高优先级的区域的属性可以覆盖其他区域的属性**，优先级**仅作用于重叠部分**的地址；
- 区域的起始地址必须是其大小的倍数；
- 区域的大小可以是4KB~4GB的任何2的乘幂；
- 访问所定义区域外的存储器将产生异常。如果是内核预取指令，则MPU产生预取指中止异常；如果是存储器数据请求，则产生数据中止异常。

---

所以中止实际上是访问非法地址后由MPU产生的两种中止异常

---

指令和数据区域配置是否分离和区域分离无关，即使区域重合也可以分离配置。

#### 13.1.1重叠区域

当存储空间的某部分被分配给一个以上的区域时，会发生区域重叠。重叠区域比非重叠区域在分配访问权限时有更大的灵活性。

作为区域重叠的一个例子，假设有一个小的嵌入式系统，她有256KB的可用存储空间，起始地址为0x00000000，现在须保护一块特权系统空间，用户模式下的程序不能对其进行读写操作。

---

之前不同ARM处理器模式下的对应不同的堆栈，但这并不代表存储空间中没有共有的部分。堆栈是临时存放程序参数、返回值、保存上下文的，并不是存储数据的。通过修改sp指向不同地址实现的区分不同模式下堆栈。

现在希望让存储空间的一部分无法在某些模式下访问，涉及到权限的问题

----

这块特权空间的代码、数据和堆栈在一个32KB的区域内，这个区域的最前面是向量表，起始地址为0x00000000，剩下的存储空间作为用户空间。

有了重叠区域，系统使用2个区域：一个256KB的用户区域和一个32KB的特权区域。给特权区域1分配较高的优先级，因为他的属性必须优先于用户区域0（重叠之后优先级高的属性有效）

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686706878236.png" alt="1686706878236" style="zoom: 25%;" />

#### 13.1.2背景区域

重叠区域的另一个有用特征是作为背景区域---用来给一块大存储空间分配相同属性的低优先级区域。其他具有较高优先级的区域与该背景区域的某部分重叠，用来改变已定义的背景区域的较小子集的属性。这样，具有较高优先级的区域可以改变背景区域属性的子集。背景区域可以用来保护一些睡眠状态的存储空间，使其不受非法访问，而此时由另一个不同区域控制下的背景区域的其他部分可以处于活跃状态。（在对其他区域提供保护的同时，可以让某些区域处于活跃，这就是重叠区域的好处）

例如，一个嵌入式系统定义了一个大的特权背景区域，可以让一个较小的非特权的区域与这个背景区域的某部分重叠。这个较小区域的位置可以在该背景区域的不同位置，以代表不同的用户空间。当 系统将这个较小的用户区域从一个位置移动到另一个位置时，早先被覆盖的空间由背景区域所保护。因此用户区域可以向窗口一样，允许访问特权背景区域的不同部分，但他只有用户级属性。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686707985762.png" alt="1686707985762" style="zoom:25%;" />

重叠区域这个概念对我来说是闻所未闻。上图表示一个简单的3个任务的保护模式。区域3定义活跃任务的保护属性，背景区域0控制睡眠态任务空间的访问。当任务1运行时，背景区域保护任务2和任务3的空间不受任务1访问；这样工作的原因是区域3比区域0有较高的优先级，尽管区域0有较高的访问权限。

在本章最后的例程代码中用一个背景区域来演示一个简单的多任务保护模式。

---

和处理器模式下堆栈地址不同的问题不一样，这里的重叠区域是保护在同一个模式下运行的多个进程之间的数据保护问题，三个进程数据顺序排列，每次运行时用高优先级低权限的区域覆盖它。保证任务1在运行时因为权限不够从而无法访问其他存储空间。实现保护其他存储空间的目的

----

### 13.2初始化MPU，cache和写缓冲器

为了初始化MPU，cache和写缓冲器，控制系统必须定义在操作目标平台时所需要的保护区域。（需要确定保护区域）

在启用存储器保护单元之前，必须至少定义一个数据区域和一个指令区域，而且必须在启用cache和写缓冲器之前或同时启用存储器保护单元。

控制系统通过设置CP15的主寄存器c1,c2,c3,c5和c6来配置MPU。（cache、写缓冲器、MPU都需要协处理器CP15配置）

| 功能               | 主寄存器 | 次寄存器 |
| ------------------ | -------- | -------- |
| 系统控制           | c1       | c0       |
| 区域的cache属性    | c2       | c0       |
| 区域的写缓冲器属性 | c3       | c0       |
| 区域的访问权限     | c5       | c0       |
| 区域的大小和位置   | c6       | c0~c7    |

（MPU配置的是区域，而不是整体存储空间）

通过配置寄存器c2和c3来设置区域的cache和写缓冲器的属性，寄存器c5控制区域的访问权限，在寄存器c6里有8或16个次寄存器，用来定义每个区域的大小和位置。个别处理器内核中还有其他配置寄存器和MPU配置无关了。

初始化MPU、cache和写缓冲器需要以下步骤：

- 使用CP15:c6来定义指令和数据区域的大小和位置；
- 使用CP15:c5来设置每个区域的访问权限；
- 分别使用CP15:c2和CP15:c3来设置每个区域的cache和写缓冲器属性；
- 使用CP15:c1来使能cache和MPU。（因为配置区域的cache属性之前不可以使能cache，想要配置区域的cache属性需要先配置这个区域大小，最后使能cache和MPU）

在描述完用来配置每个寄存器的协处理器CP15命令以后，都有一小节描述每个步骤；也有例程代码来说明在初始化过程中，完成该步骤的程序中所用到的命令。

#### 13.2.1定义区域的大小和位置

嵌入式系统通过写8个次寄存器CP15:c6:c0:0~CP15:c6:c7:0来定义每个区域的大小和地址范围。每个协处理器次寄存器号映射到对应的区域标识号。

每个区域的起始地址必须对齐到其大小的整数倍。

-----

字节对齐的三个准则：

1. 结构体变量的首地址能够被其最宽类型的成员大小所整除；（难道是先读取大小，然后每次偏移数据的大小么）
2. 结构体成员相对结构体首地址偏移量是成员大小的整数倍；
3. 结构体的总大小为结构体最宽基本类型成员大小的整数倍。

对齐原因是带来存取效率上的损失。每次从偶地址读取4字节。如果不是按照四字节对齐，就会导致两个总线周期。但这和起始地址被总大小整除有啥关系。

-----

比如，一个区域的大小是128KB，起始地址可以是0x20000的整数倍的任何数。区域的大小可以是4KB~4GB的2的任意乘幂。

下图和下表说明CP15:c6:c0~CP15:c6:c7的8个次寄存器的位域和格式。最高位域[31:12]保存起始地址，起始地址必须是大小域[5:1]的整数倍。E位域[0]使能或禁用该区域。也就是说，区域可以被定义和禁用，因此其属性直到使能位被置位才有效。CP15:c6次寄存器中未定义的位必须置为0。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686712415511.png" alt="1686712415511" style="zoom: 25%;" />

下表是CP15:c6:c0~CP15:c6:c7的寄存器位域描述

| 域名     | 位域    | 注释                                       |
| -------- | ------- | ------------------------------------------ |
| 起始地址 | [31:12] | 比4KB大的地址必须是[5:1]中表示的大小的倍数 |
| SBZ      | [11:6]  | 必须置为0                                  |
| N        | [5:1]   | 区域的大小尺寸为2^N+1，11<=N<=31           |
| E        | [0]     | 区域使能，1 = 使能，0 = 禁用               |

可以使用公式来定义区域的大小，在CP15:c6寄存器的大小位域中填入指数N来设置大小。硬件设置时，限制N的值为11~31的任意值，表示大小为4KB~4GB。确定了区域的大小后，区域的起始地址可以用公式算出。区域的大小和起始地址，与系统的存储器映射和控制系统必须保护的空间有关。（起始地址只有[31:12]，低12位没有，都是0）

本章最后的示例系统说明在给定的系统存储器映射中如何建立区域。

处理器有8个区域，通过写CP15:c6:cX的次寄存器来设置区域的大小和位置。比如，将区域3的位置和大小设置成起始地址为0x300000、大小为256KB的指令序列如下：

```assembly
MOV r1,#0x300000
ORR r1,r1,#0x11 << 1;需要将0x11投放到[5:1]，根据2^17+1=256KB，此时r1 = 0000 0000 0011 0000 0000 0000 0010 0010，此时[0]=0表示禁用区域，[5:1]=10001表示256KB，高五位是0x300，难道此时起始地址是0x300，只认高20位，低位默认0作为起始地址
MCR p15,0,r1,c6,c3,0;c3表示区域3，起始地址是0x300000，禁用，大小是256KB，数据区域
```

先在内核的寄存器r1中填入所需的位域值，然后用MCR指令将r1的值写入CP15的次寄存器。

ARM940T有8个指令区域和8个数据区域，需要一个附加的操作码2修正值来选择是指令区域还是数据区域。若为数据区域，则操作码2为0；若为指令区域，则操作码2为1。

例如，需要2条MRC指令才能读取数据区域和指令区域的大小和位置，一条读数据区域的大小和位置，一条读指令区域的大小和位置。读取区域5的大小和起始地址的指令如下：

```assembly
MRC p15,0,r2,c6,c5,0;r2 = 数据区域5的起始地址和大小
MRC p15,0,r3,c6,c5,1;r3 = 指令区域5的起始地址和大小
```

第一条指令将数据区域5的起始地址和大小装载到内核的寄存器r2中（格式应该和当初写入的 r1内容一样），第二条指令将指令区域5的大小和起始地址装载到内核的寄存器r3中。ARM940T是目前唯一的指令区域和数据区域分离的处理器核。

例13.1说明怎样设置区域的起始地址、大小和使能位。

例程regionSet的C函数原型如下：

```c
void regionSet(unsigned region,unsigned address,unsigned sizeN,unsigned enable);
```

这个例程有4个无符号整型的输入参数：要配置的区域、区域的起始地址、编码以后的区域的大小sizeN以及区域是使能还是禁止。在改变区域的属性时，最好是先禁用它，然后在改变完成以后再重新使能它。

为了使这个例程可以在全部4个，带MPU的处理器上运行，可以通过配置指令区域和数据区域的大小和起始地址信息来统一处理器的区域空间。为了实现这个功能，编写的宏SET_REGION包含两部分：一部分专为ARM940T；另一部分为其他核。这样，相同的例程就可以支持4个带MPU的核了。（这里是为了SMP对称多处理器设置的宏）

```c
#if defined(__TARGET_CPU_ARM940T)
#define SET_REGION(REGION_NUMBER) \
	__asm{MCR p15,0,c6f,c6,c##REGION_NUMBER,0} \/*这里是拼接符的使用，REGION_NUMBER是传入的参数如果为6，则是c6*/
	__asm{MCR p15,0,c6f,c6,c##REGION_NUMBER,1}
#endif
#if defined(__TARGET_CPU_ARM946E_S)|\
	defined(__TARGET_CPU_ARM1026EJ_S)
#define SET_REGION(REGION_NUMBER)\/*设置区域的起始地址和大小，这是针对946和1026的，这是冯诺依曼结构吧，统一的*/
	__asm{MCR p15,0,c6f,c6,c##REGION_NUMBER,0}
#endif
void regionSet(unsigned region,unsigned address,unsigned sizeN,unsigned enable)
{
    unsigned c6f;
    c6f = enable |(sizeN << 1) | address;//起始地址+使能位+大小
    switch(region)
    {
        case 0:{SET_REGION(0);break;}
        case 1:{SET_REGION(1);break;}
        case 2:{SET_REGION(2);break;}
        case 3:{SET_REGION(3);break;}
        case 4:{SET_REGION(4);break;}
        case 5:{SET_REGION(5);break;}
        case 6:{SET_REGION(6);break;}
        case 7:{SET_REGION(7);break;}
        default:{break;}
    }
}
```

代码首先将起始地址、sizeN和使能位等区域属性合并到一个无符号整形变量c6f；然后跳转到用宏SET_REGION创建的8个regionSet例程之一，SET_REGION通过写CP15:c6次寄存器，为定义的区域设置起始地址、大小和使能状态。一个函数都实现了，宏判定使用的哪个cpu

#### 13.2.2访问权限

有2组可用的访问权限机制：标准组合扩展组。4个核都支持标准组，标准组有4级权限。ARM946E-S和ARM1026EJ-S支持扩展组，扩展组增加了额外的两级权限。扩展组AP访问权限位域编码支持12个增加的权限值，现在只有2个值有定义。使用未定义的编码，将导致不可预知的结果。

| 管理者   | 用户     | 标准AP值编码 | 扩展AP值编码 |
| -------- | -------- | ------------ | ------------ |
| 不可访问 | 不可访问 | 00           | 0000         |
| 读/写    | 不可访问 | 01           | 0001         |

这个表中的管理者和用户是啥，权限是存储器区域的权限，就是在什么处理器模式下可以访问

通过CP15:c5的次寄存器来分配区域的访问权限。次寄存器CP15:c5:c0:0和CP15:c5:c0:1配置标准的AP，次寄存器CP15:c5:c0:2和CP15:c5:c0:3配置扩展的AP。（为啥有俩指令配置标准的AP，因为操作码2为0对应数据区域、1对应指令区域）

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686727156245.png" alt="1686727156245" style="zoom:25%;" />

这里可以看到，标准AP只占2位，AP0表示区域0的标准AP权限，共8区域，所以占用16位。扩展AP占4位，eAP0表示区域0的扩展AP权限，占用32位。

支持扩展权限的处理器也可以运行，为标准权限编写的软件。有效的权限类型**取决于对CP15 AP寄存器的最后一次写入**：最后一次写入的AP寄存器是标准AP寄存器，则内核使用标准权限；若最后一次写入的AP寄存器是扩展AP寄存器，则内核使用扩展权限。

这样做的原因是，写标准AP寄存器也更新了扩展AP寄存器，即扩展AP区域的高位[2:3]被清除了。也就是每个区域的AP高两位被清除。

当使用标准AP时，每个区域在寄存器CP15:c5:c0:0和CP15:c5:c0:1中有2位。CP15:c5:c0:0设置数据AP，CP15:c5:c0:1设置指令区域。

读指令和数据空间的标准AP，需要读2个寄存器。下面的2句MRC指令序列将数据区域的AP信息放在r1中，指令区域的AP信息放在寄存器r2中：

```assembly
MRC p15,0,r1,c5,c0,0;数据区域标准AP
MRC p15,0,r2,c5,c0,1;指令区域标准AP
```

如果是扩展AP，则每个区域在寄存器CP15:c5:c0:2和CP15:c5:c0:3中有4位。内核将8个区域的指令信息保存在一个寄存器中，数据信息保存在另一个寄存器中。CP15:c5:c0:2设置数据区域的AP，CP15:c5:c0:3设置指令区域的AP。

要获取指令和数据区域的扩展AP，也需要读2个寄存器。下面的2句指令序列将数据区域的AP放在核寄存器r3中，指令区域的AP放在寄存器r4中：

```assembly
MRC p15,0,r3,c5,c0,2;数据区域扩展AP
MRC p15,0,r4,c5,c0,3;指令区域扩展AP
```

下面将用2个例子来说明如何使用访问权限。一个说明标准AP，另一个说明扩展AP。这两个例子使用内嵌汇编代码来读/写CP15寄存器。

这里提供2个标准AP例程：regionSetISAP和regionSetDSAP，以设置区域的标准AP位。在C中调用时，使用下面的函数原型：

```c
void regionSetISAP(unsigned region,unsigned ap);
void regionSetDSAP(unsigned region,unsigned ap);
```

第一个参数是区域号，第二个参数是2位的值，用来定义被区域控制的指令或数据空间的标准AP。

例13.2两个例程除了读/写不同的CP15:c5次寄存器外，几乎完全相同：一个是读/写指令寄存器，另一个是读/写数据寄存器。例程通过对CP15:c5寄存器进行简单的读-修改-写操作来设置指定区域的AP，而不改变其他区域的配置。

```c
void regionSetISAP(unsigned region,unsigned ap)
{
    unsigned c5f,shift;
    shift = 2 * region;//这是因为2位标准AP，需要乘2找到对应的区域AP
    __asm{MRC p15,0,c5f,c5,c0,1}/*装载标准数据AP*/
    c5f = c5f &~(0x3 << shift);//&~的操作就是BIC，0x3==11，左移到对应AP区域位置，所以就是清除对应区域值
    c5f = c5f | (ap << shift);//设置新的ap位
    __asm{MCR p15,0,c5f,c5,c0,1}//保存标准数据AP
}
void regionSetDSAP(unsigned region,unsigned ap)
{
    unsigned c5f,shift;
    shift = 2 * region;//设置位域宽度
    __asm{MRC p15,0,c5f,c5,c0,0}
    c5f = c5f &~(0x3 << shift);
    c5f = c5f | (ap << shift);
    __asm{MCR p15,0,c5f,c5,c0,0}
}
```

例程设置了特定区域的权限，先使用一个被移位的屏蔽码来清除AP位，然后用AP输入参数来设置ap位域。**AP位域的位置是区域号乘以权限位域的位数**，即变量shift。通过移位ap值和使用OR指令来修改c5f核寄存器，以设置位域值。

这里提供两个扩展AP例程：regionSetIEAP和regionSetDEAP，以设置区域的扩展AP位。他们的C函数原型如下：

```c
void regionSetIEAP(unsigned region,unsigned ap);
void regionSetDEAP(unsigned region,unsigned ap);
```

第一个参数是区域号，第二个参数是4位的值，表示由区域控制的指令或数据存储空间的扩展AP。

例13.3,2个例程除了读/写不同的CP15:c5次寄存器和4位宽的AP位域外，与标准AP例程几乎完全相同。

```c
void regionSetIEAP(unsigned region,unsigned ap)
{
    unsigned c5f,shift;
    shift = 4 * region;
    __asm{MRC p15,0,c5f,c5,c0,3}/*设置位域宽度*/
    c5f = c5f &~(0xf << shift);
    c5f = c5f |(ap << shift);
    __asm{MCR p15,0,c5f,c5,c0,3}
}
void regionSetDEAP(unsigned region,unsigned ap)
{
    unsigned c5f,shift;
    shift = 4*region;
    __asm{MRC p15,0,c5f,c5,c0,2}
    c5f = c5f &~ (0xf << shift);
    c5f = c5f | (ap << shift);
    __asm{MCR p15,0,c5f,c5,c0,2}
}
```

每个例程都是用一个移位后的屏蔽码来清除AP位，然后用ap输入参数设置AP位域，以设置指定的区域权限。

#### 13.2.3设置区域的cache和写缓冲器属性

每个内核有3个CP15寄存器用过来控制区域的cache和写缓冲器属性。其中CP15:c2:c0:0和CP15:c2:c0:1两个寄存器保存D-cache和I-cache区域属性；第三个寄存器CP15:c3:c0:0用于保存区域写缓冲器属性，并应用于**存储器数据区域。**（指令区域和写缓冲器无关。因为指令不会被修改，也就不需要写回主存，自然不需要通过写缓冲器到主存）因为cache本身的数据就是从主存中来的，配置主存区域的cache属性其实就是配置cache的属性，之前只学过清理清除锁定cache，没有配置cache。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686731065960.png" alt="1686731065960" style="zoom:25%;" />

SBZ意思是should be zero，还有SBO不知道啥意思。寄存器CP15:c2:c0:1包含所有8个指令区域的cache配置信息，寄存器CP15:c2:c0:0包含所有8个数据区域的cache配置信息。这两个寄存器使用相同的位域编码。

cache位决定对区域内一个给定的地址是否使能cache。如果控制器找到一个有效的cache数据项，那么他就使用cache内的数据，而不使用外部存储器的数据。每次查找cache是不会考虑cache位的状态。

基于这个cache特征，当cache策略从使用cache变为不使用cache时，必须清除并可能要清理区域的cache。因此，MPU控制系统每次改变cache写策略，从直写变为禁用cache时，都必须清除cache；而从回写变为禁用cache时，都必须清理并清除cache；而从回写变为直写时，必须清理cache。（比如，现在明明已经禁用cache了，但是每次cpu还是会从cache中读取数据，为此在每次禁用的时候必须清除cache）

在ARm946E-S中，如果cache位被清除，则物理上存储在cache中的信息将不从cache中返回，而是直接访问外部存储器。（就是说这种处理器内核会考虑禁用cache的情况）这种设计减少了当cache被禁用时清除cache的次数，然而，原来区域的清理规则仍然适用。

寄存器CP15:c3:c0:0中的8个区域写缓冲器位，使能或禁用每个区域的写缓冲器。

当配置数据区域时，区域的cache位和写缓冲器位一起决定区域的策略。写缓冲器位有两个用途：使能或禁用区域的写缓冲器和**设置区域的cache写策略**。区域的cache位控制写缓冲器位的作用。

- 当cache位为0时，写缓冲器位为1，则使能写缓冲器；写缓冲器位为0，则禁用写缓冲器。
- 当cache位为1时，cache和写缓冲器都被使能，此时写缓冲器位决定cache写策略。此时写缓冲器位为0，则区域使用直写策略；若写缓冲器位为1，则区域使用回写策略。

下图是cache和写缓冲器控制的表

因为指令cache不需要写入主存，所以不使用写缓冲器。

| 指令cache             |             | 数据cache             |                          |                                                              |
| --------------------- | ----------- | --------------------- | ------------------------ | ------------------------------------------------------------ |
| cache位，CP15:c2:c0:1 | 区域属性    | cache位，CP15:c2:c0:0 | 写缓冲器位，CP15:c3:c0:0 | 区域属性                                                     |
| 0                     | 不使用cache | 0                     | 0                        | NCNB                                                         |
| 1                     | 使用cache   | 0                     | 1                        | NCB，这里不使用cache但是会使用写缓冲器。（写缓冲器是cache和主存的连接通道，不使用cache，其实写缓冲器也没用） |
|                       |             | 1                     | 0                        | 使用cache，直写策略。（使用cache，必然使用写缓冲器）         |
|                       |             | 1                     | 1                        | 使用cache，回写策略                                          |

这里给出两个例程来示范使能和禁用区域的cache和写缓冲器属性。这两个例程使用内嵌汇编来读写CP15寄存器。

通过合并cache和写缓冲器的控制为一个简单的例程调用，以简化系统配置。通过他们控制的写策略来引用数据cache位和写缓冲器位，指令cache位单独表示。从系统角度来看，为**每个区域合并cache和写缓冲器为一个单独的值**，容易将区域信息分组到一个区域控制块。

设置区域的cache和写缓冲器属性的例程，称为regionSetCB，在例13.4中表示，并有下面的C函数原型：

```c
void regionSetCB(unsigned region,unsigned CB);
```

例程有2个输入参数：第一个参数region，是区域号；第二个参数CB，合并区域指令cache属性和数据cache与写缓冲器属性。

第二个参数有格式，使用无符号整数的低3位：位[2]代表指令cache位，位[1]代表数据cache位，位[0]代表数据写缓冲器位。

例13.4设置cache和写缓冲器

例程顺序设置数据写缓冲器位、数据cache位和数据cache位。对每个位，都是先读出CP15的寄存器；然后清除原来的位值，并设置新的位值；最后将值写回到CP15的寄存器。

```c
void regionSetCB(unsigned region,unsigned CB)
{
    unsigned c3f,tempCB;
    tempCB = CB;
    __asm{MRC p15,0,c3f,c3,c0,0}/*装载写缓冲器控制寄存器*/
    c3f = c3f &~(0x1 << region);/*清除原来的写缓冲器位*/
    c3f = c3f | ((tempCB & 0x1) << region);/*设置新的写缓冲器位*/
    __asm{MCR p15,0,c3f,c3,c0,0}/*写回写缓冲器*/
    //写缓冲器重新配置完成
    tempCB = CB >>0x1;//移位至数据cache位
    __asm{MRC p15,0,c3f,c2,c0,0}//装载数据cache控制寄存器
    c3f = c3f &~(0x1 << region);
    c3f = c3f | ((tempCB & 0x1) << region);//设置数据cache位
    __asm{MCR p15,0,c3f,c2,c0,0}
    //设置完数据cache
    tempCB = CB >> 0x2;//移位至指令cache
    __asm{MRC p15,0,c3f,c2,c0,1}//装载指令cache控制寄存器
    c3f = c3f &~(0x1 << region);
    c3f = c3f | ((tempCB & 0x1) << region);//设置新的指令cache位
	__asm{MCR p15,0,c3f,c2,c0,1}//保存指令cache控制信息
}
```

#### 13.2.4使能区域和MPU

初始化还剩下2步：一步是使能活动的区域；另一步是通过使能MPU、cache和写缓冲器来启用保护单元硬件。（之前是配置区域起始地址、区域大小，并没有使能区域，然后配置区域的cache和写缓冲器属性，现在就剩下使能区域以及MPU、cache、写缓冲区，毕竟都已经配置完了）

这里控制系统再次用到之前介绍的regionSet例程，使能一个区域。regionSet的多种用途最后介绍。

为了使能MPU、cache和写缓冲器，须修改系统控制寄存器**CP15:c1:c0:0**中的位值。在某些处理器内核中，MPU位、cache位和写缓冲器位在CP15:c1:c0中的位置是相同的，因此对于这3个核，使能配置好的MPU是一样的。使能位的位置见下图。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686795330219.png" alt="1686795330219" style="zoom:25%;" />

CP:c1:c0寄存器还有其他的没有在上图表示出的配置位，这些位的目的和位置是与处理器相关的，并不是保护系统的一部分。

下表是CP15控制寄存器1的保护单元使能位。

| 位   | 使能的功能 | 值           |
| ---- | ---------- | ------------ |
| 0    | MPU        | 0禁用，1使能 |
| 2    | 数据cache  | 0禁用，1使能 |
| 12   | 指令cache  | 0禁用，1使能 |

这里使用changeControl例程，使能MPU和cache。changeControl例程可以修改CP15:c1:c0:0寄存器中的任意位置的值。它有下面的C函数原型：

```c
void controlSet(unsigned value,unsigned mask);
```

传递的第一个无符号整型参数包含需改变的**位值**。第二个参数用来选择要改变的**位**；位值1改变控制寄存器的相应位；位值0则保持相应位值不变，而不管第一个参数的位状态。说白了，第一个参数决定值改变成啥，第二个参数决定哪个位的值需要改变

例如，若使能MPU和I-cache，禁用D-cache，则设置位[12]为1，位[2]为0，位[0]为1.第一个参数的值就应为0x00001001，剩下的不改变的位为0.为了只选择位[12]、位[2]和位[0]这些要改变的位，将屏蔽码设置为0x00001005。==0001 0000 0000 0101 

例13.5读取控制寄存器，将值保存在一个寄存器中；然后用屏蔽输入值清除所有要改变的位，用value值设置其为希望的状态；例程最后将新的控制值写到CP15:c1:c0寄存器。

```c
void controlSet(unsigned value,unsigned mask)
{
    unsigned int c1f;
    __asm{MRC p15,0,c1f,c1,c0,0}
    c1f = c1f &~ mask;//清除要修改的位
    c1f = c1f | value;//设置要改变的位
    __asm{MCR p15,0,c1f,c1,c0,0}//写控制寄存器
}
```

### 13.3MPU系统示例

本章前面已经介绍了一系列例程，这些例程可以作为构建块来使用，以初始化和控制一个受保护的系统。本节使用这些例程来初始化和控制一个简单的受保护系统，该系统使用固定的存储器映射。

MPU系统示例使用本章前面几节介绍的例子，以创建一个实用的受保护的系统。它提供了在一个简单的受保护多任务系统中运行3个任务的基本框架。这个例子能够清晰地说明ARM MPU硬件的概念。该实例用C语言编写，实用标准访问权限。

---

我现在对整体没有一个认识，之前学的uboot和kernel启动忘了，现在这个添加了MPU来保护，脑子混沌，我学完这本书，需要总结下他们各自的功能。

---

#### 13.3.1系统需求

本实例系统有以下一些硬件特征：

- 一个带MPU的ARM核；
- 256KB的物理存储器，起始地址为0x0，结束地址为0x4000；
- 一些存储器映射的外设，位于0x10000000~0x12000000的几兆字节空间里。

只有256KB的空间怎么映射到那么远的地址上。

在本例中，所有的存储器映射外设，被看做是一个需要保护的存储器独立空间。

本实例系统有以下一些软件模块：

- 系统软件小于64KB。包括向量表、异常处理程序和支持异常的数据堆栈。（各个模式堆栈）。系统软件必须是用户模式下程序不可访问的，也就是说，用户模式下的任务必须通过系统调用来运行或访问在这个区域中的代码或数据。（就是说必须软中断到svc模式才能访问该区域）
- 有一个小于64KB的共享程序，包括通用库和用户任务间传递消息的数据空间。
- 有3个在系统中控制独立功能的用户任务。这些任务每个小于32KB，当这些任务运行时，他们不能被其他2个任务访问。

很好，这个例子真的很吸引我，可以看到内核空间和用户空间的影子。

这些软件被连接，并将软件模块放在分配给他们的区域内。这个实例软件的存储器映射如下表所示。系统软件的访问权限是系统级的，共享的程序空间可被整个系统访问，任务程序区域包含用户级任务。

| 功能                     | 访问级别 | 起始地址   | 大小 | 区域 |
| ------------------------ | -------- | ---------- | ---- | ---- |
| 保护存储器映射的外围设备 | 系统     | 0x10000000 | 2MB  | 4    |
| 受保护的系统             | 系统     | 0x00000000 | 4GB  | 1    |
| 共享的系统               | 用户     | 0x00010000 | 64KB | 2    |
| 用户任务1                | 用户     | 0x00020000 | 32KB | 3    |
| 用户任务2                | 用户     | 0x00028000 | 32KB | 3    |
| 用户任务3                | 用户     | 0x00030000 | 32KB | 3    |

这里三个进程都在同一个区域内，那他们岂不是可以互相访问了，三个进程栈在同一个区域内，就是这么理解的，可以运行期间首先修改该用户任务区域的属性，这样可以保证其他进程无法访问了。运行结束后还原区域属性。（现在还没有进程地址空间的概念，就是进程堆栈+寄存器这就是进程的空间了）

#### 13.3.2使用存储器映射分配区域

上表的最后一列为分配给取出器空间的四个区域。使用该表中列出的起始地址、代码、数据块的大小来定义区域。表示区域布局的存储器映射如下。下面的图非常好！！！！ARM体系结构真的是太有学习的必要了，对于这个存储空间。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686799736390.png" alt="1686799736390" style="zoom:25%;" />

首先，从这张图可以看出，区域1和区域4权限属于系统级的，区域的权限针对svc和用户模式，也就是说这里是非用户访问区域，其实就是内核空间的雏形。六种模式堆栈中的五个都在内核空间中，只有用户堆栈是在用户空间，那些进程堆栈就是在用户堆栈中，第一个进程的堆栈起始地址就是用户堆栈的起始地址。设备IO虽然距离其他区域非常远但不影响其访问权限。任务1和3在未运行时属于区域1，当运行时将区域3重叠实现用户访问的功能。

区域1是一个背景区域，覆盖整个可寻址的存储器空间。他是一个特权区域（不允许用户模式下的访问），使能指令cache，数据cache使用直写策略操作。该区域的优先级最低，因为他是最小分配号的区域。（之前没有提到对优先级的配置问题，分配号是什么）

区域1的主要功能是限制对0x0~0x10000之间的64KB空间的访问，即受保护的系统区域。区域1还有另外两个功能：作为背景区域和作为睡眠态用户任务的保护区域。

作为背景区域，他保证整个存储器空间默认被分配系统级访问，这样就能防止用户任务访问备用的或未用的存储空间；

作为用户任务保护区域，他保护睡眠态任务不受运行态任务的非法访问。（内核空间的固定1GB是虚拟地址，物理地址可能是离散的，这样的话和这种动态划分一样）

区域2控制对共享系统资源的访问。它的起始地址为0x10000，大小为64KB。它直接映射在共享系统代码的共享存储器空间上。区域2是受保护的区域1的一部分，但优先于受保护的区域1，因为它有较高的区域号。区域2允许用户级和系统级的存储器访问。（就是说用户模式和非用户模式都可以访问）

区域3控制运行任务的存储器空间和属性。当控制权从一个任务传给另一个任务时，**它将原来任务的空间交给区域1的属性控制**。原来的任务变成了区域1的一部分，而当前运行的任务是一个新的区域3.这样运行任务就不能访问原来的任务空间，因为它受区域1属性的保护。

区域4是存储器映射的外围系统空间。该区域的主要目的是，建立没有cache和没有写缓冲器的空间。这样，在对控制寄存器和I/O设备操作时，就不会涉及到高速缓存可能产生的陈旧数据信息，同时还可以避免使用写缓冲导致的时间或顺序问题。（是不是C语言上用volatile关键字底层实现就是将该数据分配到外围系统空间，数据虽然不会被缓存，但可能存放在寄存器中，这个关键字还保证不会从寄存器中读取该数据。网上找不到具体实现，由编译器实现的）

#### 13.3.3初始化MPU

为了便于组织初始化过程，这里创建了一个称为Region的结构。该结构的成员项保存系统操作中使用的区域的属性。在使用MPU时，Region结构并不是必须的（直接MCR配置协处理器实现的，这里这是更方便设计，和Linux内核中的VMA区域一个意思），这个示例中，称这些数据结构的集合为一个区域控制块RCB(Region Control Block)。

初始化程序（内核的第一个程序）使用存储在RCB中的信息来配置MPU中的区域。可以在RCB中定义比物理区域更多的Region结构。因为物理区域会不断的修改起始地址。肯定会比8个区域要大的。例如，区域3是任务使用的唯一物理区域，但是它对应3个Region结构，每个用户任务使用一个Region结构。该结构的定义如下：

```c
typedef struct{
    unsigned int number;//MPU区域号，也就是优先级，这里的区域号就是0~7，数越大优先级越高。
    unsigned int type;//使用的标准AP还是扩展AP(attend priority)
    unsigned int baseaddress;//区域起始地址
    unsigned int size;//区域大小
    unsigned int IAP;//指令区域的AP权限
    unsigned int DAP;//数据区域的AP权限
    unsigned int CB;//区域的Icache/Dcache/写缓冲器配置
}Region;
```

示例中RCB的6个Region结构体如下：

```c
/*区域号、AP类型、起始地址、大小、IAP、DAP、CB*/
Region peripheralRegion = {PERIPH,STANDARD,
                         0x10000000,SIZE_1M,RONA,RWNA,ccb};/*NA表示不可访问，这里是指令区域管理模式只读、用户不可访问，数据区域管理模式可读写，用户不可访问，指令cache不使用，不使用数据cache和写缓冲器*/
Region kernelRegion = {KERNEL,STANDARD,0x00000000,SIZE_4G,RONA,RWNA,CWT};/*使用指令cache、对于数据cache采用直写策略，WT==Cb，数据cache位1，写缓冲器位0*/
Region sharedRegion = {SHARED,STANDARD,0x00010000,SIZE_64K,RORO,RWRW,CWT};/*共享部分的指令区域是只读只读，数据区域是读写读写*/
Region task1Region = {TASK,STANDARD,0x00020000,SIZE_32K,RORO,RWRW,CWT};
Region task2Region = {TASK,STANDARD,0x00028000,SIZE_32K,RORO,RWRW,CWT};/*区域号是TASK，指令部分只读只读，数据区域读写读写*/
```

访问RCB时，为了增强可读性，创建下面一系列的宏，值得注意的是，这里使用一个4字母的简单组合，以作为数据存储器指令存储器的访问权限。前2个字母表示系统访问权限，后两个字母表示用户访问权限。表示系统的用户访问权限的两个字母可以是读写RW、只读RO、不可访问NA。

这里将cache和写缓冲器配置信息映射到指令cache和数据cache的策略属性。第一个字母为C或c，分别表示启用或禁用区域的指令cache。后两个字母表示数据cache策略和写缓冲器配置，可以为WT或WB，分别表示直写策略或回写策略。cache位和写缓冲器位的配置也可以使用字母c和b。Cb为WT的别名，CB为WB的别名，cB表示禁用cache和启用写缓冲器，cb表示禁用cache和禁用写缓冲器。

#### 13.3.4初始化和配置区域

接下来介绍configRegion例程。configRegion接受RCB中的一个Region结构指针来配置CP15寄存器，使CP15寄存器保存有描述区域的数据。

```c
/*区域号分配（优先级分配）*/
#define BACKGROUND 0
#define KERNEL 1
#define TASK 2
#define SHARED 3
#define PERIPH 4
/*区域类型分配*/
#define STANDARD 0
#define EXTEMDED 1
#define DISABLE 0
/*访问权限*/
#define NANA 0
#define RWNA 1
#define RWRO 2
#define RWRW 3
#define RONA 5
#define RORO 6
/*区域大小*/
#define SIZE_4G 31
#define SIZE_2G 30
#define SIZE_1G 29
#define SIZE_512M 28
#define SIZE_256M 27
#define SIZE_128M 26
#define SIZE_64M 25
...
#define SIZE_4K 11
/*AP*/
	#define CCB 7
    #define CWB 7
    #define CCb 6/*110*/
    #define CWT 6
    #define CcB 5
    #define Ccb 4
    #define cCB 3
    #define cWB 3
    #define cCb 2
    #define cWT 2
    #define ccB 1
    #define ccb 0
    /*区域使能*/
	#define R_ENABLE 1
    #define R_DISABLE 0
```

例程遵循在13.2节列出的初始化步骤。输入参数是一个指向区域RCB的指针。例程内部使用Region的成员项作为初始化过程的数据输入。该例程的C函数原型如下：

```c
void configRegion(Region *region);
```

例13.6初始化受保护系统的MPU、cache和写缓冲器。

初始化过程中使用了本章前面介绍的例程。执行该例程就初始化了MPU。

```c
void configRegion(Region * region)
{
    /*第一步，使用CP15:c6来定义指令和数据区域的大小和位置*/
    regionSet(region->number,region->baseaddress,region->size,R_DISABLE);//此时不使能，至于指令和数据各自的划分没有体现，这应该是读取的时候识别出指令还是数据
    /*第二步，使用CP15:c5来设置每个区域的访问权限*/
    if(region->type == STANDARD){
        regionSetISAP(region->number,region->IAP);
        regionSetDSAP(region->number,region->DAP);
    }else if(region->type == EXTENDED)
    {
        regionSetIEAP(region->number,region->IAP);
        regionSetDEAP(region->number,region->DAP);
    }
    /*第三步，分别使用CP15:c2和CP15:c3来设置每个区域的cache和写缓冲器属性*/
    regionSetCB(region->number,region->CB);
    /*第四步，使用CP15:c6使能区域*/
    regionSet(region->number,region->baseaddress,region->size,R_ENABLE);/*所谓的使能cache、写缓冲器和MPU是controlSet函数实现的，这里只实现了使能区域，写缓冲区不需要使能*/
}
```

#### 13.3.5完成初始化MPU

对于该实例，使用RCB来保存描述所有区域的数据，**使用最高层的名为initActiveRegions的例程来初始化MPU**。在系统启动时，该例程被调用一次，为每个活动的区域进行设置。为了完成初始化工作，例程也使能了MPU。该例程的C函数原型如下：

```c
void initActiveRegions()
```

该例程没有输入参数。

例13.7首先为每个在系统启动时处于活跃状态（这里与其说活跃状态，不如说系统启动时就存在的区域）下的区域调用一次configRegion:kernelRegion，sharedRegion，peripheralRegion和task1Region。

在该实例中，任务1是运行的第一个任务。最后调用例程controlSet来使能cache和MPU。

```c
#define ENABLEMPU (0x1)
#define ENABLEDCACHE (0x1 << 2)
#define ENABLEICACHE (0x1 << 12)
#define MASKMPU (0x1)
#define MASKDCACHE (0x1 << 2)
#define MASKICACHE (0x1 << 12)
void initActiveRegions()
{
    unsigned int value,mask;
    configRegion(&kernelRegion);
    configRegion(&sharedRegion);
    configRegion(&peripheralRegion);
    configRegion(&task1Region);/*配置并使能任务1的区域*/
    value = ENABLEMPU | ENABLEDCACHE | ENABLEICACHE;
    mask = MASKMPU | MASKDCACHE | MASKICACHE;
    controlSet(value,mask);/*最后将Icache、Dcache、MPU使能*/
}
```

#### 13.3.6受保护系统的上下文切换

至此已经完成了初始化示例系统，控制系统也已经运行了它的第一个任务。在某个时刻，系统可能须做上下问切换，以运行另一个任务。（之前学的是无硬件保护的上下文切换，主要考虑的就是进程栈和寄存器之间的保存恢复上下文）

**RCB中包含当前任务的区域的上下文信息**，所以在上下文切换时，无须通过从CP15寄存器读取数据来保存区域信息。（之前没有RCB的概念，只有PCB，其中保存了进程栈大小和起始地址，没有任务区域这个概念，这个任务区域是任务运行的空间，这个任务区域应该包含了进程栈，有没有别的东西呢）

为了切换到下一个任务，比如任务2，操作系统须将区域3移动到任务2的存储空间上个。这里再次使用例程configRegion实现功能。作为调度的一部分，只需在执行实现当前任务和下一个任务间上下文切换的代码之前调用configRegion。

---

总的来说，就是初始化代码多了一个初始化cache/MPU，存储空间上变成了各个区域来覆盖之前的模式堆栈。上下文切换多了一个步骤需要先移动区域到下一个任务上。任务区域覆盖任务堆栈的目的应该只是为了提供保护

---

例程configRegion的输入参数是指向task2Region的指针，请看下面的汇编代码例子：

```assembly
STMFD sp!,{r0-r3,r12,lr}
BL configRegion ;此时cache和MPU都使能了，上下文切换只是修改某一个区域位置而已，输入的task2Region的指针
LDMFD sp!,{r0-r3,r12,pc};这里的sp应该是下一个任务的PCB地址，这个存放在当前任务PCB的成员中
```

#### 13.3.7mpuSLOS

本章的许多概念和例子代码被包含到一个被称之为mpuSLOS的实用控制系统中。

mpuSLOS是第11章介绍的、SLOS的带存储器保护单元的变体。它实现了与基本的SLOS相同的功能，但有以下重要的区别：

- mpuSLOS充分利用了MPU；

- 应用程序需与内核分开，**单独编译和构建build**，然后合并到一个二进制文件；连接每个应用程序，**使他们在不同的存储空间上执行**。（链接的过程其实就是makefile的过程，一堆依赖文件生成目标文件的过程就是链接，链接各种系统支撑的库文件，毕竟使用了人家的提供的API，得把API的实现包含进来）这里单独编译就是各个整体。应用程序的数据单独在任务区域，而不是所有的应用程序的数据混一起了

- 每个应用程序被一个称为静态应用程序装载器的例程，**装载到不同的固定大小为32KB的区域**，装载地址是应用程序的执行地址。因为每个区域大小为32KB，所以把堆栈指针设置在32KB的顶端。（现在进程从外存装载到内存就是直接装载到任务区域，**指令+数据+进程栈都在这？**，这就是我的疑问，任务区域内到底有啥？）

- 应用程序只能通过只能通过设备驱动程序调用访问硬件。如果应用程序试图直接访问硬件，那么将产生数据中止异常。这与基本的SLOS不同，在基本的SLOS中，硬件程序直接访问设备，而不产生数据中止异常。（因为设备也就是寄存器映射在区域1中，用户没有权限访问了）

- 跳转到一个应用程序的操作包括：设置spsr寄存器，然后使用MOVS指令来改变pc，使它指向任务1的入口。

  -----

  进程栈是创建进程的时候分配的，所以无存储保护单元的时候，进程和内核都放在一起，一起装载到主存中，先创建模式堆栈，每调用一个进程创建一个进程栈，栈内存放上下文、局部变量、返回地址。而现在有存储保护单元了，每个进程非常独立，在装载进内存的时候就把指令+数据放到任务区域了，等到执行任务的时候再分配对应的进程栈到任务堆栈的起始地址。之前只有进程栈是独立的，指令和数据都是放在一起的

  ----

- 每次调用调度程序，活跃的区域2就被改变，以反映将要执行的应用程序。

### 13.4总结

存储器保护有两个钟方法：一种是无硬件保护的，这种方法使用强制的软件控制例程来维护任务间相互作用的规则；另一种是有硬件保护的，这种方法使用硬件和软件来强制维护任务间相互作用的规则。在受保护的系统里，当访问权限非法时，硬件产生一个异常来保护存储空间，然后软件做出响应，以处理该异常和管理基于存储器的资源。

ARM中的MPU使用区域作为系统保护的主要概念。区域是一个存储空间属性的集合，也代表一个具有特定属性的逻辑存储空间。区域可以重叠，这样就可以使用背景区域来保护睡眠任务的存储空间不受当前运行任务的非法访问。

初始化MPU需要多个步骤，本章介绍了设置各种区域属性的例程。第一步是使用**CP15:c6**来设置指令区域和数据区域的大小和位置；第二步是使用CP15:c5来设置每个区域的访问权限；第三步是分别使用**CP15:c2**和**CP15:c3**来设置每个区域的cache和写缓冲器属性；最后一步是使用**CP15:c6**来使能活跃的区域，并使用**CP15:c1**来使能cache、写缓冲器、MPU。

本章最后介绍了一个简单的多任务环境示例系统。系统有3个任务，保护每个任务不受其他2个任务的非法访问。示例系统首先定义一个受保护系统，然后显示了如何额初始化它，初始化之后，运行一个受保护系统的最后一个步骤：在任务切换时，针对下一个任务改变区域分配。mpuSLOS是一个受保护操作系统的实例。

**我的疑问是任务区域内有什么，大于等于进程栈？**

任务区域内应该只有进程栈，进程本身的指令在只读代码段中，全局数据在全局数据段中。任务区域只是在进程创建前在背景区域上重叠出一块区域给该进程。单独编译造成的结果是让代码区、数据区、常量区、静态存储区这些编译期间确定的区域根据每个进程单独划分。而不是任务区域把这些都包括了。32KB的任务区域放不下！装载也是装载到这些已经为每个进程单独划分的区域。

无保护情况下，也是这么做的，但是每个区域不存在访问权限的概念。

## 第十四章，存储管理单元

- 从MPU到MMU
- 虚存如何工作
- ARM MMU的详情
- 页表
- 转换旁路缓冲器
- 域和存储器访问权限
- cache和些缓冲挂起
- 协处理器CP15和MMU配置
- 快速上下文切换扩展
- 示例：一个简单的虚拟存储系统
- MMU SLOS示例
- 总结

在创建多任务嵌入式系统时，最好由一个简单的方式来编写、装载以及运行各自独立的任务。目前的很多嵌入式系统不再使用自己定制的控制系统，而是用操作系统来简化这个过程。较高级的操作系统采用基于硬件的存储管理单元MMU。

MMU提供的一个关键服务是，能使各个任务作为各自独立的程序在其自己的私有存储空间中运行。（MPU只是保证访问权限）在带MMU的操作系统控制下，运行的任务无须知道其他与之无关的任务的存储需求情况，这就简化了各个任务的设计。

第13章介绍了带有存储保护单元MPU的处理器核。这些内核只含一个可寻址的物理存储空间，处理器核运行任务时所产生的地址直接用来访问主存。这样，如果2个程序编译时使用重叠的地址，那么他们不能同时驻留在主存中。这使得在嵌入式系统中运行多个任务比较困难，因为每个任务都必须运行在主存的不同地址块中。

MMU简化了任务编程，因为它提供了一些资源，以允许使用虚拟存储器（虚存）：一个另外的独立于系统物理存储器的存储空间。MMU作为转换器，将程序和数据的虚拟地址转换为实际的物理地址，即在物理主存中的地址。这个转换过程允许运行的多个程序使用相同的虚拟地址，而各自存放在物理存储器的不同位置。

从这样2个角度看存储器，存储器就有2种类型的地址：虚拟地址和物理地址。虚拟地址**由编译器和链接器在定位程序时分配**；物理地址用来访问实际的主存硬件模块。

ARm公司提供了多种集成有MMU硬件的处理器核。这些MMU硬件有效地使用虚存来支持多任务环境。本章的目的就是，学习ARM存储管理单元的一些基本知识和有关虚存使用的一些基本概念。

本章首先回顾一下MPU的保护特性 ，然后提出一些由MMu提供的其他特性。这里将介绍重定位寄存器，他保存用来将虚拟地址转换成物理地址的转换数据；将介绍转换旁路缓冲器TLB（快表），他是一个存放最近地址重定位信息的高速缓存；将介绍如何使用页和页表来配置重定位寄存器。

接下来，要讨论如何通过配置虚存中的页块来创建区域。在概述部分的最后，将演示如何使用MMU和页表来支持多任务。

将详细说明如何配置MMU硬件，分别介绍ARM MMU的每个部件：页表、TLB、访问权限、cache和写缓冲器、控制寄存器CP15:c1，以及快速上下文切换扩展FCSE。

本章的最后将提供一个实例程序来延时如何使用虚存建立一个嵌入式系统。示例程序支持3个任务运行在多任务环境中，并演示如何保护系统中的每个任务不受其他任务的影响。这些任务被编译运行在哦同一个虚存执行地址，而放在物理存储器的不同位置。示例的主要部分是演示如何配置MMU，将一个任务的虚拟地址转换为物理地址以及如何在任务间切换。

本章将示例程序集成到第11章介绍的SLOS操作系统中，称为mmuSLOS。

### 14.1从MPU到MMU

第十三章介绍了带有存储保护单元MPU的ARM核，在那里引入了区域region的概念，以方便组织和保护存储器。区域可以是活跃的，也可以是睡眠的：活跃区域包含当前系统正在使用的代码或数据；睡眠区域包含当前不使用，但可能在短时间内变为活跃的代码或数据。睡眠区域是被保护的，因此当前正在运行的任务是不能访问它的。

| 区域属性 | 配置选项              |
| -------- | --------------------- |
| 类型     | 指令、数据            |
| 起始地址 | 大小的倍数            |
| 大小     | 4KB~4GB，区域最小32KB |
| 访问权限 | 读、写、执行          |
| cache    | 回写法、直写法        |
| 写缓冲器 | 使能、禁用            |

MPU有专门的硬件来给区域分配属性。可以分配给区域的属性如上表所示。

MPU和MMU的主要区别是，MMU中增加了额外的硬件，以**支持虚存**；同时MMU硬件将区域属性从CP15寄存器移到主存中的表，从而增加了有效区域的数目。（CP15只支持8个区域）

### 14.2虚存如何工作

第十三章介绍了MPU并演示了一个多任务嵌入式系统。该系统的每个任务被编译和运行在彼此不同的、固定的主存地址空间，（之前无保护操作系统是统一编译的，装载到一起，除了进程栈独立之外，剩下的都是放在一起了）

每个任务只能在同一个进程空间中运行，任何2个任务都不能在主存中有重叠地址。为了运行一个任务，一个保护区域被放置在固定地址的程序上，以允许任务访问由该区域定义的一段存储空间。保护区域的放置使得该任务得以运行，而其他任务空间被保护。

在MMU中，即使任务被编译、链接、运行在主存中有重叠地址的区域中，他们仍然可以运行。MMU中对虚存的支持可使构建后的嵌入式系统具有**多个虚拟存储器映射**和**单个物理存储器映射**。（这里指的是存储器映射寄存器么）

每个任务拥有自己的虚拟存储器映射（自己的进程地址空间）。以编译和连接组成此任务的代码和数据。内核层管理各个任务在物理存储器中的放置，使得他们在物理存储器中拥有彼此不同的地址，这个地址与其设计时的虚拟运行地址不同。

为了使任务有各自的虚拟存储器映射，MMU硬件采用地址重定位，也就是说在地址访问主存之前，转换由处理器核输出的存储器地址。可认为在介于内核和主存间的**MMU中有一个重定位寄存器**。

当处理器核产生一个虚拟地址时，MMU取出这个虚拟地址的高位，并用重定位寄存器内的值替换它，从而形成一个物理地址。（实际上是虚拟地址由段号+段基地址组成通过段号查找段表找到对应的页号，进而找到物理起始地址+段基地址=物理地址）

虚拟地址的低位部分是一个偏移量，它转换成物理存储器的一个特定地址。使用这种可以转换的地址范围由这个虚拟地址偏移量部分的最大值所决定。

一个被编译成以虚拟存储器的0x4000000为起始运行地址的任务，重定位寄存器将任务1的虚拟地址转换成以0x8000000开始的物理地址。

第二个同样被编译在这个虚拟地址运行的任务，可以被放置在任何其他以0x10000为倍数的地址的物理存储器上，只需要简单地改变以下重定位寄存器的值，就可以将它映射到0x4000000处。

**一个重定位寄存器只能转换一块存储空间**。这块存储空间的大小由虚拟地址的偏移量部分所占位数决定。（段号对应页号也就是决定具体是哪个页面，偏移量就是页面内偏移）这样的一块虚拟存储空间称为一页，而转换过程中所对应的那块物理存储空间称为一个页帧。

页、MMU、页帧之间的关系如下图所示。ARM MMU硬件有**多个重定位寄存器**来支持虚拟地址到物理地址的转换，MMU需要多个重定位寄存器来有效地支持虚存，因为系统必须将多个页转换成页帧。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686880992627.png" alt="1686880992627" style="zoom:25%;" />

ARM MMU中临时存放转换数据的一组重定位寄存器实际上是一个由64个重定位寄存器组成的全相联cache。这个cache被称为转换旁路缓冲器TLB。TLB缓存最近被访问的页的转换数据。（一下子清晰了，实际上TLB就是由一组重定位寄存器组成的从而实现转换数据的功能，全相联就是一个虚拟地址对应一个cache行，TLB在MMU内部）

除了使用重定位寄存器外，MMU还使用主存中的表来存放描述系统中用到的虚拟存储器映射的数据，这些转换数据的表称为页表。页表中的每个项代表了将虚拟存储器的一个页转换到物理存储器的一个页帧所需的所有信息。

页表中的每个页表项PTE(Page table entry)包含关于一个虚拟页的以下信息：

- 用于将虚拟页转换为物理页帧的物理基地址；
- 分配给该页的访问权限；
- 页的cache和写缓冲器配置；

**MPU的大部分区域配置数据都保存在页表项中**。也就是说访问权限、cache和写缓冲器的行为都以页大小为粒度进行控制。（页就是区域了，MPU只有8个区域，MMU直接以页作为区域）

这在存储器的使用上提供了更好的控制。MMU中的区域由软件通过将存储器中的虚拟页块进行分组来创建。

#### 14.2.1使用页定义区域

第十三章介绍了使用区域来组织和控制用于特殊功能（比如任务代码和数据，或存储器输入输出）的各块存储空间，在那里区域被看做是MPU体系结构的硬件组成部件。在MMU中，**区域被定义为一组页表的集合**，并作为虚存中的连续页完全由软件控制。

虚存中的一页在页表中有一个对应的项，因此虚存的一组连续的页映射到页表的一组连续的项。这样，区域可以被定义为一组连续的页表项的集合。区域的位置和大小可以保存在一个软件数据结构中（内核中的VMA结构体），而实际的转换数据和属性信息保存在页表中。（此时区域已经不同于MPU的区域了，现在是以页为粒度的区域，页是区域，连续的页组成一个相同属性的大区域）

下图的例子表示一个任务有3个区域：一个用于代码，一个用于数据，第三个用于支持任务堆栈。（这就是熟悉的C内存分布了）**虚存中的每个区域映射到物理存储器的不同块**（都对应到不同的芯片了）。图中，可执行代码放在Flash中，数据和堆栈放在RAM中。区域的这种使用方法是支持任务间共享代码的操作系统的典型用法。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1686883572461.png" alt="1686883572461" style="zoom:25%;" />

除了一级页表外，所有其他的页表都代表虚存的1MB空间。如果一个区域的大小大于1MB或者它跨过页表的1MB边界地址，（一级页表代表的是一组二级页表）

那么就必须用一组页表来描述这个区域。一个区域的页表总是来自L1页表的连续页表项，然而在物理存储器中的L2页表的位置是不需要是连续的。（虚拟地址连续，线性地址不需要连续，但是这是针对段页表的，而不是多级页表）14.4节将更全面地介绍页表层次。

#### 14.2.2多任务和MMU

页表可以驻留在存储器中，而不必映射到MMU硬件。构建一个多任务系统的一种方法是，创建几组独立的页表，每组页表对应一个任务的唯一虚存空间（这就是进程地址空间）。

为了激活某个任务，对应这个任务的那组页表和其虚存空间由MMU使用，而其他没有被激活的页表则代表睡眠的任务。这种方法使得所有的任务都驻留在物理存储器中。（这里的意思是所有的页表都驻留在物理存储器中，也不是，页表项在外存中也有）

通过在上下文切换时激活不同的页表，使得执行有重叠虚拟地址的多个任务成为可能。MMU可以**重定位一个任务的执行地址**（相同的虚拟地址对应着不同的物理地址，因为每次激活页表，重定位寄存器会改变）。而无需在物理存储器中移动这个任务。任务的物理存储空间只是简单地通过激活和不激活页表来映射到虚拟存储空间。下图为三个有各自页表集合的任务（有着各自的进程地址空间以及映射的页表）

下图还表现出活跃的页表和睡眠的页表，只有正在运行的任务才有活跃的页表集合。睡眠任务的页表驻留在特权物理存储空间中，不能被正在运行的任务所访问。（因为正在运行的任务通过虚拟地址转换成物理地址访问的，只要保证MMU中的TLB没有对应页表项，就可以保证无法访问到该物理地址）这样就完全保护睡眠任务不受活跃任务的影响，因为从虚拟存储器中不能映射到睡眠任务物理空间。（这种防止访问的方式是通过禁止虚实转换实现的，而不是MPU通过硬件设定的访问权限）

当页表被激活或不激活时，虚拟地址到物理地址的映射关系也随着改变。因此，每次激活页表后，访问虚存的一个地址可能突然转换成物理存储器的一个不同地址。（每个任务中相同虚拟地址对应的页表项中记录的物理地址不同）

之前提到，一些ARM处理器核有一个逻辑cache，用来缓存虚拟存储器中的数据。当刚刚提及的地址转换发生时，cache可能包含无效的、从旧的页表映射来的虚拟数据。（逻辑cache的数据是存储单元中的数据，但是地址是虚拟地址，可是当切换任务后，虚实映射关系改变，同样的虚拟地址找到的是不同的数据了）

为了保证存储器数据的一致性，cache可能须清除和清理。TLB可能也须清除，因为他也可能缓存了旧的转换数据。（TLB中是一组重定位寄存器，保存了一些页表项，这是上一个任务的页表项，需要清理）

虽然清除和清理cache以及TLB会使系统的执行速度有所降低，但是清除和清理cache中过时的数据和代码以及TLB中过时的转换物理地址，可避免系统因使用无效的数据而发生崩溃。

上下文切换时，并不需要在物理存储器中移动页表数据，而只须改变指向页表位置的指针。

任务间需要以下步骤：

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687051767477.png" alt="1687051767477" style="zoom:25%;" />

这里的页表包括TLB还是物理存储器中的。

1. 保存活跃任务的上下文，并将该任务置为睡眠态；
2. 清除cache，如果使用回写策略，清理D-cache让其回写到主存中；
3. 清除TLB，从而移除原任务的转换数据；
4. 配置MMU（修改TLB），以使用新的页表，把虚拟运行空间转换为被唤醒任务在物理存储器中的位置；
5. 恢复被唤醒任务的上下文；
6. 继续执行恢复的任务。

----

之前学内核的时候对进程创建过程中的页表、TLB、进程栈、进程地址空间这些东西很困惑，现在清楚了，各自在进程运行期间的存储位置以及作用

---

注意：为了缩短执行上下文切换所花费的时间，在ARM9系列中可以采用cache直写策略。清理数据cache需要对CP15的寄存器写几百次，而将数据cache配置为使用直写策略，就不需要在上下文切换时清理数据cache，从而获得更好的上下文切换性能。使用直写策略，将这些写操作分布在任务的整个操作过程中（每次修改cache跟着直接修改主存，而不是等到cache被置换的时候才修改）。虽然回写策略有较好的整体性能，但是使用直写策略，对小型嵌入式系统的代码编写更简单。

使用这种直写的简化是因为大部分系统使用Flash存储器作为非易失性存储介质，而在系统运行时将程序复制到RAM中。（这里使用地址总线直接通信，访问时间很短的）

如果系统含有文件系统并使用动态分页，那么应该采用cache回写策略，因为对文件系统存储介质的访问时间通常是访问RAM时间的几十倍到上千倍。（时间太长就不能采用直写了，之后再回写吧）

如果在性能分析后，发现采用直写策略的效率不高，那么采用cache回写策略，性能就能得到改善。如果使用磁盘驱动器或其他非常慢的2级存储器，采用回写策略。

上面的讨论，仅仅适用于使用逻辑cache的ARM核。如果使用物理cache，像ARM11系列，则当MMU改变虚存映射时，cache中的信息仍然有效。（毕竟是通过物理地址得到的数据，这是不会改变的）这样，就不需要在改变虚拟存储地址时执行cache清除清理操作。

#### 14.2.3虚存系统的存储器组织

典型的，页表存放在主存的一块空间中，虚拟地址到物理地址的映射是固定的。所谓固定的，是指通常操作中，页表中的数据是不会发生变化的（就是说映射关系、访问权限不会发生变化）。

下图中，存储器中的这块固定空间还包含操作系统内核以及其他一些进程。可以看到，包含TLB的MMU是在虚拟或物理存储空间之外操作的硬件，其功能是在2个存储空间之间转换地址。

这种固定映射的好处在上下文切换中可以看到。把系统软件放在一个固定的虚拟存储器位置（Linux中内核被放在最高地址的1GB处），这样就消除了一些存储器管理任务和流水线影响。(所有进程地址空间为4GB，最高处的1GB虚拟地址都对应同一个固定的物理地址)

当在2个应用程序任务间实现上下文切换时，处理器其实要发生多次上下文切换。它先从用户模式切换到内核模式任务，为了处理准备运行下一个应用程序任务时的上下文数据的移动（上下文包括：用户级上下文、内核级上下文、寄存器级上下文，这里需要切换到内核空间去保存该空间中的上下文）；然后它从内核模式任务切换到下一个上下文的新的用户模式任务。

通过在虚存的一块固定空间上共享系统软件，一个系统调用可以直接跳转到这块系统空间。（进程调用系统调用陷入内核，运行内核中对应的系统调用例程，这并不算进程切换，仍然属于用户进程的运行时间，可以理解为用户进程在内核态形式，虚拟运行时间依旧会增加）并且不需要担心将页表改为映射到内核进程中。（内核进程只有内核进程栈，没有属于自己的进程地址空间，他们其实就是一个个API）内核进程也需要虚实转换，但使用的是调用它的进程的页表。并且所有进程的内核空间虚拟地址映射的页表都相同。

跳转到一个固定的内核空间也避免了流水线结构中固有的问题。处理器核从原来的物理存储空间中预取了几条指令，此时指令还没有执行，则在新指令从新映射的存储空间中取出并填充流水线时，原来取出的指令会被执行。也就是说新旧指令同时在流水线中执行。此时执行原来的存储映射的流水线中的指令可能会破坏程序的正常执行。

这里建议在固定的地址空间中执行系统代码时激活新任务的页表。这种方法**保证了用户任务间的安全切换**。（我确实需要进程切换，切换必然需要激活新的页表，极大可能导致流水线中同时存在新旧指令，旧指令按照原来的映射关系执行，想要不出问题，只有保证旧指令执行的映射关系没有被修改，所以只能在内核空间中激活新任务的页表，因为所有任务在内核地址空间处的页表是固定相同的，此时内核执行的旧指令遵循的映射关系在新页表中一样，**这就是所有进程固定一块空间的原因**）

许多嵌入式系统不使用复杂的虚存，而只简单地创建一个固定的虚拟空间映射来合并所有的物理空间。这些系统通常收集分布在大的地址空间内的多快物理存储块，使其成为一个连续的虚拟存储块。通常他们在初始化过程中创建一个固定的映射，该映射在系统操作期间保持不变。

### 14.3ARM MMU的详情

ARM MMU执行以下一些功能：将虚拟地址转换成物理地址；控制存储访问权限；决定存储器中每一页的cache和写缓冲器的行为。**当禁用MMU时，所有的虚拟地址一一映射到与其相同的物理地址**。（就是说相当于没有虚拟地址了）如果MMU在转换一个地址时失败，就会产生一个中止异常。MMU只有在转换失败、权限错误和域错误（这个没提到过）时，才会中止。

MMU的主要软件配置和控制模块如下：

- 页表；
- TLB；
- 域和访问权限；
- cache和写缓冲器；
- CP15:c1控制寄存器；
- 快速上下文切换扩展。

### 14.4页表

ARM MMU硬件采用2级页表结构：一级页表L1和二级页表L2。

一级页表只有L1主页表。L1主页表包含2种类型的页表项：保存**指向二级页表起始地址指针**的页表项，以及保存**用于转换1MB页的页表项**。L1主页表也称为**段页表**。

---

之前分析多级页表的时候独独没有考虑过MMU的问题，页表本身就是由MMU使用的。也分析过段页表，这是intel发展出来的历史问题，想要兼容旧版本只能使用段页式内存管理，但是段的部分已经名存实亡了，所以学内核的时候只学到了页表。

---

L1主页表将4GB的地址空间划分为**多个1MB的段**，因此L1页表**包含4096个页表项**。L1主页表是一个混合表，可作为L2页表的页目录，也可作为用于转换1MB虚拟页的普通页表。

当L1页表作为页目录时，其页表项包含的是代表1MB虚拟空间的L2粗页表或L2细页表的指针；

当L1页表用于**转换1个MB的段**时，其页表项包含的是**物理存储器中1MB页帧的首地址**。（这里的段页式解释成了段式+多级页表，并不是段+页式）目录页表项和1MB的段页表项可以共存于L1主页表。

一个L2**粗页表有256个页表项**，**占用1KB的主存空间**，每个页表项将一个4KB的虚拟存储块转换成一个4KB的物理存储块。（页的大小是4KB，段的大小具有逻辑性，根据程序决定，这里是统一认为1MB，256*4KB=1MB）

粗页表支持4KB或64KB的页，页表项包含的是4KB或64KB的页帧的首地址。如果转换的是一个64KB的页，则对于每个64KB的页，同一个页表项必须在页表中重复16次。（实际上支持64KB的页意思就是将4KB的页表项重复16次，页粒度就是4KB）

一个L2**细页表有1024个页表项**，占用4KB的主存空间，每个页表项转换一个1KB的存储块。（1024*1KB=1MB）细页表支持1KB、4KB或64KB虚存页，每个页表项包含1KB，4KB或64KB物理页帧的首地址。如果转换的是4KB的页，则同一个页表项必须在页表中连续重复4次；如果转换的是64KB的页，则同一个页表项需要在页表中连续重复64次。(这里的页粒度就是1KB)

下表概括了ARM MMU中3种类型页表的特征。

| 名称          | 类型     | 页表占用的存储空间/KB  | 支持的页大小/KB | 页表项数目 |
| ------------- | -------- | ---------------------- | --------------- | ---------- |
| 主页表/段页表 | 一级(L1) | 16（含有4096个页表项） | 1024(1MB)       | 4096       |
| 细页表        | 二级(L2) | 4                      | 1,4或64         | 1024       |
| 粗页表        | 二级(L2) | 1                      | 4或64           | 256        |

#### 14.4.1一级页表项

一级页表支持4种类型的页表项：

- 1MB段转换项；（这是段式内存管理的目录项吗）
- 指向L2细页表的目录项；
- 指向L2粗页表的目录项；
- 产生中止异常的错误项。

系统通过页表项的最低2位[1:0]来确定页表项的类型。页表项的格式要求L2页表的地址必须与其页大小的倍数对齐。

一个段页表项指向一个1MB的存储段。页表项的**高12位代替虚地址的高12位**来产生物理地址。（采用段页式的虚拟地址中存放的是段号+页面号+页内地址，这里的段项后面没有二级页表，直接得到物理地址）**段页表项还包含域属性、cache属性、缓冲器属性和访问权限属性。**

粗页表项包含一个L2粗页表首地址的指针，同时还包含L1表项代表的1MB虚存段的域信息。粗页表必须与1KB的倍数地址对齐。（因为粗页表本身占用1KB内存）

细页表项包含一个L2细页表首地址的指针，同时还包含L1表项代表的1MB虚存段的域信息。细页表必须与4KB的倍数地址对齐。（因为L2细页表占用4KB内存，所以指向L2细页表的地址是4KB的倍数）

错误页表项产生一个存储页错误。错误条件会导致预取指中止或数据中止，这取决于具体的存储器访问类型。（指令区域还是数据区域）

L1主页表在存储器中的**位置通过写CP15:c2寄存器设置**。粗页表比细页表占用的空间小了4倍，所以基地址多两位。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687087458433.png" alt="1687087458433" style="zoom:25%;" />

#### 14.4.2L1转换表基地址

CP15:c2寄存器保存转换表基地址TTB也就是指向L1主页表在虚存中的位置。CP15:c2寄存器格式如下：

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687087569429.png" alt="1687087569429" style="zoom:25%;" />

例14.1一个称为ttbSet的例程。设置L1主页表的TTB。

ttbSet例程使用MCR指令来写CP15:c2:c0:0.例程的函数原型如下：

```c
void ttbSet(unsigned int ttb);
```

传递给函数的唯一参数是转换表的基地址。TTB地址必须与存储器的16KB边界对齐。

```c
void ttbSet(unsigned int ttb)
{
    ttb &= 0xffffc000;//因为需要是16KB的倍数，所以低14位为0
    __asm{MCR p15,0,ttb,c2,c0,0}
}
```

#### 14.4.3二级页表项

L2页表有4种可能的页表项：

- 定义64KB页帧属性的大页表项；
- 定义4KB页帧的小页表项；
- 定义1KB页帧的微页表项；
- 访问时产生页错误中止异常的错误页表项。

L2页表的页表项格式如下图。MMU通过页表项的最低2位来确定L2页表项的类型。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687089030711.png" alt="1687089030711" style="zoom:25%;" />

之前说是同一个页表项连续存放从而表示一个大页表。怎么现在变成了一个大页表来表示了。

大页表项包含一个64KB物理存储块的基地址，同时它还含有4组权限位域，以及页的cache和写缓冲器属性。**每一组访问权限位域代表虚存页的1/4**，这些页表项可以看成是16KB子页，以更好地控制64KB页的访问权限。

小页表项保存一个4KB物理存储块的基地址，同时它也含有4组权限位域，以及页的cache和写缓冲器属性。每一组权限位域代表虚存页的1/4，这些页表项可以看成是1KB的子页，以更好地控制4KB页的访问权限。

微页表项提供一个1KB物理存储块的基地址，同时它含有**一个访问权限位域**，以及页的cache和写缓冲器属性。ARMv6体系结构不包含微页，如果打算创建一个很容易移植到以后体系结构的系统，则建议在该系统中避免使用1KB微页。

错误页表项产生存储页访问错误。错误条件会导致预取指中止或数据中止，这取决于具体的存储器访问类型。

#### 14.4.4为嵌入式系统选择合适的页大小

下面是为系统设置页大小的一些技巧和建议：

- 页越小，给定物理存储块就有越多的页帧。
- 也越小，内部碎片就会越少。内部碎片是指一页中未使用的存储空间，比如一个大小为9Kb的任务可以放在3个4KB大小的页中，也可以放在一个64KB大小的页中。
- 页越大，系统就越有可能装入引用的代码和数据。
- 二级存储器的访问时间增加时，选择大的页会更有效。
- 随着页的增大，每个TLB条目代表存储器中越大的空间，从而系统可以缓存更多的转换数据，将一个任务的所有转换数据装入TLB的速度也会更高。
- 如果使用L2粗页表，则每个页表占用1KB的存储空间；每个L2细页表占用4KB的存储空间。每个L2页表转换1MB的地址空间。每个任务使用的最大页表存储空间为：（（任务大小/1MB）+1）*(L2页表大小)

### 14.5转换旁路缓冲器

转换旁路缓冲器TLB是一个存放最近使用的**页转换数据**的特殊cache。他将一个虚拟页映射到一个活跃页帧，并存储用于约束页的访问的控制数据。TLB是一个cache，因此有一个丢弃指针和一个TLB行替换策略。在ARM处理器核中，TLB采用循环算法发来选择替换的重定位寄存器。（之前的cache行替换策略我就没搞懂，整了一个计数器每次替换进来一个cache行就+1，复位值寄存器来设置复位）

ARM处理器核的TLB没有很多用来控制其操作的软件命令，TLB只支持两种类型的命令：清除和锁定TLB中的转换数据。（存放的就是页转换数据，不需要修改，也不会区分指令和数据的区别。所以不需要清理）

存储器访问时，MMU将虚拟地址的一部分（页号+页内地址）与TLB中的所有值进行比较，如果TLB中已有所要的转换数据即为一次TLB命中，则由TLB提供物理地址转换数据。

如果TLB中不存在有效的转换数据，即为一次TLB失效，则MMU会由硬件自动处理TLB失效，通过主存中的页表搜索有效的转换数据，并将其装入TLBD 64行中的一行。在页表中搜索有效的转换数据称为页表搜索。如果找到一个有效的页表项，则由硬件将该转换地址从页表项复制到TLB中，并产生访问主存的物理地址；如果最后搜索到页表的错误页表项，则MMU硬件产生中止异常。（就是缺页中断吧，当时纠结是硬中断还是软中断，现在来看其实属于异常处理，和硬中断无关，不会进入IRQ/FIQ模式，和软中断也无关不会进入SVC模式，而是进入到ABT模式）

当TLB失效时，在将数据装入TLB和产生所需的地址转换之前，MMU最多搜索2个页表。由于MMU转换表硬件搜索页表，一次失效的开销通常是1~2个主存访问周期，具体的周期数取决于是在哪个页表中找到转换数据的。如果在L1主页表中就找到，则为单步页表搜索；如果在L2页表中才找到，则为2步页表搜索。（L1中找到是指段项找到的）

如果MMU产生中止异常，则一次TLB失效可能会消耗更多的额外周期，因为当中止异常处理程序**映射在所请求的虚拟空间**时需要额外的周期。（听不懂这里说的）有些处理器核采用哈佛总线体系结构：一个TLB用于指令转换，一个TLB用于数据转换。

#### 14.5.1单步页表搜索

如果MMU搜索的是1MB大小的段页，则硬件能用单步搜索找到所要的页表项，因为1MB的页表项是存放在L1主页表里的。

对于1MB段页转换的L1页表搜索如下图。MMU使用虚地址的基地址部分（位[31:20]，操作系统中说虚拟地址是由段号+偏移地址组成的，这里是**转换表基地址**+偏移地址作为虚拟地址）来选择L1主页表中4096个页表项的一个。如果位[1:0]的值为二进制的10，则此页表项含有一个有效的1MB页可用。页表项中的值被复制到TLB中，把它与虚拟地址的偏移量部分合并组成物理地址。

如果最低2位为00，则发生错误；如果为01或11，则MMU执行2步页表搜索。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687093079909.png" alt="1687093079909" style="zoom:25%;" />

这个过程和操作系统讲的差不多，虚拟地址中的基地址实际上是转换表基地址。类似于段号了，通过检查页表项的最后2位查看下采用的什么内存分配方式。

#### 14.5.2 2步页表搜索

如果MMU搜索的是大小为1KB，4KB，16KB或64KB的页，则页表搜索须执行2步才能找到地址转换数据。下图说明了搜索保存在L2粗页表的转换数据的过程。这里虚拟地址分成3部分。

第一步，用L1偏移量部分索引L1主页表，找到虚拟地址的L1页表项。如果该页表项的最低2位是二进制的01，则表示该页表项包含的是一个粗页的L2页表基地址。

第二步，将L2偏移量部分合并到第一步找到的L2页表基地址，得到的地址用来选择包含所搜索页的转换数据的页表项。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687093636368.png" alt="1687093636368" style="zoom:25%;" />

和操作系统的流程一模一样，虚拟地址就是由段号+页号+页偏移值组成。

#### 14.5.3TLB操作

如果IT改变了页表中的数据，那么缓存在TLB中的转换数据可能就不再有效了。处理器核有一些CP15命令，用于清除TLB，从而作废TLB中的数据。以下是一些可用的命令：清除所有TLB数据，清除指令TLB，清除数据TLB，也可以一次只清除一行TLB数据。

| 命令              | MCR指令              | Rd的值               |
| ----------------- | -------------------- | -------------------- |
| 使所有TLB无效     | MCR p15,0,Rd,c8,c7,0 | 0                    |
| 按行使TLB无效     | MCR p15,0,Rd,c8,c7,1 | 要使之无效的虚拟地址 |
| 使指令TLB无效     | MCR p15,0,Rd,c8,c5,0 | 要使之无效的虚拟地址 |
| 按行使指令TLB无效 | MCR p15,0,Rd,c8,c5,1 | 要使之无效的虚拟地址 |
| 使数据TLB无效     | MCR p15,0,Rd,c8,c6,0 | 要使之无效的虚拟地址 |
| 按行使数据TLB无效 | MCR p15,0,Rd,c8,c6,1 | 要使之无效的虚拟地址 |

例14.2一个使TLB无效的C例程

```c
void flushTLB(void)
{
    unsigned int c8format = 0;
    __asm{MCR p15,0,c8format,c8,c7,0}//清除TLB
}
```

#### 14.5.4TLB锁定

有些ARM处理器核支持TLB转换数据的锁定。如果TLB中的某一行是锁定的，则当TLB清除命令发出时，他仍然保留在TLB中。各种ARM核的可用锁定命令如下表。用于TLB数据锁定的MCR指令使用的内核寄存器Rd格式。

| 命令          | MCR指令                | Rd的值  |
| ------------- | ---------------------- | ------- |
| 读数据TLB锁定 | MRC p15,0,Rd,c10,c0,0  | TLB锁定 |
| 写数据TLB锁定 | MCR p15,0,Rd,c10,c0,0  | TLB锁定 |
| 读指令TLB锁定 | MRC p15,0,Rd,c10,c0,1  | TLB锁定 |
| 写指令TLB锁定 | MCR p15,0,Rd,c10,c0,c1 | TLB锁定 |

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687137288651.png" alt="1687137288651" style="zoom:25%;" />

Rd格式是用来锁定TLB的，这里怎么还涉及到丢弃者的问题。

### 14.6域和存储器访问权限

有两种不同的控制用来管理一个任务的存储器访问权限（之前就好奇过域权限是啥）：域用于主控制(具有逻辑意义)；页表中的访问权限用于次控制（代表某个页的访问权限）。

在共享一个共用虚拟存储器映射时，域将一块存储空间与另一块存储空间隔离，以控制虚存的基本访问。有16种不同的域可以**分配给虚存的1MB段**，并通过设置L1主页表项中的域的有关位来分配给一个段。

当**一个域分配给了一个段**时，它必须遵守分配给这个域的访问权限。域的访问权限在CP15:c3寄存器中分配，它控制处理器核访问虚存段的能力。（就是MPU中的管理者和用户访问权限）

16个可用的域，每个域使用CP15:c3寄存器的2位来定义访问权限，域访问位取值以及对应的意义如表。

| 访问     | 位阈值 | 说明                                            |
| -------- | ------ | ----------------------------------------------- |
| 管理者   | 11     | 访问不受控制，不产生权限中止（预取指+数据中止） |
| 保留     | 10     | 不可预料                                        |
| 用户     | 01     | **访问受页表项中设置的权限值控制**              |
| 不可访问 | 00     | 产生域错误                                      |

这个域就是被写入到段项中[8:5]的域中，MPU的域访问分为四种，只读只写不可访问。和MMU不太一样。（MPU的访问权限是针对区域的，区域对标的是页，而这里是段访问权限）

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687139020344.png" alt="1687139020344" style="zoom:25%;" />

上图给出了CP15:c3:c0寄存器的格式，它保存域访问控制信息，在图中16个可用的域分别标以D0~D15。

即使不使用MMU提供的虚存功能，仍然可以把这些内核（Rd寄存器）用作简单的存储保护单元（MPU）：首先将虚拟存储空间直接映射到物理存储空间；然后为**每个任务分配一个不同的域**；最后使用这些域来保护睡眠任务（通过将他们的域访问设置成不可访问）。

###### 基于页表的访问权限

页表项中的AP位决定该页的访问权限，下表说明了MMU如何解释AP位域的2位值。（这回对标的就是MPU的区域访问权限了）

| 特权模式 | 用户模式 | AP位域 | 系统位 | ROM位 |
| -------- | -------- | ------ | ------ | ----- |
| 读/写    | 读写     | 11     | 忽略   | 忽略  |
| 读/写    | 只读     | 10     | 忽略   | 忽略  |
| 读/写    | 不可访问 | 01     | 忽略   | 忽略  |
| 不可访问 | 不可访问 | 00     | 0      | 0     |
| 只读     | 只读     | 00     | 0      | 1     |
| 只读     | 不可访问 | 00     | 1      | 0     |
| 不可预料 | 不可预料 | 00     | 1      | 1     |

除了页表项中的AP位外，在CP15:c1寄存器中还有2位起到全局修改存储器访问权限的作用：系统S位和ROM位。**这2位用来在不同模式加速系统中访问大的存储块**。

设置S位使得所有页具有不可访问权限，从而允许特权模式任务对页有读访问权限。因此通过改变CP15:c1中的一个位，所有标识为不可访问的空间一下子变为可用，而不需要改变每个页表项的AP位域，节省了开销。（这里的S位和ROM位，不属于某一页，而是整个存储空间属性）

改变R位使得所有页具有不可访问权限，因而特权模式任务和用户模式任务对页都有读访问权限。同样，这一位可以加速对大块存储块的访问（不需要对存储块中的每个页挨个修改），而不需要修改许多页表项的值。

### 14.7cache和写缓冲器

第12章介绍了cache和写缓冲器的基本操作，这里可以通过页表项中的2位来配置存储器中每一页的cache和写缓冲器。当配置的是指令页时，写缓冲器位被忽略，cache位决定cache的操作。设置该位，则该页使用cache；清除该位，则该页不使用cache。

当配置的是数据页时，写缓冲器位有2个用途：使能或禁用页的写缓冲器；设置页的cache写策略。页的cache位控制写缓冲器位的意义：当cache位为0时，如果写缓冲器位为1，则使能写缓冲器，如果写缓冲器位为0，则禁用写缓冲器；当cache位为1时，使能写缓冲器，cache的写策略由写缓冲器位的状态决定，如果写缓冲器位为0，则页采用直写策略，如果写缓冲器位为1，则页采用回写策略。（这部分和MPU是一样）

### 14.8协处理器CP15和MMU配置

这里再次用到例程changControl，用于使能MMU、cache和写缓冲器。

控制MMU操作的控制寄存器值见下表。有些ARM处理器内核在控制寄存器的相同位置分别有MMU使能位[0]和cache使能位[2]；有些ARM处理器有写缓冲器使能位[3]；有些处理器使用分离的指令cache和数据cache，因此需要另一个位来使能指令cache。**所有带MMU的处理器核都支持将向量表改变到以0xffff0000开始的高地址存储器**。

控制MMU操作的控制寄存器CP15:c1的位域描述。

| 位   | 字母指示 | 使能功能     | 控制                                    |
| ---- | -------- | ------------ | --------------------------------------- |
| 0    | M        | MMU          | 0禁用，1使能                            |
| 2    | C        | 数据cache    | 0禁用，1使能                            |
| 3    | W        | 写缓冲器     | 0禁用，1使能                            |
| 8    | S        | 系统         |                                         |
| 9    | R        | ROM          |                                         |
| 12   | I        | 指令cache    | 0禁用，1使能                            |
| 13   | V        | 高地址向量表 | 0向量表在0x00000000,1向量表在0xFFFF0000 |

上述3类内核使能一个已配置的MMU的方法十分类似。之前出现的S位和ROM位就是这里修改的。为了使能MMU、cache和写缓冲器，需要改变控制寄存器的位[12]、位[3]、位[2]和位[0]。

例程changeControl操作CP15:c1:c0:0，以改变控制寄存器c1的值。下例给出了一个设置控制寄存器位的简单C例程，可以使用下面的函数原型调用它：

```c
void controlSet(unsigned int value,unsigned int mask)
```

传递给例程的第一个参数是一个无符号的整形。第二个参数mask选择要改变的位，mask变量中为1的位将把CP15:c1:c0寄存器的相应位变为vlaue输入参数的相同位的值；0则保持控制寄存器的相应位不变，而不管value参数的位状态。

例14.3例程controlSet设置CP15:c1的控制位。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687143640780.png" alt="1687143640780" style="zoom:25%;" />

例程首先读取CP15:c1寄存器的值，将它放到变量clformat中；然后用输入的amsk值清除clformat中需要更新的位，通过将clformat和输入参数value作或操作完成更新；最后将更新后的clformat写回到CP15:c1寄存器，以使能MMU、cache和写缓冲器。

```c
void controlSet(unsigned int value,unsigned int mask)
{
    unsigned int clformat;
    __asm{MRC p15.0,clformat,c1,c0,0}/*读取控制寄存器*/
    clformat &= ~mask;
    clformat |= value;
    __asm{MCR p15,0,clformat,c1,c0,0}/*写控制寄存器*/
}
```

下面是调用controlSet例程使能ARM920T的指令cache、数据cache和MMU的代码序列：

```c
#define ENABLEMMU 0x00000001
#define ENABLEDCACHE 0x00000004
#define ENABLEICACHE 0x00001000
#define CHANGEMMU 0x00000001
#define CHANGEDCACHE 0x00000004
#define CHAnGEICACHE 0x00001000
unsigned int enable,change;
#if defined{__TARGET_CPU_ARM920T}
	enable = ENABLEMMU | ENABLEICACHE | ENABLEDCACHE;
	change = CHANGEMMU | CHANGEICACHE | CHANGEDCACHE;
#endif
controlSet(enable,change);
```

### 14.9快速上下文切换扩展

快速上下文切换扩展FCSE(Fast Context Switch Extension)是**MMU中的一个附加硬件**（可以看做是一种增强特征），用于提高ARM嵌入式系统的系统性能。FCSE**使得多个独立的任务可以运行在一个固定的重叠存储空间中**（这句话意思是多个独立的任务的虚实映射相同，所以不需要清除了），而在上下文切换时又不需要清理或清除cache，或清除TLB。**FCSE的主要特征是不需要清除cache和TLB**（之前因为切换任务会导致虚实映射出错，需要清除逻辑cache和TLB）

如果没有FCSE，则从一个任务切换到另一个任务需要改变虚拟存储映射。如果改变涉及2个有重叠地址（虚拟地址重叠了）的任务，则保存在cache和TLB中的信息将变为无效，这样系统就必须清除cache和TLB。清除这些模块的过程使任务切换增加了很多时间，因为内核不仅要清除cache和TLB中的无效数据，还要从主存中装载新的数据到cache和TLB。

使用FCSE，虚拟存储管理增加了一次地址转换。FCSE在虚拟地址到达cache和TLB之前，使用一个特殊的、包含进程ID值的重定位寄存器来修改虚拟地址。（也就是说不同的任务对应的重定位寄存器不同）把第一次转换之前的虚存地址称为虚地址VA，把第一次转换之后的地址称为修改后虚地址MVA，当使用FCSE时，所有的修改后虚地址都是活跃的（此时修改后虚地址才是与页表项对应的地址，之前的地址映射不到），**通过使用域访问方式阻止访问睡眠任务**（就是通过访问域访问权限寄存器实现的），以保护任务。

这样，任务间的切换就不用涉及到改变页表，只需简单地将新任务的进程ID写到位于CP15的FCSE进程ID寄存器。（也就是说，此时任务间的虚拟地址VA可能是相同的，而虚实映射的页表项是根据**MVA对应物理地址**，让VA根据各自的进程ID找到**对应的重定位寄存器**并修改成各自的MVA，即使使用**同一份页表**，同一个虚拟地址VA，最终也会找到不同的物理地址，所有进程共用一套虚实地址映射的页表，这和之前没啥区别）正是因为任务切换不需要改变页表，因而切换后cache和TLB中的值依然保持有效，不再需要清除。

当使用FCSE时，每个任务必须在0x0000000~0x1ffffff的固定虚存地址范围内执行，且必须位于修改后虚存的**不同的32MB空间**中。系统共享0x2000000上面的所有存储空间（这里的0x2000000不是起始地址，而是虚拟空间大小），使用域来实现任务间保护（段项的[8:5]域保护1MB）。正在运行的任务通过其当前进程ID进行识别。

为了利用FCSE，编译链接所有的任务，使他们都运行在虚存的第一个32MB块空间，为每个任务分配一个进程ID；然后使用下面的重定位公式，将每个任务放置在修改后虚存的不同32MB分区中。（进程地址空间可是4GB，这里只分配32MB够用吗，虚拟地址不仅仅是为了保护单元，还是为了体现出逻辑存储结构）

MVA = VA + (0x2000000 * 进程ID)

为了计算任务在修改后虚存的起始地址，将VA和任务的进程ID取0即可。

保存在CP15:c13:c0寄存器中的值包含当前的进程ID，寄存器中进程ID位域为7位宽度，因此可以有**128个进程ID**。寄存器的格式如下

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687157731210.png" alt="1687157731210" style="zoom:25%;" />

例14.4为一个简单的例程processIDSet，用来设置FCSE中的进程ID。使用下面的函数原型调用它：

```c
void processIDSet(unsigned value);
```

例14.4，以一个无符号整数作为输入，取出低7位乘以0x2000000，然后使用MCR指令将结果写入进程ID寄存器。

```c
void processIDSet(unsigned int value)
{
    unsigned int PID;
    PID = value << 25;
    __asm{MCR p15,0,PID,c13,c0,0}/*写进程ID寄存器*/
}
```

#### 14.9.1FCSE如何使用页表和域

为了地使用FCSE，系统使用页表来控制区域的配置和操作，使用域来隔离各个任务。（先得到MVA，一般ARM采用逻辑cache，此时直接找对应的cache行，找不到就去TLB中获得对应的物理地址，此时找到对应的段项，检查上面的域查看是否可访问，可访问再转换成物理地址）

下图中表示了从任务1切换到任务2之前和之后的存储器布局。该图显示了CP15:c3:c0的域访问寄存器值的改变情况（用于实现从任务1到任务2的切换）。任务间的切换需要更改进程ID，相应的，域访问寄存器也要被赋予新的内容。不明白为什么域访问寄存器包含16个域访问权限）。

下表表示域1分配给任务1，域2分配给任务2。当从任务1切换到任务2时，须改变域访问寄存器，以允许客户访问域2，而不允许访问域1，这样就能防止任务2访问任务1的存储空间。（域访问寄存器16个代表可以并发执行16个进程，当某一个进程执行时，可以修改其余15个进程的域访问权限，统一下这里的D0~D15**每个对应一个任务**，会将任务中的所有段设置访问权限）

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687160241470.png" alt="1687160241470" style="zoom:25%;" />

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687160519585.png" alt="1687160519585" style="zoom:25%;" />

可以看出，每个任务的VA都是0x0-0x2000000区域的，经过FCSE的特殊重定位寄存器根据进程ID去查找域访问控制寄存器中对应的访问权限域，如果可访问就获得MVA，根据MVA去查找逻辑cache和TLB，进而获得数据或者物理地址。切换到任务2可以看出VA还是0x0~0x2000000，同样查看域权限控制寄存器中对应的任务的域值，如果可以访问根据不同进程ID计算出不同的MVA去查表。

---

之前学MPU的时候硬件决定了8个区域，区域与任务一一相对，MMU的粒度变成页了，然后前面加了一个段项，但是这个段项只代表1MB，始终没有与任务一一对应的，现在来了，域访问控制寄存器中的16组区域具有逻辑意义了。

----

在任务间共享存储空间可以通过使用一个共享的域来完成，比如下图中的域15，任务可以共享一个域，这个域允许用户访问修改后的虚存中的一个分区。两个任务都可以看到这个共享的域，而访问它要通过对应存储空间的页表项来控制。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687161921293.png" alt="1687161921293" style="zoom:25%;" />

其实这个寄存器保存的16组域就是说当前进程下可以访问到哪些区域。

| 区域  | 域   | 特权AP | 用户AP   | 修改后虚存中分块的起始地址 | 进程ID                           |
| ----- | ---- | ------ | -------- | -------------------------- | -------------------------------- |
| 内核  | 0    | 读/写  | 不可访问 | 0xFE000000                 | 不分配（内核空间不属于任何进程） |
| 任务3 | 3    | 读/写  | 读/写    | 0x06000000                 | 0x03                             |
| 任务2 | 2    | 读/写  | 读/写    | 0x04000000                 | 0x02                             |
| 任务1 | 1    | 读/写  | 读/写    | 0x02000000                 | 0x01                             |
| 共享  | 15   | 读/写  | 读/写    | 0xF8000000                 | 不分配                           |

使用FCSE时执行一次上下文切换需要以下步骤：

1. 保存活跃任务的上下文，并将活跃任务置为睡眠态；
2. 将唤醒任务的进程ID写到CP15:c13:c0中；
3. 通过写CP15:c3:c0，将当前任务的域设置为不可访问，而唤醒任务的域设置为用户可访问；
4. 恢复唤醒任务的上下文；
5. 继续执行被恢复的任务。

#### 14.9.2使用FCSE的提示

- 任务在大小上有固定的最大32MB的限制。
- 存储器管理者必须使用有固定起始地址的固定32MB分区。
- 除非想为每个任务管理一个异常向量表，否则使用CP15寄存器1的V位将异常向量表放置在虚拟地址0xffff0000。因为每个任务的VA地址是0x0开始的。
- 必须定义和使用一个活跃的域控制系统。
- 如果执行发生在第一个32MB块中，则紧随着进程ID的改变，内核会从先前的进程空间中取2条指令。因此，从存储器中一个固定区域切换任务是明智的。
- 如果使用域来控制任务的访问，则正在运行的任务也作为一个别名出现在虚存的VA+(0x2000000 * 进程ID)地址。
- 如果使用域来保护各个任务，则除非修改一级页表中域的相应位，并在上下文切换时清除TLB，否则最多只能有16个并发任务。（之前就合计到了毕竟域访问权限寄存器只有16组权限）如果不使用FCSE，域寄存器用不上。（这里清除TLB导致虚实转换映射改变，此时特殊重定位寄存器是否存在无所谓）

### 14.10示例：一个简单的虚拟存储系统

下面是一个简单的实例，用于说明使用虚存的小型嵌入式系统的基本原理。它设计成运行在ARM720T核上。该示例提供一个静态的多任务系统，说明了运行3个并发任务所需的基础部分。它选用的开发工具是ARM ADS1.2。该示例的主要目的是，理解ARM MMU的底层硬件原理。该实例没有涉及分页和二级存储器交换。

该实例中**所有的用户任务使用相同的执行区域**，从而简化了这些任务的编译和链接工作。每个任务被编译成一个独立的程序，包含单个区域中的代码、数据和堆栈信息。

硬件需求是一块基于ARM的评估板，包含一个ARM720或ARM920T的处理器核。例子需要256KB的RAM，起始地址为0x00000000；还需要一种将代码和数据装载到存储器的方法；其外还要有若干存储器映射的外设，分布在0x10000000~0x20000000的256MB地址范围。

软件需求是一个操作系统的基础部分，比如在前面章节中介绍的SLOS，系统必须支持固定分区的多任务。

本例使用了1MB（段大小）和4KB的页（实际页帧大小），因为任务的大小限制在小于1MB，可放在单个L2页表中，因此只需通过改变主L1页表的单个L2页表项就能执行任务切换。（这句话讲透了，但是任务大小应该是4GB，怎么这里小于1MB了，还是说任务是线程并不是进程？）

与另一种方法--为每个任务创建和维护一个完整的页表集合（那一个任务大小就是4GB了），在切换时改变TTB地址相比，这种方法要简单的多。

通过改变TTB来实现任务存储器映射的改变，需要在**3个不同**的页表集合中创建一个主表和所有的L2系统表，这样就需要额外的存储器来保存这些增加的页表。

在**单个L2表交换**（只实现一个L1页表项的二级页表，同时只存在一个二级页表）的目的是，避免在多个页表组中复制系统信息，减少复制的页表数目，也就减少了运行系统所需的存储器。（意思是说只创建一个L2表）

该实例使用下列7个步骤来设置MMU：

1. 定义固定的系统软件区域，这个固定的空间如下表所示。
2. 为3个任务定义3个虚存映射，这些映射的总体布局如图。（就是建立三个页表，实际上就是一个L1主页表，3个L2页表项）
3. 将步骤1和步骤2列出的区域定位到物理存储器映射（找到对应的物理地址）
4. 定义并在页表区域中定位页表。（初始化页表）
5. 定义创建和管理区域与页表的数据结构，这些结构与实现有关，这里是特别为这个例子定义的。（指的是mm_struct进程地址空间以及VMA内存区域结构体）
6. 初始化MMU/cache和写缓冲器。（既然页表项的物理地址添加了，把剩下的域、cache、写缓冲器权限添加、配置、使能）
7. 建立上下文切换例程，以顺利地从一个任务转换到下一个任务。

下面各节将详细介绍这些步骤。

#### 14.10.1第1步：定义固定的系统软件区域

这个操作系统使用4个固定的系统软件区域：位于0x00000的专用32KB内核区域；位于0x80000的32KB共享存储区域；位于0x10000的专用32KB页表区域；位于0x10000000的256MB外设区域。在初始化过程中定义这些区域，以后不再改变其页表。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687173557373.png" alt="1687173557373" style="zoom:25%;" />

（页表区域不再内核区域中），特权内核区域保存系统软件，包含操作系统内核代码和数据。通过在这个区域使用**固定的地址**，可以避免改变系统模式时重映射的复杂性（这里说的是在内核中切换上下文时不会因为前后指令的地址的映射关系改变而错误）。该区域还包含**向量表**和处理FIQ/IRQ/SWI/NUD/ABT**异常的堆栈**。（这个之前就知道了）

共享存储区域在虚存的一个固定地址上，所有的任务使用这个区域来访问共享的系统资源。共享存储区域包含共享库，以及在上下文切换时从特权模式切换到用户模式所使用的转换例程。（就是软中断例程）

页表区域包含5个页表，虽然页表区域大小为32KB，但是系统只使用其中的20KB：16KB用于主表，4KB用于L2表（4个L2表每个使用1KB）。（这是一个L2细表，这里只实现了一个L2细表，L1主表中有4096个页表项，一个页表项32位，所以占用了16KB，而L2页表中有1024个页表项，细页表项因为是1KB粒度的所以为了体现4KB需要1024个页表项）。

外设区域控制系统设备I/O空间，这个区域的主要目的是，将该区域配置成无cache且无写缓冲的区域。这样，对输入、输出和控制寄存器来说，可以避免因为缓存操作而可能包含的陈旧数据；同时，也可以避免使用写缓冲器所引起的延时（写缓冲器对接cache是快速的，对接主存是慢速的）。（其实就是volatile关键字作用，但如何保证不从寄存器中读取数据）

这个区域也防止用户模式下访问外围设备，因此访问外设必须通过设备驱动程序完成。这个区域只允许特权访问，不允许用户访问。示例中只有单个外设区域，但是在一个较完整的系统中，可能需要定义更多的这种区域。

#### 14.10.2第二步：为每个任务定义虚存映射

三个用户任务分别在3个时间片内运行，每个任务的虚存映射都是一样的。（VA地址一样，MVA与物理地址映射相同）

每个任务在其存储器映射中可以看到两个区域：一个是位于0x400000的专用32KB任务区域；另一个是位于0x8000的32KB共享存储区域。（任务并不是固定区域）

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687175615034.png" alt="1687175615034" style="zoom:25%;" />

任务只能看到自身区域以及共享区域。

任务区域包含运行的用户任务的代码、数据和堆栈。（**代码、数据都在任务区域内，页表在内核空间中**）当调度器使控制权从一个任务切换到另一个任务时，它必须重新映射任务区域，这是通过改变L1页表项，使它指向即将运行任务的L2页表来完成的。（相同的VA转换成不同的MVA，因为只实现了一个L1页表项，现在需要修改L1页表项中的基地址，换成下一个任务的MVA的地址）此时虚实映射关系变成了任务2的物理地址。

共享区域是一个固定的系统软件区域。

#### 14.10.3第三步：在物理存储器中定位区域

实例中定义的区域必须定位在物理存储器的互不重叠或冲突的地址上。所有区域在物理存储器上的定位及其虚地址和大小如下表表中也列出了为每个区域所选择的页大小和每个区域所需要的页的数目。使用FCSE之后，固定区域的物理内存就是虚拟地址+0x8000000 * 0=物理地址，因为不是进程，没有进程ID

| 区域  | 地址 | 区域大小                          | 虚存基地址  | 页的大小 | 页的数目 | 物理基地址 |
| ----- | ---- | --------------------------------- | ----------- | -------- | -------- | ---------- |
| 内核  | 固定 | 64KB（段项并不是固定不变是1MB的） | 0x0000 0000 | 4KB      | 16       | 0x00000000 |
| 共享  | 固定 | 32KB                              | 0x00010000  | 4KB      | 8        | 0x00010000 |
| 页表  | 固定 | 32KB                              | 0x00018000  | 4KB      | 8        | 0x00018000 |
| 外设  | 固定 | 256MB                             | 0x10000000  | 1MB      | 256      | 0x10000000 |
| 任务1 | 动态 | 32KB                              | 0x00400000  | 4KB      | 8        | 0x00020000 |
| 任务2 | 动态 | 32KB                              | 0x00400000  | 4KB      | 8        | 0x00028000 |
| 任务3 | 动态 | 32KB                              | 0x00400000  | 4KB      | 8        | 0x00030000 |

三个任务的虚拟地址相同，可以看出来页表是很灵活的，可以段项+细页表+粗页表并存。

上表列出了4个在系统操作过程中使用固定页表的区域：内核、共享存储器、页表和外设区域。（存放页表也是需要存储空间的，也涉及到虚实转换，那页表中是否还包含了页表的虚实转换呢）

任务区域在系统操作过程中动态改变其页表，针对正在运行的不同任务，他将同一个VA转换成不同的物理地址。

下图显示了各个区域在虚存和物理存储器中的放置情况。内核、共享和页表区域直接映射到物理存储器的连续页帧块，在这个空间的上面，是分配给3个用户任务的页帧。物理存储器中的任务是32KB的固定分区，也是连续的页帧。存储器映射的外围IO设备稀疏分布在物理存储器的256MB空间内。（不知道页表是如何分配的，16KB的主页表没问题，4KBL2页表项是分布在多个L1页表项中，还是完整的实现了一个L2页表）

#### 14.10.4第4步：定义和定位页表

系统中专门用一个区域来预先保存页表，下一步就是将区域内的实际页表定位到物理存储器中。下图详细表示了页表区域映射到物理存储器的哪个位置。他是页表的放大（之前合计过，看来页表中是包含页表区域的L2页表项的），将存储器展开来描述L1主页表和4个L2页表之间的关系。图中还描述了转换数据（就是页表项）如何保存在页表中的。

一个L1主页表定位L2页表，并转换外设区域的1MB段。（外设是段项，没有二级页表）。系统L2页表包含3个系统区域（内核区域、共享存储区域和页表区域）的转换地址数据。有3个任务L2页表，用来映射。

从图中可以看出来，固定分区的虚拟地址和物理地址相同，只有任务区域映射到不同地址。并且系统区域中的页表区域就是装载主页表+二级页表的区域。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687225007384.png" alt="1687225007384" style="zoom:25%;" />

可以看出，外设区域是没有二级页表的就是段项。并且中间没使用的空间都是错误项，也就是最后两位设置为错误。访问就会导致数据中止异常。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687225089560.png" alt="1687225089560" style="zoom:25%;" />

任务区域是L1页表项，拥有二级页表。

<img src="C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687225414007.png" alt="1687225414007" style="zoom:25%;" />

系统区域也拥有二级页表，里面包括了内核、共享、页表区域，可以看到页表中包含页表区域，但是共享区域是用户也能访问的区域为什么要放到内核空间中呢。此时存储器管理还是存在问题。

5个页表中只有3个在运行时是同时有效的：L1主页表、L2系统页表和3个L2任务页表中的一个。(依旧看不懂4KB的二级页表是怎么分配的)

调度器通过上下文切换重新映射任务区域，控制哪个任务是活跃的，哪些任务是睡眠的。特别要指出的是，位于0x18010的L1主页表项在上下文切换时是要改变的，（每个任务的VA是相同的，进程ID不同，那么MVA不同，根据MVA找到L1主页表项，所以需要改变），使它指向下一个活跃任务的L2页表的基地址。

#### 14.10.5第5步：定义页表和区域数据结构

例子中定义了2个数据结构，用来配置和控制系统。这两个数据结构描绘了用来定义和初始化页表以及区域的实际代码。这里定义2个数据类型：Pagetable类型包含页表数据；Region类型定义和控制系统的每个区域。

Pagetable结构的类型定义以及结构成员的描述如下：

```c
typedef struct {
    unsigned int vAddress;//表示由段项或L2页表控制的虚存1MB段的起始地址。
    unsigned int ptAddress;//页表在虚存中的地址。
    unsigned int masterPtAddress;//父亲L1主页表的地址，如果页表为L1页表，则该值与ptAddress的值相同。
    unsigned int type;//页表类型，可以是COARSE/FINE/MASTER粗细主
    unsigned int dom;//用来设置分配给L1页表项的1MB的域。这里是由域访问权限寄存器中的16组权限分配给段的域。
}Pagetable;//这个结构体描述页表信息。可以L1主页表，也可以是L2页表
```

这里使用Pagetable类型来定义系统中使用的5个页表。这些Pagetable结构一起组成一块页表数据，用来**管理、填充、定位、识别**所有活跃和非活跃页表并为其设置域。在实例的其他部分，称这个Pagetable块为页表控制块PTCB。

前面章节中描述的5个Pagetable及其初始值如下：

```c
#define FAULT 0
#define COARSE 1
#define MASTER 2
#define FINE 3
/*创建并初始化页表*/
/*VADDRESS,PTADDRESS,MasterPTADDRESS,PTTYPE,DOM*/
Pagetable masterPT = {0x00000000,0x18000,0x18000,MASTER,3};//第一个是该整体存储空间在虚存中的地址，第二个是L1主页表在虚存的起始地址，第三个L1主页表的地址，和第二个相同，主页表类型，11访问权限
Pagetable systemPT = {0x00000000,0x1c000,0x18000,COARSE,3};//这是系统段的页表，首先是系统段在虚存中的起始地址，保存系统段映射关系的L2页表的起始地址，L2页表的父页表L1的起始地址，粗页表类型，11
Pagetable task1PT = {0x00400000,0x1c000,0x18000,COARSE,3};//任务段在虚存中的起始地址，任务1的L2页表起始地址，L1主页表起始地址，粗页表类型
Pagetable task2PT = {0x00400000,0x1c800,0x18000,COARSE,3};
Pagetable task3PT = {0x00400000,0x1cc00,0x18000,COARSE,3};
```

上面这个是针对页表的结构体，并不是针对内存段的，对应不到VMA

Region结构的类型定义，以及结构成员的描述如下：

```c
typedef struct{
    unsigned int vAddress;//区域在虚存中的起始地址，和页表结构体第一个一样
    unsigned int pageSize;//虚存页的大小，4KB还是1KB
    unsigned int numPages;//区域中页的数目。
    unsigned int AP;//区域的访问权限，这里的访问权限是页表项的权限，MPU中区域的访问权限，读写、只读、不可访问
    unsigned int CB;//区域的cache和写缓冲器属性。
    unsigned int pAddress;//区域在物理存储器中的起始地址。
    Pagetable *PT;//区域所对应的页表结构体的指针。
}Region;
```

区域结构体中存放L2页表项的访问权限，页表结构体存放L1段项的访问权限，后者是VA地址计算MVA前访问域访问权限寄存器得到对应区域的权限。**决定访问是否受页表项访问权限的限制**。

所有的Region数据结构一起组成第二个数据块，用来定义系统中使用的区域的**大小、位置、访问权限、cache和写缓冲器操作以及页表位置**。称这个Region块为区域控制块RCB。（所谓的区域控制块实际上就是页表项控制块）

共有7个Region结构，用来定义四个系统软件和3个任务。（页表结构体只关注页表，区域控制块关心区域）下面是RCB的4个系统软件和3个任务Region的初始值：

```c
#define NANA 0x00;//管理者和用户均不可访问
#define RWNA 0x01;
#define RWRO 0x02
#define RWRW 0x03
/*配置cache和写缓冲器*/
#define cb 0x0
#define cB 0x1
#define WT 0x2
#define WB 0x3
/*区域表*/
/*VADDRESS,PAGESIZE,NUMPAGES,AP,CB,PADDRESS,&PT*/
Region kernelRegion = {0x00000000,4,16,RWNA,WT,0x00000000,&systemPT};//页面4KB，区域拥有的页面数量16，区域的物理起始地址，页表指针
Region sharedRegion = {0x00010000,4,8,RWRW,WT,0x00010000,&systemPT};
Region pageTableRegion = {0x00018000,4,8,RWNA,WT,0x00018000,&systemPT};
Region peripheralRegion = {0x10000000,1024,256,RWNA,cb,0x100000000,&masterPT};//可以看出来这就是在主页表上
/*任务区域*/
Region t1Region = {0x00400000,4,8,RWRW,WT,0x00020000,&task1PT};
Region t2Region = {0x00400000,4,8,RWRW,WT,0x00028000,&task2PT};
Region t3Region = {0x00400000,4,8,RWRW,WT,0x00030000,&task3PT};
```

#### 14.10.6第6步：初始化MMU、Cache和写缓冲器

在激活MMU、cache和写缓冲器之前，必须对他们进行初始化。（和之前的区别在于，带MMU的体系结构是固定分区、定位物理地址、创建页表、创建页表和区域数据结构）PTCB和RCB保存有这3个部件的配置信息（先创建的数据结构，然后再初始化页表）。初始化MMU需要以下5个步骤：

1. 初始化主存中的页表，将他们都填充成FAULT项；
2. 使用将区域映射到物理存储器的转换数据填充页表；
3. 激活页表；（所谓的激活就是说将该任务的页表写入cache和TLB，不过使用FCSE之后所有任务的虚实地址映射关系相同）
4. 分配域的访问权限；
5. 使能存储管理单元和cache硬件。

前4个步骤配置系统，最后一个步骤使能系统。下面的章节将提供在初始化过程中完成这5个步骤的例程，例程的函数和例子号下图列出。

#### 14.10.6.1初始化主存中的页表

初始化MMU的第一步是，**将页表设置到一个已知的状态**。最简单的方法是使用FAULT页表项填充这些页表，这样就确保除了PTCB中定义的那些转换数据外，没有其他有效的转换数据存在。将所有活跃页表的所有页表项设置成FAULT，这样，如果某个页表项没有使用PTCB中的数据填充，那么对它访问将产生过一个中止异常。

例14.5例程mmuInitPT初始化页表，通过接受分配给页表的存储空间，将它设置成FAULT值。他的函数原型如下：

```c
void mmuInitPT(Pagetable * pt);
//例程接受一个指向PTCB中Pagetable的指针作为参数。
int mmuInitPT(Pagetable *pt)
{
    int index;
    unsigned int PTE,*PTEptr;//指向页表中的页表项
    PTEptr = (unsigned int *)pt->ptAddress;//指向主页表基地址
    PTR = FAULT;//这里的FAULT就是页表项的默认值32位的
    switch(pt->type)
    {
        case COARSE:{index = 256/32;break;}//粗页表中含有256个页表项，这里的32是每次初始化的页表项个数，需要执行256/32个循环
        case MASTER:{index = 4096/32;break;}//主页表中含有4096个页表项
        default:
            {
                printf("mmuInitPT:UNKNOWN pagetable type\n");
                return -1;
            }
    }
    __asm
    {
        mov r0,PTE
        mov r1,PTE
        mov r2,PTE
        mov r3,PTE
    }
    for(;index != 0;index--)
    {
        __asm
        {
            STMIA PTEptr!,{r0-r3};//每次将四个寄存器赋值给4个页表项，因为页表项也是32位的
            STMIA PTEptr!,{r0-r3}
            STMIA PTEptr!,{r0-r3}
            STMIA PTEptr!,{r0-r3}
            STMIA PTEptr!,{r0-r3}
            STMIA PTEptr!,{r0-r3}
            STMIA PTEptr!,{r0-r3}
            STMIA PTEptr!,{r0-r3}
        }
    }
    return 0;
}
```

mmuInitPT从页表基地址PTEptr开始，使用FAULT项填充页表。页表大小通过读取pt->type中定义的Pagetable的类型确定。页表类型可以是有4096个项的L1主页表，有256个项的L2粗页表，或是有1024个项的L2细页表。

例程通过使用循环，每次写一小块存储器来填充页表。页表的项数除以每次循环写的项数就是块的数目，保存到index变量中。switch语句判断Pagetable类型，然后天赚到一个设置页表的index变量值的case。执行填充页表的循环以后，程序结束了。__asm关键字用于调用内嵌的inline汇编语句，这样可以通过使用STMIA多寄存器装载指令缩短循环的执行时间。

#### 14.10.6.2用转换数据填充页表

初始化MMU的第二步是将保存在**RCB中的数据转化成页表项**，（区域控制块转换成页表项？之前利用页表控制块中的数据来定位到各个页表，初始化页表项是依靠FAULT，现在修改成我们自己的数据，数据来源于区域控制块）然后将其复制到页表中。这里提供多个例程来将RCB中的数据转换成页表中的项。最上层的例程mmuMapRegion判断页表的类型，然后调用3个例程中的一个来构造页表项：mmuMapSectionTableRegion,mmuMapCoarseTableRegion或mmuMapFineTableRegion。

为使以后代码的移植更容易，建议不要使用微页和mmuMapFineTableRegion例程，不常用。

下面是四个例程的描述：

四个例程都有一个参数，指向包含生成页表项所需的配置数据的Region结构指针。

例14.6是最上层的例程，判断页表类型。

```c
int mmuMapRegion(Region * region)
{
    switch(region->PT->type)
    {
        case SECTION:/*L1页表段项*/
            {
                mmuMapSectionTableRegion(region);
                break;
            }
        case COARSE:
            {
                mmuMapCoarseTableRegion(region);
                break;
            }
        default:
            {
                printf("mmuMapRegion:UNKNOWN pagetable type\n");
                return -1;
            }
    }
    return 0;
}
```

Region中有一个指向Pagetable的指针，区域的转换数据保存在这里，例程判断页表类型region->PT->type，然后调用一个例程，以给定页表类型的格式将Region映射到页表中。

对于段、粗、细三种页表分别有单独的例程。

例14.7第一个例程，把区域数据转化成页表项。

```c
void mmuMapSectionTableRegion(Region * region)
{
    int i;
    unsigned int *PTEptr,PTE;//页表项指针，以及内容
    PTEptr = (unsigned int *)region->PT->ptAddress;//主页表起始地址
    PTRptr += region->vAddress >> 20;//区域的第一个页表项地址，这里是区域起始虚拟地址的高12位（这里作为L1主页表项的偏移值，0~4095） +主页表起始地址。
    PTRptr += region->numPages - 1;//因为页表项号就是偏移量，用12位表示，那么numPages-1+PTEptr将是该区域的最后一个页表项
    PTE = region->pAddress & 0xfff00000;//取物理地址的高12位作为内容的高12位
    PTR |= (region->AP & 0x3) << 10;//获取该段项的访问权限存入段项中
    PTE |= region->PT->dom << 5;//设置段的域
    PTE |= (region->CB & 0x3) << 2;//设置cache和写缓冲器属性
    PTE |= 0x12;//设置类型是段项
    //此时第一个段项设置完成
    for(i = region->numPages - 1;i >= 0;i--)//填充区域的页表项
    {
        *PTEptr-- = PTE + (i << 20);//从该区域的最后一个页表项循环到该区域的第一个页表项。
    }
}
```

---

虚拟地址的高12位是段号，换句话说是该段项距离主页表的偏移量，而物理地址的高12位是段项内部的高12位。因为段项没有二级页表

段项：[31:20]物理地址的高12位。[11:10]段项的访问权限AP。[8:5]段项的域访问权限dom。[3:2]cache和写缓冲器、写策略。[1:0]页面类型

---

在mmuMapSectionTableRegion例程的开始，线设置局部指针变量PTEptr，使它指向L1主页表的基地址。然后例程使用区域的虚拟起始地址来创建一个页表的索引，区域的页表项从索引处开始。这个索引值加到PTEptr变量中，这时变量PTEptr就指向页表中区域项的起始位置。下一个程序行计算区域的大小，然后将这个值加到PTEptr中。这时PTEptr指向区域的最后一个页表项。PTEptr变量被设置为区域的结束为止，因此在填充页表的循环中可以使用向下递减计数器。

接下来，例程使用Region结构中的值构造一个段页表项，这个项保存在局部变量PTE中。一系列OR语句设置这个PTE，包括其实物理地址、访问权限、域以及cache和写缓冲器属性。

例14.82个例程：mmuMapCoarseTableRegion和mmuMapFineTableRegion，非常相似，使得例程的文字描述也几乎相同。

```c
int mmuMapCoarseTableRegion(Region * region)
{
    int i,j;
    unsigned int * PTEptr,PTE;
    unsigned int *tempAP = region->AP & 0x3;
    PTEptr = (unsigned int *)region->PT->ptAddress;//L2页表起始地址
    switch(region->pageSize)//判断页面大小，如果是LARGEPAGE就是64KB，那么实际上的页表项是numPages * 16个，将相同的4KB的页表项连续放置实现的。
    {
        case LARGEPAGE:
            {
             PTEptr += (region->vAddress & 0x000ff000) >> 12;//L1页表项的高8位被用作L2页表项的偏移值，同时这个值是虚拟地址的[19:12]，此时L2页表起始地址+L2页表偏移量=L2页表项的地址
                PTEptr += (region->numPages * 16) - 1;//如果是small页，不需要乘16，得到区域最后一个页表项
                PTE = region->pAddress & 0xffff0000;//设置页表项的[31:16]基物理地址。
                PTE |= tempAP << 10;
                PTE |= tempAP << 8;
                PTE |= tempAP << 6;
                PTE |= tempAP << 4;//设置四组AP，每16KB位一组
                PTE |= (region->CB & 0x3) << 2;//设置cache和写缓冲器属性
                PTE |= 0x1;//设置为大页表
                for(i = region->numPages-1;i>=0;i--)//填充区域页表项
                {
                    for(j=15;j>=0;j--)//因为是大页表，将16个页表合并了，所以还需要进行16次循环
                        *PTEptr-- = PTE + (i << 16);
                }
                break;
            }   
    }
}//有个问题，这里并没有对那一个L1页表项进行初始化。
```

例14.9使用区域转换信息填充细页表。就是上面的翻版，没必要看了

#### 14.10.6.3激活页表

之前合计了下，我以为激活页表是使能页表项中的使能位，后来想起了这是对CP15的寄存器的操作用来使能mmu/cache/写缓冲器，激活页表就是把该任务的页表送入TLB和cache。说白了就是选择该任务的虚实映射关系，后来使用FCSE，将虚拟地址分成了VA和MVA，导致MVA和物理地址的映射关系全相等。此时就不需要切换TLB了，又该怎么激活页表呢。但是考虑到节约存储空间，并不会让所有的任务对应的L2页表都存在，每次只会存在一个。

初始化MMU的第三步是，为了执行位于特定区域的代码，激活所需的页表。

例14.10例程mmuAttachPT或者激活一个L1主页表（通过将其地址放到CP15:c2:c0寄存器的TTB中）；或者激活一个L2页表（通过将其基地址放到L1主页表项中）。他的函数原型如下：

```c
int mmuAttachPT(Pagetable * pt);
```

例程只接受一个参数，指向待激活Pagetable的指针，并增加新的从虚存到物理存储器的转换数据。

```c
int mmuAttachPT(Pagetable *pt)
{
    unsigned int * ttb,PTE,offset;//定义ttb、PTE内容
    ttb = (unsigned int *)pt->masterPtAddress;//从PT中读主页表起始地址
    offset = (pt->vAddress) >> 20;//将1MB段的虚拟地址保留高12位，这是段号或者说是偏移地址
    switch(pt->type)//判断当前页表类型，主页表还是粗、细页表
    {
        case MASTER:
            {
                __asm{MCR p15,0,ttb,c2,c0,0};//设置主页表起始地址
                break;
            }
        case COARSE:
            {
                PTE = (pt->ptAddress & 0xfffffc00);//粗页表自身的地址取高22位赋值给粗页表项，没毛病。
                PTE |= pt->dom << 5;//将域放到[8:5]
                PTE |= 0x11;
                ttb[offset] = PTE;//页表本身是由数组维护的，这里没问题，对粗页表中特定的粗页表项进行初始化。这里是初始化L1主页表项，并不负责创建L2页表项。
                break;
            }
    }
    return 0;
}
```

该例程做的第一件事是，准备2个变量：L1主页表的基地址ttb和L1页表偏移量offset。变量offset由页表的虚地址产生。例程读取区域的虚地址，虚地址的高12位就是主页表中的偏移量。将这个偏移量加到L1主页表的基地址，产生一个指针，指向L1主页表中代表1MB段的**转换数据**的地址。

例程用Pagetable类型的pt->type变量来跳转到相关页表的case。三个可能的case将在下面描述。

- MASTER处理L1主页表。例程使用汇编语言的MCR指令来设置CP15:c2:c0寄存器，处理这个特殊的页表。
- COARSE把一个粗页表加入L1主页表中。这个case读取保存在Pageteble结构中的L2页表地址，组合结构的dom成员和粗页表类型，构造PTE。然后将PTE写入L1页表。

上面给出了初始化MMU时判断、装载和激活页表的例程。下面将设置域访问年权限并使能MMU。

---

- 将所有页表项设置为FAULT是初始化页表。
- 初始化L1的每个段项以及L2中的页表项是填充页表。
- L1主页表地址（选择L1页表）以及L1主页表项（选择L2页表）是激活页表

#### 14.10.6.4分配域访问权限和使能MMU

初始化MMU的第四步是配置系统的域访问权限。示例中不使用FCSE，也不需要快速显现和隐藏大块的存储器，因此不需要使用CP15:c1:c0寄存器中的S和R访问控制位。这意味着页表中定义的访问权限对保护系统来说已经足够，并且应该使用域。

然而硬件需要所有活跃的存储空间有域的分配，并且赋予域访问权限。最简单的域配置是将所有的区域放在同一个域里，把域的访问权限设置为**客户访问允许**。在域的这种配置下，只有**页表中允许访问的项才是系统活跃项**。（这句话印证了我的想法，dom只是第二层而已，只要设置为用户访问就形同虚设）

示例中，所有的区域都分配在域3，并分配客户访问允许权限。其他的域不使用，并通过L1主页表的未使用页表项中的错误项，将不使用的域屏蔽掉。域在L1主页表中分配，域访问权限在CP15:c3:c0寄存器中定义。

例14.11domainAccessSet例程设置域访问控制寄存器中16个域的访问权限。他的函数原型如下：

```c
void domainAccessSet(unsigned int value,unsigned int mask);
```

传递给例程的第一个参数是无符号整数，包含设置16个域的域访问权限的位域。第二个参数决定需要改变哪些域的访问权限。例程首先读CP15:c3寄存器，将其值保存到c3format变量中；然后使用输入的mask值清除c3format中需要更新的位，这是通过把变量c3format和输入的value值做OR运算来完成的；最后将更新后的c3format值回写到CP15:c3寄存器，完成设置域访问权限。

```c
void domainAccessSet(unsigned int value,unsigned int mask)
{
    unsigned int c3format;
    __asm{MRC p15,0,c3format,c3,c0,0}//读域寄存器
    c3format &= ~mask;//清除要改变的位
    c3format |= value;//设置要改变的位
    __asm{MCR p15,0,c3format,c3,c0,0}//写域寄存器
}
```

使能MMU是初始化MMU过程的第5步，也是最后一步。例程controlSet使能MMU。建议在一个固定的地址空间中调用controlSet例程。

#### 14.10.6.5完成初始化MMU

例程mmuInit调用前面章节中描述的例程，初始化示例的MMU。读这段代码时，可以先复习之前的控制块。

例程的C函数原型如下：

```c
void mmuInit(void)
```

例14.12调用前面描述的初始化MMu的5个步骤。5个步骤在例子代码中以注释的形式标出。

在例程mmuInit的开始，先初始化页表，并将区域映射到特权的系统区域。第一步是调用mmuInitPT例程，初始化固定的系统空间。这些调用使用FAULT值填充L1主页表和L2页表。

```c
void mmuInit()
{
    unsigned int enable,change;
    //第一步，初始化系统固定的页表
    mmuInitPT(&masterPT);
    mmuInitPT(&systemPT);
    mmuInitPT(&task3PT);
    mmuInitPT(&task2PT);
    mmuInitPT(&task1PT);
    //第二步，使用转换和属性数据填充页表
    mmuMapRegion(&kernelRegion);
    mmuMapRegion(&sharedRegion);
    mmuMapRegion(&pageTableRegion);
    mmuMapRegion(&peripheralRegion);
    mmuMapRegion(&t3Region);
    mmuMapRegion(&t2Region);
    mmuMapRegion(&t1Region);
    
    //第三步，激活页表
    mmuAttachPT(&masterPT);//设置主页表地址
    mmuAttachPT(&systemPT);//将L2系统页表项装载到L1主页表中
    mmuAttachPT(&task1PT);//将L2任务1PTE装载到L1PT
    //第四步，设置域访问
    domainAccessSet(DOM3CLT,CHANGEALLDOM);//设置域访问
    //第五步，使能MMU、caches和写缓冲器
    enable = ENABLEMMU | ENABLECACHE | ENABLEWB;
    change = CHANGEMMU | CHANGEcACHE | CHANGEWB;
    controlSet(enable,change);//使能cache和MMU
}
```

![1687316731146](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687316731146.png)

![1687316744989](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687316744989.png)

![1687316843119](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687316843119.png)

上面的话配合上面的代码一切都很清晰了。

#### 14.10.7第七步：建立上下文切换程序

示例系统的上下文切换相对来说比较简单，主要有以下六个步骤：

- 保存活跃任务的上下文，并将活跃任务置为睡眠态；
- 清除cache，如果使用回写策略，则还要清理数据cache；
- 清除TLB，以删除退出任务的转换数据；
- 配置MMU，**以使用新的页表**，把同样的虚存执行空间转换到唤醒任务在物理存储器中的位置；
- 恢复唤醒任务的上下文；
- 开始执行恢复的任务。

![1687317305941](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1687317305941.png)

### 14.11MMUSLOS示例

MMU示例代码中的许多概念和例子被包含到一个实用的控制系统中，该系统被称为mmuSLOS。他是第11章的SLOS控制系统的扩展。

mpuSLOS是SLOS带存储保护单元的扩展，已经在第13章中介绍过了。这里使用mpuSLOS作为mmuSLOS的基本源代码。与mpuSLOS相比，mmuSLOS主要有以下3个变化。

- mmu页表是在mmuSLOS的初始化阶段建立的。
- 应用程序任务被构建成在地址0x400000处执行，但是他们被装载在不同的物理地址上。每个应用程序任务从它的执行地址开始，在一个虚存中执行。栈顶被定位在执行地址的32KB偏移处。
- 每次调用调度器，**都改变MMU页表中活跃的32KB页**，以反映出新的活跃的应用或任务。

### 14.12总结

本章介绍了存储器管理和虚拟存储器系统的基本知识。MMU的一个主要服务是能把各个任务作为各自独立的程序在其自己的虚拟存储空间中运行。

虚拟存储器系统的一个重要特征是地址重定位。地址重定位是将处理器核产生的地址转换到主存的不同地址，转换由MMU硬件完成。

在一个虚拟存储器系统中，虚存通常作为固定空间或动态空间被分成几个部分。在固定空间内，映射在页表中的转换数据在在普通操作中不发生变化；在动态空间内，虚存到物理存储器之间的映射关系频繁发生变化。

页表包含虚拟页的描述信息。一个页表项PTE将虚存中的一页转换到物理存储器中的一个页帧。页表项通过虚拟地址进行组织，包含将一页转换成一个页帧的转换数据。

ARM MMU的功能如下：

- 读L1和L2页表，并将其装载到TLB中；
- 在TLB中保存最近的虚实地址转换数据；
- 执行虚拟地址到物理地址的转换；
- 强化访问权限，配置cache和写缓冲器。

ARM MMU中增加的一个特殊功能是快速上下文切换扩展FCSE。快速上下文切换扩展改善了多任务环境中的系统性能，因为在上下文切换时，他不需要清除cache和TLB。

一个简单的虚拟存储器系统的实用例子详细介绍了配置MMU，以支持多任务的过程。

配置步骤为：定义虚存的固定系统软件所使用的区域：定义每个任务的虚拟存储映射；将任务的区域定位到物理存储器映射中；在页表区域中定义和定位页表；定义创建、管理区域和页表所需要的数据结构；初始化MMU：使用预定义的区域数据构造页表项，并将他们写入页表中；建立上下文切换例程，从一个任务转换到另一个任务。



## 第十五章、ARM体系结构的发展

- ARMv6对高级DSP和SIMD的支持
- ARMv6增加的系统和多处理器支持
- ARMv6的实现
- ARMv6之后的未来技术
- 总结

##### 个人感悟

这本书是我学的时间最久的，从二月份到六月，经历了四个月时间，中间的四月份和五月份没怎么学，主要还是两个月的时间，但是这本书对我而言意义是非凡的，让我补全了缺失已久的知识，让我对之前学习的内核中的很多点有了清晰的认识，比如页表、访问权限等，之前学内核的时候经常出现，但总是不理解，这些是硬件决定的，所以内核只不过是按照人家的规则办事，自然无法了解全况。

----

学了下介绍Cortex-M3的视频，介绍了两种堆栈指针，MSP和PSP，刚开始我还有点疑惑，其实就是svc模式下的r13和用户模式下的r13。准确的说MSP是作为了特权模式下的堆栈，无论是中断还是复位都是使用MSP。

main函数的执行在裸机中是先执行复位服务程序rest_init，然后在这个函数最后将__main地址送入r0之后跳转中。（如果采用ICP和ISP就不会发生跳转， 而是直接执行0x08000000或者0x1fff0000处的向量表复位函数）

![1688278504413](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1688278504413.png)

先是执行IAP的中断向量表，执行用户程序的复位中断程序地址，最后重定位到用户程序的向量表地址，以后就是执行用户程序的向量表，为什么是先执行复位后重定位。

对VTOR的操作是在system_init实现的，而初始化双堆栈指针是在__main中实现的。

VTOR寄存器和VBAR是ARM处理器中的两个重要寄存器，它们有以下区别：

1. 功能不同：VTOR寄存器（Vector Table Offset Register）用于存储向量表的偏移地址，通过设置该寄存器可以更改向量表的起始地址；而VBAR寄存器（Vector Base Address Register）则用于指示向量表的基地址，即向量表的起始地址。

2. 作用不同：VTOR寄存器用于支持中断和异常处理，当处理器遇到中断或异常时，会根据VTOR寄存器中的偏移地址找到对应的中断或异常处理函数；而VBAR寄存器则用于定义异常向量表的位置，处理器在异常发生时会根据VBAR寄存器指示的向量表起始地址去执行相应的异常处理函数。

3. 寄存器大小不同：VTOR寄存器的大小为32位，可以在32位处理器中使用；而VBAR寄存器的大小为32位或64位，取决于所用的ARM架构。

4. 可设置的位置不同：VTOR寄存器可以位于系统内存的任何位置，通过设置其偏移地址来指示向量表的起始地址；而VBAR寄存器只能位于处理器的特定位置，具体位置取决于特定的ARM架构。

总之，VTOR寄存器用于指示向量表的偏移地址，而VBAR寄存器用于指示向量表的基地址。通过设置这两个寄存器可以控制处理器中异常和中断的处理方式。

VTOR是M系列特有的寄存器，映射出来的，VBAR是协处理器内部的寄存器。VBAR只有在uboot启动期间修改异常向量表起始地址，以及使能软件重定位，而VTOR是用来找到想要的向量表中服务程序地址。

MSP和PSP区别就是，前者是主模式堆栈指针，后者是任务堆栈指针，也就是线程堆栈中的一系列指针。 

中断优先级由寄存器设定，十个是系统异常由M3决定，256个是外部中断由芯片厂家决定。

中断屏蔽寄存器和屏蔽CPSR（Current Program Status Register，当前程序状态寄存器）控制域的区别如下：

1. 功能：中断屏蔽寄存器用于控制中断的使能和屏蔽，通过设置寄存器的位来屏蔽或允许特定的中断；屏蔽CPSR控制域是ARM架构中的一个寄存器字段，用于控制和管理处理器的执行状态。

2. 寄存器位置：中断屏蔽寄存器通常是一个单独的寄存器，例如在ARM架构中是中断屏蔽寄存器（Interrupt Mask Register，IMASK）；而屏蔽CPSR控制域是CPSR寄存器的一个字段，CPSR寄存器是一个32位的寄存器。

3. 作用范围：中断屏蔽寄存器一般只影响中断的处理过程，通过屏蔽或允许特定的中断来控制中断的触发；而屏蔽CPSR控制域则可影响到整个处理器的执行状态，包括中断、指令集、执行模式等。

4. 粒度：中断屏蔽寄存器的屏蔽位一般是针对单个中断的，可以配置每个中断的屏蔽情况；而屏蔽CPSR控制域则是对整个处理器的执行状态进行配置。

综上所述，中断屏蔽寄存器主要用于控制和管理中断的使能和屏蔽，而屏蔽CPSR控制域则主要用于控制和管理处理器的执行状态。两者在功能、寄存器位置、作用范围和粒度上存在明显的区别。中断屏蔽寄存器是不会向cpu发送被屏蔽的中断信号。

中断返回需要判断决定返回的模式和使用堆栈指针。以及处理器状态。

M3内核的咬尾中断机制会导致中断嵌套时省去出入栈的操作。上一个中断结束不会恢复上下文，也不会保存上下文，而是直接进入下一个中断服务程序。

M3中有MPU，协处理器设置region最多8个，region号越大优先级越高。对于未分配的区域访问会导致fault异常，如果采用背景区域就好了，未分配区域为背景区域权限。

![1688284144207](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1688284144207.png)

4GB的区域划分的默认访问许可。

M4比M3多了一个SIMD指令，这是单周期内同时操作多个数据的指令。

多了一个FPU，这是一个独立于CPU的浮点运算单元。支持单精度浮点数的运算，这也是M3无法浮点运算的原因。

因为M4多了对浮点运算的支持，在中断响应和退出时增加了对FPU扩展寄存器的保护，这导致扩大了栈帧的存储大小，增加中断响应延迟，在OS环境下增加上下文切换时间。

![1688285185687](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1688285185687.png)

寄存器上下文需要保存的更多了。

对比下Cortex-M0和Cortex-M3的对比。

- Cortex-M0基于ARMv6-M架构，只有一条系统总线。
- 没有定义非特权模式
- 两种操作模式，两个堆栈。handler和线程模式，这是为了区分正在执行代码的类型，前者是异常处理例程的代码；线程模式为普通应用程序的例程。
- 仅支持6个系统异常，和32个外部中断。
- 不支持存储器管理fault，所有的fault都由硬件fault异常进行处理。
- 更少的中断优先级

![1688286761316](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1688286761316.png)这里可以看出来，cpsr和BASEPRI都属于中断屏蔽的方法，M0不支持个别的方法。

这里的IAP复位异常实现的功能其实就是编译器自动创建的__main函数实现的。然后IAP跳转到用户程序的向量表中。执行system _init函数进行向量表重映射。

![1688286953166](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1688286953166.png)

这里不支持使用VTOR寄存器实现向量表重定位，而是采用存储器重映射，将用户程序的向量表重映射到SRAM区。这里的SYSCFGR1.MEM_MODE是32的系统配置寄存器CFGR1的一个位字段，用于设置内存映射模式。**boot1和BOOT0启动模式决定该位字段的具体数值，决定哪个内存映射到地址0x0上。**这就是启动模式的真正实现。为啥要拷贝到0x20000000上进行重映射，就是因为位字段是有选择的，0x0800 0000/0x2000 0000可以映射到0x0地址上。下图可以看到只有主flash、系统flash、SRAM可以映射到。

![1688288514078](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1688288514078.png)

系统上电后是从0x0地址处开始执行，因为采用主flash启动模式，导致flash的0x8000000被映射到0x0处，从而实现的访问中断向量表。这就是通过VTOR实现的重映射。这种方法只能是寄存器硬件实现就是mmu虚实映射实现的重映射。

M0支持4G的存储空间，但是不支持位带操作、也不支持MPU。

![1688296188242](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1688296188242.png)

![1688296309525](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1688296309525.png)

主要的是就是M0不是硬件分区，没有MPU，M3不支持FPU浮点数运算，M0的向量表不可重定位。

8M有源晶振链接的是外部时钟HSE，所以需要配置HSE时钟的倍频，然后使能各个总线下的外设时钟，GPIO和复用功能就是使能不同总线下的外设时钟从而选择对应功能。具体使能实现就是配置对应存储器映射出的系统外设寄存器。

这里采用项目启动流程对比下IAP之间的区别。

1. 内核初始化；
2. 强制PC指针指向中断向量表的复位中断向量执行复位中断函数；reset，这是汇编定义的。上来就是执行的用户程序的中断向量表，而不是IAP的中断向量表
3. 在复位中断函数中调用Systeminit函数（此函数是c函数，但是项目中屏蔽了此函数），作用是初始化时钟、配置中断向量表（也就是重定位向量表地址通过VTOR寄存器，库函数版本没屏蔽，而寄存器版本屏蔽了，虽然屏蔽了但在main函数中同样进行了重定位，两者区别就是执行顺序不同。项目从来没重定位过。。。）
4. 调用__main函数完成全局/静态变量的初始化和重定位工作，初始化堆栈和库函数。（之前一直以为此函数是main函数，发现不是，应该是编译器内部函数）
5. 跳转到main函数。

----

ICP/ISP/IAP之前的区别。

- ICP是使用J-link启动，启动地址在0x0800 0000，这是主闪存存储器也就是内部flash的起始地址，直接下载到这里。boot01为0x
- ISP是使用串口启动，需要用到bootloader，这是芯片厂固化到0x1fff ffff之前地址上（这是一个ROM），然后通过系统引导程序将程序下载到0x0800 0000处。这是直接下载到内部flash上。boot01为10时
- IAP是使用开发者自己的代码，自己的IAP代码在0x0800 0000上，然后由IAP代码将程序写入到0x0800 0000后面的内存上，写入完成后跳转到该位置。
- 调试的话，是直接将代码烧录到0x2000 0000的SRAM上。boot01都拉高

 支持位段操作，则其仅SRAM区域和外设区域的前1MB空间支持位段操作 ， 没有特殊的汇编指令，但其可以自动转化特殊存储区域的地址，降低了代码编写的复杂度 

位段操作指的是用特定地址来映射某地址空间中的某一位。只需要将特定地址赋值即可实现对某地址中的某一位操作。

Cortex-M3架构由三种PSR，分别为APSR/EPSR/IPSR，分别表示应用、执行、中断。（不同的处理器模式对应着不同的CPSR，IPSR保存了中断号以及异常类型，我之前就好奇中断号在哪里。）

![1690704815611](C:\Users\MACHENIKE\AppData\Roaming\Typora\typora-user-images\1690704815611.png)

时钟和向量表由system_init函数实现，其余由__main函数实现。

- bin是单纯的二进制代码镜像，最终烧录的文件依旧是bin文件
- hex是带有地址信息的bin，使用ISP串口或者st-link下载使用这个用来检验文件是否破损以及配置地址，如果没有最终会编译成bin文件烧录。
- axf是包含调试信息的hex，在线调试debug时使用这个

出栈抢占：系统优化，异常请求在另一个异常处理出栈期间发生，此时取消出栈，转而执行新的异常请求，这类似于咬尾中断机制。

静态重定位：虚实映射关系在进程装入时完成，以后不再改变。固定分区比如外设映射区、内核空间都属于这种。装入时将程序的数据和代码逻辑地址转换成物理地址。

动态重定位：执行期间，每次访问内存之前进行重定位。

SDRAM是每个时钟周期传输一次数据，也就是一个沿传送一位，DDR是每个时钟周期传输两位。

**Linux内存管理的伙伴系统**

内存被分成很多大块，每个块都是两个页面的幂，如果找不到想要的小块，就将大块分成两部分，一半被分配，一半空闲，当块被释放时找到其伙伴，如果伙伴也空闲就合并两者。优点就是会将连续地址合并。把所有的空闲页面分成11个块链表，第11个块链表可以分配2^10个页。页面为4KB。

**交换空间**

物理内存空间不足时，将一部分磁盘空间当做物理内存。创建swap区所用的分区或文件，使用mkswap命令在该分区或文件上写入一个特殊的识别标志，将swap类型的文件系统的挂载信息添加到/etc/fstab文件中。

fork进程复制父进程的地址空间时，内存操作顺序：1.刷出高速缓存，2.操作内存，3.刷出TLB

